Date: 2022-11-26 23:20:25.204853+07:00 (GMT+7)
Mode: CV_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: microsoft/deberta-v3-large
Model_config: DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0.0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.20.1",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Pooling_strategy: concat_attn_mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 367, 'num_training_steps': 5880}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 768

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 1/4 | STEP: 0000/1470 | LOSS: 2.16139 (2.16139) | LR: 0.00000005 | TIME: 0:00:03 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0040/1470 | LOSS: 1.70918 (2.39280) | LR: 0.00000223 | TIME: 0:01:19 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0080/1470 | LOSS: 0.58919 (1.77587) | LR: 0.00000441 | TIME: 0:02:32 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0120/1470 | LOSS: 0.20168 (1.27501) | LR: 0.00000659 | TIME: 0:03:53 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0160/1470 | LOSS: 0.19703 (1.01018) | LR: 0.00000877 | TIME: 0:05:10 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0200/1470 | LOSS: 0.09117 (0.84245) | LR: 0.00001095 | TIME: 0:06:30 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0240/1470 | LOSS: 0.09680 (0.72889) | LR: 0.00001313 | TIME: 0:07:51 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0280/1470 | LOSS: 0.05918 (0.64956) | LR: 0.00001531 | TIME: 0:09:13 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0320/1470 | LOSS: 0.07679 (0.59142) | LR: 0.00001749 | TIME: 0:10:36 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0360/1470 | LOSS: 0.10998 (0.54473) | LR: 0.00001967 | TIME: 0:11:57 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0400/1470 | LOSS: 0.15787 (0.50493) | LR: 0.00002000 | TIME: 0:13:23 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0440/1470 | LOSS: 0.16490 (0.47437) | LR: 0.00001999 | TIME: 0:14:41 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0480/1470 | LOSS: 0.33265 (0.44763) | LR: 0.00001998 | TIME: 0:15:56 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0520/1470 | LOSS: 0.06477 (0.42395) | LR: 0.00001996 | TIME: 0:17:16 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0560/1470 | LOSS: 0.10631 (0.40215) | LR: 0.00001994 | TIME: 0:18:39 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0600/1470 | LOSS: 0.09117 (0.38455) | LR: 0.00001991 | TIME: 0:20:00 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0640/1470 | LOSS: 0.19853 (0.36916) | LR: 0.00001988 | TIME: 0:21:21 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0680/1470 | LOSS: 0.13217 (0.35641) | LR: 0.00001984 | TIME: 0:22:41 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0720/1470 | LOSS: 0.06694 (0.34512) | LR: 0.00001980 | TIME: 0:23:55 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0760/1470 | LOSS: 0.15330 (0.33489) | LR: 0.00001975 | TIME: 0:25:15 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0800/1470 | LOSS: 0.08573 (0.32490) | LR: 0.00001970 | TIME: 0:26:33 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0840/1470 | LOSS: 0.13204 (0.31591) | LR: 0.00001964 | TIME: 0:27:50 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0880/1470 | LOSS: 0.11291 (0.30727) | LR: 0.00001957 | TIME: 0:29:04 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0920/1470 | LOSS: 0.07907 (0.29968) | LR: 0.00001951 | TIME: 0:30:18 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0960/1470 | LOSS: 0.05587 (0.29316) | LR: 0.00001943 | TIME: 0:31:36 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1000/1470 | LOSS: 0.09767 (0.28640) | LR: 0.00001935 | TIME: 0:32:52 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1040/1470 | LOSS: 0.14332 (0.28071) | LR: 0.00001927 | TIME: 0:34:12 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1080/1470 | LOSS: 0.16033 (0.27543) | LR: 0.00001918 | TIME: 0:35:26 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1120/1470 | LOSS: 0.07327 (0.27042) | LR: 0.00001909 | TIME: 0:36:45 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1160/1470 | LOSS: 0.13060 (0.26584) | LR: 0.00001899 | TIME: 0:38:09 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1200/1470 | LOSS: 0.12895 (0.26094) | LR: 0.00001889 | TIME: 0:39:27 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1240/1470 | LOSS: 0.13612 (0.25653) | LR: 0.00001879 | TIME: 0:40:46 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1280/1470 | LOSS: 0.13808 (0.25261) | LR: 0.00001867 | TIME: 0:42:00 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1320/1470 | LOSS: 0.06323 (0.24948) | LR: 0.00001856 | TIME: 0:43:17 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1360/1470 | LOSS: 0.10752 (0.24636) | LR: 0.00001844 | TIME: 0:44:32 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1400/1470 | LOSS: 0.22453 (0.24307) | LR: 0.00001831 | TIME: 0:45:47 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1440/1470 | LOSS: 0.16268 (0.24036) | LR: 0.00001818 | TIME: 0:47:04 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1469/1470 | LOSS: 0.14436 (0.23812) | LR: 0.00001809 | TIME: 0:48:01 |

VALID_LOOP
[VALID F0] EPOCH: 1/4 | STEP: 000/485 | LOSS: 0.06899 (0.06899) | TIME: 0:00:01 |
[VALID F0] EPOCH: 1/4 | STEP: 040/485 | LOSS: 0.18479 (0.11620) | TIME: 0:00:14 |
[VALID F0] EPOCH: 1/4 | STEP: 080/485 | LOSS: 0.06993 (0.10147) | TIME: 0:00:28 |
[VALID F0] EPOCH: 1/4 | STEP: 120/485 | LOSS: 0.11280 (0.10455) | TIME: 0:00:41 |
[VALID F0] EPOCH: 1/4 | STEP: 160/485 | LOSS: 0.07333 (0.10355) | TIME: 0:00:55 |
[VALID F0] EPOCH: 1/4 | STEP: 200/485 | LOSS: 0.13632 (0.10702) | TIME: 0:01:09 |
[VALID F0] EPOCH: 1/4 | STEP: 240/485 | LOSS: 0.09000 (0.10991) | TIME: 0:01:22 |
[VALID F0] EPOCH: 1/4 | STEP: 280/485 | LOSS: 0.13880 (0.10943) | TIME: 0:01:36 |
[VALID F0] EPOCH: 1/4 | STEP: 320/485 | LOSS: 0.07934 (0.10974) | TIME: 0:01:50 |
[VALID F0] EPOCH: 1/4 | STEP: 360/485 | LOSS: 0.10283 (0.10970) | TIME: 0:02:03 |
[VALID F0] EPOCH: 1/4 | STEP: 400/485 | LOSS: 0.13251 (0.10937) | TIME: 0:02:17 |
[VALID F0] EPOCH: 1/4 | STEP: 440/485 | LOSS: 0.14485 (0.11041) | TIME: 0:02:30 |
[VALID F0] EPOCH: 1/4 | STEP: 480/485 | LOSS: 0.14891 (0.11087) | TIME: 0:02:44 |
[VALID F0] EPOCH: 1/4 | STEP: 484/485 | LOSS: 0.12089 (0.11066) | TIME: 0:02:45 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.23812 |      0.11066 |  0.47094 | 0.515 | 0.500 | 0.430 | 0.455 | 0.478 | 0.447 | 0:50:47 |


[SAVED] EPOCH: 1 | MCRMSE: 0.4709397554397583

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 2/4 | STEP: 0000/1470 | LOSS: 0.15627 (0.15627) | LR: 0.00001809 | TIME: 0:00:02 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0040/1470 | LOSS: 0.05396 (0.12136) | LR: 0.00001795 | TIME: 0:01:17 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0080/1470 | LOSS: 0.11278 (0.12252) | LR: 0.00001781 | TIME: 0:02:41 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0120/1470 | LOSS: 0.05202 (0.12068) | LR: 0.00001766 | TIME: 0:04:05 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0160/1470 | LOSS: 0.05842 (0.12059) | LR: 0.00001752 | TIME: 0:05:17 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0200/1470 | LOSS: 0.09352 (0.12394) | LR: 0.00001736 | TIME: 0:06:35 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0240/1470 | LOSS: 0.08423 (0.12433) | LR: 0.00001721 | TIME: 0:07:49 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0280/1470 | LOSS: 0.14039 (0.12134) | LR: 0.00001705 | TIME: 0:09:03 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0320/1470 | LOSS: 0.07816 (0.11991) | LR: 0.00001688 | TIME: 0:10:25 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0360/1470 | LOSS: 0.20508 (0.11853) | LR: 0.00001672 | TIME: 0:11:43 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0400/1470 | LOSS: 0.13046 (0.12011) | LR: 0.00001655 | TIME: 0:13:03 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0440/1470 | LOSS: 0.03871 (0.11830) | LR: 0.00001637 | TIME: 0:14:22 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0480/1470 | LOSS: 0.10447 (0.11730) | LR: 0.00001620 | TIME: 0:15:38 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0520/1470 | LOSS: 0.13670 (0.11654) | LR: 0.00001601 | TIME: 0:16:52 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0560/1470 | LOSS: 0.12141 (0.11567) | LR: 0.00001583 | TIME: 0:18:10 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0600/1470 | LOSS: 0.10333 (0.11521) | LR: 0.00001564 | TIME: 0:19:32 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0640/1470 | LOSS: 0.07494 (0.11592) | LR: 0.00001545 | TIME: 0:20:51 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0680/1470 | LOSS: 0.17010 (0.11663) | LR: 0.00001526 | TIME: 0:22:10 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0720/1470 | LOSS: 0.12166 (0.11600) | LR: 0.00001507 | TIME: 0:23:32 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0760/1470 | LOSS: 0.08742 (0.11587) | LR: 0.00001487 | TIME: 0:24:54 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0800/1470 | LOSS: 0.10662 (0.11593) | LR: 0.00001467 | TIME: 0:26:13 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0840/1470 | LOSS: 0.05220 (0.11657) | LR: 0.00001447 | TIME: 0:27:27 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0880/1470 | LOSS: 0.12508 (0.11658) | LR: 0.00001426 | TIME: 0:28:47 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0920/1470 | LOSS: 0.06741 (0.11722) | LR: 0.00001405 | TIME: 0:30:06 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0960/1470 | LOSS: 0.04567 (0.11707) | LR: 0.00001384 | TIME: 0:31:25 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1000/1470 | LOSS: 0.16841 (0.11694) | LR: 0.00001363 | TIME: 0:32:42 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1040/1470 | LOSS: 0.07726 (0.11671) | LR: 0.00001342 | TIME: 0:33:59 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1080/1470 | LOSS: 0.05504 (0.11626) | LR: 0.00001320 | TIME: 0:35:19 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1120/1470 | LOSS: 0.21874 (0.11641) | LR: 0.00001299 | TIME: 0:36:38 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1160/1470 | LOSS: 0.15667 (0.11597) | LR: 0.00001277 | TIME: 0:37:54 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1200/1470 | LOSS: 0.13058 (0.11592) | LR: 0.00001255 | TIME: 0:39:12 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1240/1470 | LOSS: 0.11473 (0.11585) | LR: 0.00001233 | TIME: 0:40:20 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1280/1470 | LOSS: 0.08932 (0.11587) | LR: 0.00001211 | TIME: 0:41:39 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1320/1470 | LOSS: 0.14164 (0.11569) | LR: 0.00001188 | TIME: 0:42:57 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1360/1470 | LOSS: 0.11487 (0.11535) | LR: 0.00001166 | TIME: 0:44:13 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1400/1470 | LOSS: 0.09965 (0.11500) | LR: 0.00001143 | TIME: 0:45:33 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1440/1470 | LOSS: 0.07249 (0.11448) | LR: 0.00001121 | TIME: 0:46:50 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1469/1470 | LOSS: 0.08660 (0.11457) | LR: 0.00001104 | TIME: 0:47:47 |

VALID_LOOP
[VALID F0] EPOCH: 2/4 | STEP: 000/485 | LOSS: 0.06509 (0.06509) | TIME: 0:00:01 |
[VALID F0] EPOCH: 2/4 | STEP: 040/485 | LOSS: 0.20241 (0.11389) | TIME: 0:00:14 |
[VALID F0] EPOCH: 2/4 | STEP: 080/485 | LOSS: 0.06303 (0.09942) | TIME: 0:00:28 |
[VALID F0] EPOCH: 2/4 | STEP: 120/485 | LOSS: 0.09604 (0.10459) | TIME: 0:00:42 |
[VALID F0] EPOCH: 2/4 | STEP: 160/485 | LOSS: 0.08865 (0.10382) | TIME: 0:00:55 |
[VALID F0] EPOCH: 2/4 | STEP: 200/485 | LOSS: 0.06439 (0.10824) | TIME: 0:01:09 |
[VALID F0] EPOCH: 2/4 | STEP: 240/485 | LOSS: 0.09933 (0.11197) | TIME: 0:01:22 |
[VALID F0] EPOCH: 2/4 | STEP: 280/485 | LOSS: 0.11151 (0.11144) | TIME: 0:01:36 |
[VALID F0] EPOCH: 2/4 | STEP: 320/485 | LOSS: 0.08123 (0.11146) | TIME: 0:01:50 |
[VALID F0] EPOCH: 2/4 | STEP: 360/485 | LOSS: 0.12576 (0.11166) | TIME: 0:02:03 |
[VALID F0] EPOCH: 2/4 | STEP: 400/485 | LOSS: 0.10636 (0.11098) | TIME: 0:02:17 |
[VALID F0] EPOCH: 2/4 | STEP: 440/485 | LOSS: 0.13589 (0.11245) | TIME: 0:02:31 |
[VALID F0] EPOCH: 2/4 | STEP: 480/485 | LOSS: 0.14005 (0.11337) | TIME: 0:02:44 |
[VALID F0] EPOCH: 2/4 | STEP: 484/485 | LOSS: 0.10669 (0.11311) | TIME: 0:02:45 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11457 |      0.11311 |  0.47571 | 0.501 | 0.515 | 0.423 | 0.445 | 0.512 | 0.459 | 0:50:33 |

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 3/4 | STEP: 0000/1470 | LOSS: 0.17324 (0.17324) | LR: 0.00001104 | TIME: 0:00:02 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0040/1470 | LOSS: 0.07798 (0.09144) | LR: 0.00001081 | TIME: 0:01:24 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0080/1470 | LOSS: 0.08838 (0.09016) | LR: 0.00001058 | TIME: 0:02:43 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0120/1470 | LOSS: 0.09016 (0.08968) | LR: 0.00001036 | TIME: 0:03:58 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0160/1470 | LOSS: 0.08962 (0.09124) | LR: 0.00001013 | TIME: 0:05:14 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0200/1470 | LOSS: 0.13848 (0.09255) | LR: 0.00000990 | TIME: 0:06:34 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0240/1470 | LOSS: 0.05985 (0.09175) | LR: 0.00000967 | TIME: 0:07:49 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0280/1470 | LOSS: 0.05727 (0.09028) | LR: 0.00000944 | TIME: 0:09:10 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0320/1470 | LOSS: 0.14652 (0.09110) | LR: 0.00000922 | TIME: 0:10:29 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0360/1470 | LOSS: 0.13179 (0.09164) | LR: 0.00000899 | TIME: 0:11:47 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0400/1470 | LOSS: 0.06148 (0.09269) | LR: 0.00000876 | TIME: 0:13:08 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0440/1470 | LOSS: 0.18376 (0.09243) | LR: 0.00000854 | TIME: 0:14:24 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0480/1470 | LOSS: 0.06974 (0.09180) | LR: 0.00000831 | TIME: 0:15:39 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0520/1470 | LOSS: 0.05849 (0.09122) | LR: 0.00000809 | TIME: 0:17:00 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0560/1470 | LOSS: 0.04177 (0.09123) | LR: 0.00000787 | TIME: 0:18:16 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0600/1470 | LOSS: 0.21587 (0.09225) | LR: 0.00000764 | TIME: 0:19:39 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0640/1470 | LOSS: 0.01910 (0.09225) | LR: 0.00000742 | TIME: 0:20:58 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0680/1470 | LOSS: 0.12370 (0.09245) | LR: 0.00000720 | TIME: 0:22:18 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0720/1470 | LOSS: 0.03149 (0.09166) | LR: 0.00000698 | TIME: 0:23:36 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0760/1470 | LOSS: 0.10350 (0.09232) | LR: 0.00000677 | TIME: 0:24:53 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0800/1470 | LOSS: 0.15166 (0.09166) | LR: 0.00000655 | TIME: 0:26:08 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0840/1470 | LOSS: 0.08231 (0.09188) | LR: 0.00000634 | TIME: 0:27:24 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0880/1470 | LOSS: 0.18571 (0.09177) | LR: 0.00000613 | TIME: 0:28:41 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0920/1470 | LOSS: 0.06795 (0.09138) | LR: 0.00000592 | TIME: 0:29:59 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0960/1470 | LOSS: 0.04531 (0.09102) | LR: 0.00000571 | TIME: 0:31:19 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1000/1470 | LOSS: 0.14009 (0.09115) | LR: 0.00000551 | TIME: 0:32:33 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1040/1470 | LOSS: 0.04516 (0.09094) | LR: 0.00000531 | TIME: 0:33:54 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1080/1470 | LOSS: 0.04904 (0.09096) | LR: 0.00000511 | TIME: 0:35:16 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1120/1470 | LOSS: 0.06052 (0.09062) | LR: 0.00000491 | TIME: 0:36:27 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1160/1470 | LOSS: 0.10418 (0.09059) | LR: 0.00000471 | TIME: 0:37:52 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1200/1470 | LOSS: 0.03662 (0.09021) | LR: 0.00000452 | TIME: 0:39:08 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1240/1470 | LOSS: 0.04740 (0.09020) | LR: 0.00000433 | TIME: 0:40:25 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1280/1470 | LOSS: 0.10993 (0.09007) | LR: 0.00000415 | TIME: 0:41:50 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1320/1470 | LOSS: 0.09306 (0.08972) | LR: 0.00000396 | TIME: 0:43:11 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1360/1470 | LOSS: 0.05916 (0.08969) | LR: 0.00000378 | TIME: 0:44:27 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1400/1470 | LOSS: 0.13443 (0.08947) | LR: 0.00000361 | TIME: 0:45:41 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1440/1470 | LOSS: 0.10229 (0.08938) | LR: 0.00000343 | TIME: 0:47:00 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1469/1470 | LOSS: 0.06798 (0.08945) | LR: 0.00000331 | TIME: 0:48:01 |

VALID_LOOP
[VALID F0] EPOCH: 3/4 | STEP: 000/485 | LOSS: 0.08269 (0.08269) | TIME: 0:00:01 |
[VALID F0] EPOCH: 3/4 | STEP: 040/485 | LOSS: 0.11366 (0.10473) | TIME: 0:00:15 |
[VALID F0] EPOCH: 3/4 | STEP: 080/485 | LOSS: 0.07682 (0.09205) | TIME: 0:00:28 |
[VALID F0] EPOCH: 3/4 | STEP: 120/485 | LOSS: 0.08483 (0.09679) | TIME: 0:00:42 |
[VALID F0] EPOCH: 3/4 | STEP: 160/485 | LOSS: 0.08619 (0.09564) | TIME: 0:00:55 |
[VALID F0] EPOCH: 3/4 | STEP: 200/485 | LOSS: 0.04001 (0.09676) | TIME: 0:01:09 |
[VALID F0] EPOCH: 3/4 | STEP: 240/485 | LOSS: 0.05007 (0.09962) | TIME: 0:01:23 |
[VALID F0] EPOCH: 3/4 | STEP: 280/485 | LOSS: 0.18168 (0.09963) | TIME: 0:01:36 |
[VALID F0] EPOCH: 3/4 | STEP: 320/485 | LOSS: 0.09831 (0.09958) | TIME: 0:01:50 |
[VALID F0] EPOCH: 3/4 | STEP: 360/485 | LOSS: 0.08936 (0.10054) | TIME: 0:02:04 |
[VALID F0] EPOCH: 3/4 | STEP: 400/485 | LOSS: 0.09104 (0.10008) | TIME: 0:02:17 |
[VALID F0] EPOCH: 3/4 | STEP: 440/485 | LOSS: 0.18900 (0.10093) | TIME: 0:02:31 |
[VALID F0] EPOCH: 3/4 | STEP: 480/485 | LOSS: 0.13268 (0.10164) | TIME: 0:02:45 |
[VALID F0] EPOCH: 3/4 | STEP: 484/485 | LOSS: 0.12569 (0.10139) | TIME: 0:02:46 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.08945 |      0.10139 |  0.45067 | 0.491 | 0.445 | 0.414 | 0.447 | 0.461 | 0.446 | 0:50:48 |


[SAVED] EPOCH: 3 | MCRMSE: 0.4506726562976837

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 4/4 | STEP: 0000/1470 | LOSS: 0.04500 (0.04500) | LR: 0.00000330 | TIME: 0:00:03 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0040/1470 | LOSS: 0.06641 (0.06927) | LR: 0.00000314 | TIME: 0:01:21 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0080/1470 | LOSS: 0.10150 (0.06916) | LR: 0.00000297 | TIME: 0:02:42 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0120/1470 | LOSS: 0.08424 (0.06968) | LR: 0.00000281 | TIME: 0:04:01 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0160/1470 | LOSS: 0.05785 (0.06900) | LR: 0.00000266 | TIME: 0:05:17 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0200/1470 | LOSS: 0.04418 (0.07082) | LR: 0.00000250 | TIME: 0:06:42 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0240/1470 | LOSS: 0.05792 (0.07089) | LR: 0.00000235 | TIME: 0:08:03 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0280/1470 | LOSS: 0.03835 (0.07023) | LR: 0.00000221 | TIME: 0:09:18 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0320/1470 | LOSS: 0.05152 (0.07011) | LR: 0.00000207 | TIME: 0:10:34 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0360/1470 | LOSS: 0.07907 (0.07036) | LR: 0.00000193 | TIME: 0:11:53 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0400/1470 | LOSS: 0.05987 (0.07143) | LR: 0.00000180 | TIME: 0:13:09 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0440/1470 | LOSS: 0.06267 (0.07149) | LR: 0.00000167 | TIME: 0:14:28 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0480/1470 | LOSS: 0.08664 (0.07112) | LR: 0.00000155 | TIME: 0:15:46 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0520/1470 | LOSS: 0.20209 (0.07113) | LR: 0.00000143 | TIME: 0:17:01 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0560/1470 | LOSS: 0.02690 (0.07042) | LR: 0.00000131 | TIME: 0:18:19 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0600/1470 | LOSS: 0.06397 (0.07033) | LR: 0.00000120 | TIME: 0:19:37 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0640/1470 | LOSS: 0.02967 (0.07061) | LR: 0.00000110 | TIME: 0:21:01 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0680/1470 | LOSS: 0.02870 (0.07030) | LR: 0.00000099 | TIME: 0:22:19 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0720/1470 | LOSS: 0.17834 (0.07070) | LR: 0.00000090 | TIME: 0:23:40 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0760/1470 | LOSS: 0.04035 (0.07087) | LR: 0.00000081 | TIME: 0:25:02 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0800/1470 | LOSS: 0.04675 (0.07113) | LR: 0.00000072 | TIME: 0:26:22 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0840/1470 | LOSS: 0.06151 (0.07073) | LR: 0.00000064 | TIME: 0:27:35 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0880/1470 | LOSS: 0.05897 (0.07111) | LR: 0.00000056 | TIME: 0:28:56 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0920/1470 | LOSS: 0.14621 (0.07124) | LR: 0.00000049 | TIME: 0:30:18 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0960/1470 | LOSS: 0.04182 (0.07132) | LR: 0.00000042 | TIME: 0:31:37 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1000/1470 | LOSS: 0.15491 (0.07113) | LR: 0.00000036 | TIME: 0:32:48 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1040/1470 | LOSS: 0.04589 (0.07113) | LR: 0.00000030 | TIME: 0:34:05 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1080/1470 | LOSS: 0.05804 (0.07108) | LR: 0.00000024 | TIME: 0:35:22 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1120/1470 | LOSS: 0.07302 (0.07134) | LR: 0.00000020 | TIME: 0:36:36 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1160/1470 | LOSS: 0.04725 (0.07130) | LR: 0.00000015 | TIME: 0:37:53 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1200/1470 | LOSS: 0.10063 (0.07117) | LR: 0.00000012 | TIME: 0:39:17 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1240/1470 | LOSS: 0.06121 (0.07101) | LR: 0.00000009 | TIME: 0:40:42 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1280/1470 | LOSS: 0.08973 (0.07097) | LR: 0.00000006 | TIME: 0:42:01 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1320/1470 | LOSS: 0.05944 (0.07113) | LR: 0.00000004 | TIME: 0:43:22 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1360/1470 | LOSS: 0.17355 (0.07131) | LR: 0.00000002 | TIME: 0:44:41 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1400/1470 | LOSS: 0.11610 (0.07126) | LR: 0.00000001 | TIME: 0:46:02 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1440/1470 | LOSS: 0.02991 (0.07106) | LR: 0.00000000 | TIME: 0:47:15 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1469/1470 | LOSS: 0.05377 (0.07118) | LR: 0.00000000 | TIME: 0:48:10 |

VALID_LOOP
[VALID F0] EPOCH: 4/4 | STEP: 000/485 | LOSS: 0.08786 (0.08786) | TIME: 0:00:01 |
[VALID F0] EPOCH: 4/4 | STEP: 040/485 | LOSS: 0.12125 (0.10468) | TIME: 0:00:15 |
[VALID F0] EPOCH: 4/4 | STEP: 080/485 | LOSS: 0.06669 (0.09190) | TIME: 0:00:28 |
[VALID F0] EPOCH: 4/4 | STEP: 120/485 | LOSS: 0.07663 (0.09623) | TIME: 0:00:42 |
[VALID F0] EPOCH: 4/4 | STEP: 160/485 | LOSS: 0.08888 (0.09480) | TIME: 0:00:55 |
[VALID F0] EPOCH: 4/4 | STEP: 200/485 | LOSS: 0.03364 (0.09613) | TIME: 0:01:09 |
[VALID F0] EPOCH: 4/4 | STEP: 240/485 | LOSS: 0.05198 (0.09909) | TIME: 0:01:23 |
[VALID F0] EPOCH: 4/4 | STEP: 280/485 | LOSS: 0.17831 (0.09911) | TIME: 0:01:36 |
[VALID F0] EPOCH: 4/4 | STEP: 320/485 | LOSS: 0.09405 (0.09928) | TIME: 0:01:50 |
[VALID F0] EPOCH: 4/4 | STEP: 360/485 | LOSS: 0.08024 (0.10014) | TIME: 0:02:04 |
[VALID F0] EPOCH: 4/4 | STEP: 400/485 | LOSS: 0.08206 (0.09945) | TIME: 0:02:17 |
[VALID F0] EPOCH: 4/4 | STEP: 440/485 | LOSS: 0.19797 (0.10047) | TIME: 0:02:31 |
[VALID F0] EPOCH: 4/4 | STEP: 480/485 | LOSS: 0.13864 (0.10128) | TIME: 0:02:44 |
[VALID F0] EPOCH: 4/4 | STEP: 484/485 | LOSS: 0.10756 (0.10101) | TIME: 0:02:46 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.07118 |      0.10101 |  0.44976 | 0.492 | 0.445 | 0.409 | 0.446 | 0.463 | 0.443 | 0:50:56 |


[SAVED] EPOCH: 4 | MCRMSE: 0.44976410269737244


----------------------------------- FOLD 0 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.44976      0.4925   0.44487       0.40903        0.44622    0.46323        0.44272

################################### END OF FOlD 0 ###################################


Date: 2022-11-27 02:44:06.911403+07:00 (GMT+7)
Mode: CV_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: microsoft/deberta-v3-large
Model_config: DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0.0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.20.1",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Pooling_strategy: concat_attn_mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5860}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 768

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 1/4 | STEP: 0000/1465 | LOSS: 2.02254 (2.02254) | LR: 0.00000005 | TIME: 0:00:02 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0040/1465 | LOSS: 1.66786 (2.30835) | LR: 0.00000224 | TIME: 0:01:19 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0080/1465 | LOSS: 0.14719 (1.70413) | LR: 0.00000443 | TIME: 0:02:37 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0120/1465 | LOSS: 0.14273 (1.22452) | LR: 0.00000661 | TIME: 0:04:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0160/1465 | LOSS: 0.11961 (0.96566) | LR: 0.00000880 | TIME: 0:05:21 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0200/1465 | LOSS: 0.26957 (0.80323) | LR: 0.00001098 | TIME: 0:06:35 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0240/1465 | LOSS: 0.10606 (0.69859) | LR: 0.00001317 | TIME: 0:07:51 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0280/1465 | LOSS: 0.13250 (0.62066) | LR: 0.00001536 | TIME: 0:09:10 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0320/1465 | LOSS: 0.20791 (0.56314) | LR: 0.00001754 | TIME: 0:10:26 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0360/1465 | LOSS: 0.16379 (0.51908) | LR: 0.00001973 | TIME: 0:11:45 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0400/1465 | LOSS: 0.09154 (0.48386) | LR: 0.00002000 | TIME: 0:13:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0440/1465 | LOSS: 0.18484 (0.45222) | LR: 0.00001999 | TIME: 0:14:30 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0480/1465 | LOSS: 0.08451 (0.42938) | LR: 0.00001998 | TIME: 0:15:41 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0520/1465 | LOSS: 0.09463 (0.40810) | LR: 0.00001996 | TIME: 0:16:54 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0560/1465 | LOSS: 0.08437 (0.39098) | LR: 0.00001994 | TIME: 0:18:14 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0600/1465 | LOSS: 0.08235 (0.37499) | LR: 0.00001991 | TIME: 0:19:31 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0640/1465 | LOSS: 0.24060 (0.36074) | LR: 0.00001988 | TIME: 0:20:51 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0680/1465 | LOSS: 0.12690 (0.34697) | LR: 0.00001984 | TIME: 0:22:07 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0720/1465 | LOSS: 0.13442 (0.33502) | LR: 0.00001979 | TIME: 0:23:20 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0760/1465 | LOSS: 0.09741 (0.32520) | LR: 0.00001975 | TIME: 0:24:42 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0800/1465 | LOSS: 0.16083 (0.31585) | LR: 0.00001969 | TIME: 0:25:56 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0840/1465 | LOSS: 0.10737 (0.30838) | LR: 0.00001963 | TIME: 0:27:10 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0880/1465 | LOSS: 0.10684 (0.30050) | LR: 0.00001957 | TIME: 0:28:26 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0920/1465 | LOSS: 0.06007 (0.29438) | LR: 0.00001950 | TIME: 0:29:46 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0960/1465 | LOSS: 0.22352 (0.28805) | LR: 0.00001943 | TIME: 0:31:03 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1000/1465 | LOSS: 0.14903 (0.28251) | LR: 0.00001935 | TIME: 0:32:23 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1040/1465 | LOSS: 0.09667 (0.27685) | LR: 0.00001926 | TIME: 0:33:44 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1080/1465 | LOSS: 0.15526 (0.27135) | LR: 0.00001918 | TIME: 0:35:08 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1120/1465 | LOSS: 0.13657 (0.26707) | LR: 0.00001908 | TIME: 0:36:28 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1160/1465 | LOSS: 0.10923 (0.26201) | LR: 0.00001898 | TIME: 0:37:46 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1200/1465 | LOSS: 0.13921 (0.25811) | LR: 0.00001888 | TIME: 0:38:58 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1240/1465 | LOSS: 0.11975 (0.25389) | LR: 0.00001877 | TIME: 0:40:16 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1280/1465 | LOSS: 0.07283 (0.25031) | LR: 0.00001866 | TIME: 0:41:37 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1320/1465 | LOSS: 0.17858 (0.24660) | LR: 0.00001855 | TIME: 0:42:52 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1360/1465 | LOSS: 0.27141 (0.24327) | LR: 0.00001842 | TIME: 0:44:13 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1400/1465 | LOSS: 0.10487 (0.24016) | LR: 0.00001830 | TIME: 0:45:31 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1440/1465 | LOSS: 0.23571 (0.23688) | LR: 0.00001817 | TIME: 0:46:49 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1464/1465 | LOSS: 0.09893 (0.23525) | LR: 0.00001809 | TIME: 0:47:37 |

VALID_LOOP
[VALID F1] EPOCH: 1/4 | STEP: 000/491 | LOSS: 0.20049 (0.20049) | TIME: 0:00:01 |
[VALID F1] EPOCH: 1/4 | STEP: 040/491 | LOSS: 0.08914 (0.11426) | TIME: 0:00:14 |
[VALID F1] EPOCH: 1/4 | STEP: 080/491 | LOSS: 0.18364 (0.12526) | TIME: 0:00:28 |
[VALID F1] EPOCH: 1/4 | STEP: 120/491 | LOSS: 0.13310 (0.11645) | TIME: 0:00:42 |
[VALID F1] EPOCH: 1/4 | STEP: 160/491 | LOSS: 0.10015 (0.11608) | TIME: 0:00:55 |
[VALID F1] EPOCH: 1/4 | STEP: 200/491 | LOSS: 0.07206 (0.11248) | TIME: 0:01:09 |
[VALID F1] EPOCH: 1/4 | STEP: 240/491 | LOSS: 0.12378 (0.11368) | TIME: 0:01:23 |
[VALID F1] EPOCH: 1/4 | STEP: 280/491 | LOSS: 0.14568 (0.11250) | TIME: 0:01:36 |
[VALID F1] EPOCH: 1/4 | STEP: 320/491 | LOSS: 0.07045 (0.11369) | TIME: 0:01:50 |
[VALID F1] EPOCH: 1/4 | STEP: 360/491 | LOSS: 0.04054 (0.11278) | TIME: 0:02:04 |
[VALID F1] EPOCH: 1/4 | STEP: 400/491 | LOSS: 0.08281 (0.11348) | TIME: 0:02:17 |
[VALID F1] EPOCH: 1/4 | STEP: 440/491 | LOSS: 0.08890 (0.11454) | TIME: 0:02:31 |
[VALID F1] EPOCH: 1/4 | STEP: 480/491 | LOSS: 0.04604 (0.11458) | TIME: 0:02:44 |
[VALID F1] EPOCH: 1/4 | STEP: 490/491 | LOSS: 0.06034 (0.11412) | TIME: 0:02:48 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.23525 |      0.11412 |  0.47882 | 0.497 | 0.485 | 0.422 | 0.495 | 0.479 | 0.497 | 0:50:26 |


[SAVED] EPOCH: 1 | MCRMSE: 0.47882190346717834

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 2/4 | STEP: 0000/1465 | LOSS: 0.10761 (0.10761) | LR: 0.00001809 | TIME: 0:00:03 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0040/1465 | LOSS: 0.02519 (0.09547) | LR: 0.00001795 | TIME: 0:01:25 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0080/1465 | LOSS: 0.09198 (0.09660) | LR: 0.00001781 | TIME: 0:02:40 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0120/1465 | LOSS: 0.09359 (0.10062) | LR: 0.00001766 | TIME: 0:03:53 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0160/1465 | LOSS: 0.10892 (0.10002) | LR: 0.00001751 | TIME: 0:05:07 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0200/1465 | LOSS: 0.12038 (0.10542) | LR: 0.00001736 | TIME: 0:06:30 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0240/1465 | LOSS: 0.03502 (0.10845) | LR: 0.00001721 | TIME: 0:07:47 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0280/1465 | LOSS: 0.10577 (0.10747) | LR: 0.00001704 | TIME: 0:09:05 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0320/1465 | LOSS: 0.10405 (0.10843) | LR: 0.00001688 | TIME: 0:10:22 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0360/1465 | LOSS: 0.34412 (0.10895) | LR: 0.00001671 | TIME: 0:11:34 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0400/1465 | LOSS: 0.13554 (0.10831) | LR: 0.00001654 | TIME: 0:12:50 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0440/1465 | LOSS: 0.10585 (0.10943) | LR: 0.00001637 | TIME: 0:14:08 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0480/1465 | LOSS: 0.11289 (0.10924) | LR: 0.00001619 | TIME: 0:15:21 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0520/1465 | LOSS: 0.11674 (0.10919) | LR: 0.00001601 | TIME: 0:16:36 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0560/1465 | LOSS: 0.14002 (0.10913) | LR: 0.00001582 | TIME: 0:17:55 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0600/1465 | LOSS: 0.14900 (0.10969) | LR: 0.00001564 | TIME: 0:19:18 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0640/1465 | LOSS: 0.19409 (0.11031) | LR: 0.00001545 | TIME: 0:20:37 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0680/1465 | LOSS: 0.10509 (0.11036) | LR: 0.00001525 | TIME: 0:21:59 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0720/1465 | LOSS: 0.09387 (0.11001) | LR: 0.00001506 | TIME: 0:23:22 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0760/1465 | LOSS: 0.14676 (0.11022) | LR: 0.00001486 | TIME: 0:24:41 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0800/1465 | LOSS: 0.24250 (0.11110) | LR: 0.00001466 | TIME: 0:25:54 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0840/1465 | LOSS: 0.06335 (0.11103) | LR: 0.00001445 | TIME: 0:27:15 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0880/1465 | LOSS: 0.06456 (0.11101) | LR: 0.00001425 | TIME: 0:28:33 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0920/1465 | LOSS: 0.15622 (0.11110) | LR: 0.00001404 | TIME: 0:29:54 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0960/1465 | LOSS: 0.13277 (0.11094) | LR: 0.00001383 | TIME: 0:31:16 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1000/1465 | LOSS: 0.18523 (0.11111) | LR: 0.00001362 | TIME: 0:32:38 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1040/1465 | LOSS: 0.12718 (0.11116) | LR: 0.00001340 | TIME: 0:33:50 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1080/1465 | LOSS: 0.08765 (0.11101) | LR: 0.00001319 | TIME: 0:35:04 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1120/1465 | LOSS: 0.04064 (0.11097) | LR: 0.00001297 | TIME: 0:36:25 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1160/1465 | LOSS: 0.17071 (0.11065) | LR: 0.00001275 | TIME: 0:37:41 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1200/1465 | LOSS: 0.23290 (0.11110) | LR: 0.00001253 | TIME: 0:39:06 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1240/1465 | LOSS: 0.06018 (0.11078) | LR: 0.00001231 | TIME: 0:40:27 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1280/1465 | LOSS: 0.23464 (0.11067) | LR: 0.00001208 | TIME: 0:41:46 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1320/1465 | LOSS: 0.08017 (0.11082) | LR: 0.00001186 | TIME: 0:43:01 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1360/1465 | LOSS: 0.10255 (0.11059) | LR: 0.00001163 | TIME: 0:44:17 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1400/1465 | LOSS: 0.17514 (0.11086) | LR: 0.00001141 | TIME: 0:45:37 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1440/1465 | LOSS: 0.09070 (0.11086) | LR: 0.00001118 | TIME: 0:46:50 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1464/1465 | LOSS: 0.04132 (0.11076) | LR: 0.00001104 | TIME: 0:47:35 |

VALID_LOOP
[VALID F1] EPOCH: 2/4 | STEP: 000/491 | LOSS: 0.18410 (0.18410) | TIME: 0:00:01 |
[VALID F1] EPOCH: 2/4 | STEP: 040/491 | LOSS: 0.05857 (0.10600) | TIME: 0:00:15 |
[VALID F1] EPOCH: 2/4 | STEP: 080/491 | LOSS: 0.16013 (0.11949) | TIME: 0:00:28 |
[VALID F1] EPOCH: 2/4 | STEP: 120/491 | LOSS: 0.15279 (0.11154) | TIME: 0:00:42 |
[VALID F1] EPOCH: 2/4 | STEP: 160/491 | LOSS: 0.08613 (0.11137) | TIME: 0:00:55 |
[VALID F1] EPOCH: 2/4 | STEP: 200/491 | LOSS: 0.05344 (0.10825) | TIME: 0:01:09 |
[VALID F1] EPOCH: 2/4 | STEP: 240/491 | LOSS: 0.10655 (0.10904) | TIME: 0:01:23 |
[VALID F1] EPOCH: 2/4 | STEP: 280/491 | LOSS: 0.16058 (0.10754) | TIME: 0:01:36 |
[VALID F1] EPOCH: 2/4 | STEP: 320/491 | LOSS: 0.04789 (0.10808) | TIME: 0:01:50 |
[VALID F1] EPOCH: 2/4 | STEP: 360/491 | LOSS: 0.04897 (0.10789) | TIME: 0:02:04 |
[VALID F1] EPOCH: 2/4 | STEP: 400/491 | LOSS: 0.08395 (0.10887) | TIME: 0:02:17 |
[VALID F1] EPOCH: 2/4 | STEP: 440/491 | LOSS: 0.07669 (0.10986) | TIME: 0:02:31 |
[VALID F1] EPOCH: 2/4 | STEP: 480/491 | LOSS: 0.05695 (0.11074) | TIME: 0:02:44 |
[VALID F1] EPOCH: 2/4 | STEP: 490/491 | LOSS: 0.04466 (0.11011) | TIME: 0:02:48 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11076 |      0.11011 |  0.47049 | 0.489 | 0.445 | 0.493 | 0.464 | 0.479 | 0.454 | 0:50:24 |


[SAVED] EPOCH: 2 | MCRMSE: 0.4704926908016205

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 3/4 | STEP: 0000/1465 | LOSS: 0.15782 (0.15782) | LR: 0.00001104 | TIME: 0:00:03 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0040/1465 | LOSS: 0.09541 (0.09412) | LR: 0.00001081 | TIME: 0:01:21 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0080/1465 | LOSS: 0.05611 (0.09392) | LR: 0.00001058 | TIME: 0:02:35 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0120/1465 | LOSS: 0.07387 (0.09395) | LR: 0.00001035 | TIME: 0:04:01 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0160/1465 | LOSS: 0.08115 (0.09275) | LR: 0.00001013 | TIME: 0:05:21 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0200/1465 | LOSS: 0.11080 (0.09283) | LR: 0.00000990 | TIME: 0:06:43 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0240/1465 | LOSS: 0.10052 (0.09114) | LR: 0.00000967 | TIME: 0:08:01 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0280/1465 | LOSS: 0.07078 (0.09131) | LR: 0.00000944 | TIME: 0:09:23 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0320/1465 | LOSS: 0.08421 (0.09034) | LR: 0.00000921 | TIME: 0:10:43 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0360/1465 | LOSS: 0.24736 (0.08996) | LR: 0.00000898 | TIME: 0:12:09 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0400/1465 | LOSS: 0.14573 (0.08961) | LR: 0.00000876 | TIME: 0:13:26 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0440/1465 | LOSS: 0.11312 (0.08924) | LR: 0.00000853 | TIME: 0:14:40 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0480/1465 | LOSS: 0.06169 (0.08795) | LR: 0.00000830 | TIME: 0:15:57 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0520/1465 | LOSS: 0.05361 (0.08798) | LR: 0.00000808 | TIME: 0:17:14 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0560/1465 | LOSS: 0.09242 (0.08772) | LR: 0.00000786 | TIME: 0:18:32 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0600/1465 | LOSS: 0.09091 (0.08808) | LR: 0.00000763 | TIME: 0:19:47 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0640/1465 | LOSS: 0.13398 (0.08898) | LR: 0.00000741 | TIME: 0:21:08 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0680/1465 | LOSS: 0.07442 (0.08888) | LR: 0.00000719 | TIME: 0:22:29 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0720/1465 | LOSS: 0.03655 (0.08922) | LR: 0.00000697 | TIME: 0:23:44 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0760/1465 | LOSS: 0.11523 (0.08916) | LR: 0.00000675 | TIME: 0:25:00 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0800/1465 | LOSS: 0.06944 (0.08971) | LR: 0.00000654 | TIME: 0:26:25 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0840/1465 | LOSS: 0.06349 (0.08995) | LR: 0.00000633 | TIME: 0:27:39 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0880/1465 | LOSS: 0.05613 (0.09015) | LR: 0.00000611 | TIME: 0:29:00 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0920/1465 | LOSS: 0.10624 (0.08978) | LR: 0.00000590 | TIME: 0:30:22 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0960/1465 | LOSS: 0.07456 (0.08948) | LR: 0.00000570 | TIME: 0:31:42 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1000/1465 | LOSS: 0.05727 (0.08984) | LR: 0.00000549 | TIME: 0:33:03 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1040/1465 | LOSS: 0.04756 (0.08937) | LR: 0.00000529 | TIME: 0:34:19 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1080/1465 | LOSS: 0.05014 (0.08924) | LR: 0.00000509 | TIME: 0:35:36 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1120/1465 | LOSS: 0.07105 (0.08910) | LR: 0.00000489 | TIME: 0:36:49 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1160/1465 | LOSS: 0.15734 (0.08863) | LR: 0.00000469 | TIME: 0:37:59 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1200/1465 | LOSS: 0.09589 (0.08850) | LR: 0.00000450 | TIME: 0:39:21 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1240/1465 | LOSS: 0.07845 (0.08847) | LR: 0.00000431 | TIME: 0:40:34 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1280/1465 | LOSS: 0.11788 (0.08802) | LR: 0.00000413 | TIME: 0:41:50 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1320/1465 | LOSS: 0.18151 (0.08810) | LR: 0.00000394 | TIME: 0:43:07 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1360/1465 | LOSS: 0.10398 (0.08784) | LR: 0.00000376 | TIME: 0:44:27 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1400/1465 | LOSS: 0.08767 (0.08784) | LR: 0.00000358 | TIME: 0:45:44 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1440/1465 | LOSS: 0.13021 (0.08759) | LR: 0.00000341 | TIME: 0:46:59 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1464/1465 | LOSS: 0.17017 (0.08773) | LR: 0.00000331 | TIME: 0:47:45 |

VALID_LOOP
[VALID F1] EPOCH: 3/4 | STEP: 000/491 | LOSS: 0.19162 (0.19162) | TIME: 0:00:01 |
[VALID F1] EPOCH: 3/4 | STEP: 040/491 | LOSS: 0.05849 (0.10370) | TIME: 0:00:14 |
[VALID F1] EPOCH: 3/4 | STEP: 080/491 | LOSS: 0.17025 (0.11483) | TIME: 0:00:28 |
[VALID F1] EPOCH: 3/4 | STEP: 120/491 | LOSS: 0.12245 (0.10615) | TIME: 0:00:42 |
[VALID F1] EPOCH: 3/4 | STEP: 160/491 | LOSS: 0.08252 (0.10700) | TIME: 0:00:55 |
[VALID F1] EPOCH: 3/4 | STEP: 200/491 | LOSS: 0.06643 (0.10386) | TIME: 0:01:09 |
[VALID F1] EPOCH: 3/4 | STEP: 240/491 | LOSS: 0.07739 (0.10496) | TIME: 0:01:22 |
[VALID F1] EPOCH: 3/4 | STEP: 280/491 | LOSS: 0.14316 (0.10348) | TIME: 0:01:36 |
[VALID F1] EPOCH: 3/4 | STEP: 320/491 | LOSS: 0.06100 (0.10388) | TIME: 0:01:50 |
[VALID F1] EPOCH: 3/4 | STEP: 360/491 | LOSS: 0.04427 (0.10361) | TIME: 0:02:03 |
[VALID F1] EPOCH: 3/4 | STEP: 400/491 | LOSS: 0.07600 (0.10461) | TIME: 0:02:17 |
[VALID F1] EPOCH: 3/4 | STEP: 440/491 | LOSS: 0.06176 (0.10570) | TIME: 0:02:30 |
[VALID F1] EPOCH: 3/4 | STEP: 480/491 | LOSS: 0.05195 (0.10654) | TIME: 0:02:44 |
[VALID F1] EPOCH: 3/4 | STEP: 490/491 | LOSS: 0.04766 (0.10601) | TIME: 0:02:47 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.08773 |      0.10601 |  0.46143 | 0.484 | 0.461 | 0.418 | 0.467 | 0.485 | 0.453 | 0:50:33 |


[SAVED] EPOCH: 3 | MCRMSE: 0.4614303410053253

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 4/4 | STEP: 0000/1465 | LOSS: 0.12464 (0.12464) | LR: 0.00000330 | TIME: 0:00:03 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0040/1465 | LOSS: 0.07894 (0.08156) | LR: 0.00000314 | TIME: 0:01:22 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0080/1465 | LOSS: 0.14069 (0.07548) | LR: 0.00000297 | TIME: 0:02:39 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0120/1465 | LOSS: 0.05556 (0.07457) | LR: 0.00000281 | TIME: 0:03:59 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0160/1465 | LOSS: 0.04128 (0.07255) | LR: 0.00000265 | TIME: 0:05:18 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0200/1465 | LOSS: 0.05642 (0.07167) | LR: 0.00000250 | TIME: 0:06:33 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0240/1465 | LOSS: 0.05319 (0.07139) | LR: 0.00000235 | TIME: 0:07:54 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0280/1465 | LOSS: 0.13705 (0.07077) | LR: 0.00000221 | TIME: 0:09:18 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0320/1465 | LOSS: 0.04387 (0.07001) | LR: 0.00000206 | TIME: 0:10:35 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0360/1465 | LOSS: 0.07017 (0.07100) | LR: 0.00000193 | TIME: 0:11:48 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0400/1465 | LOSS: 0.07411 (0.07203) | LR: 0.00000179 | TIME: 0:13:10 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0440/1465 | LOSS: 0.03595 (0.07229) | LR: 0.00000167 | TIME: 0:14:28 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0480/1465 | LOSS: 0.08703 (0.07194) | LR: 0.00000154 | TIME: 0:15:44 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0520/1465 | LOSS: 0.05309 (0.07225) | LR: 0.00000142 | TIME: 0:17:03 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0560/1465 | LOSS: 0.06553 (0.07207) | LR: 0.00000131 | TIME: 0:18:22 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0600/1465 | LOSS: 0.08355 (0.07190) | LR: 0.00000120 | TIME: 0:19:41 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0640/1465 | LOSS: 0.07639 (0.07170) | LR: 0.00000109 | TIME: 0:20:58 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0680/1465 | LOSS: 0.07086 (0.07159) | LR: 0.00000099 | TIME: 0:22:08 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0720/1465 | LOSS: 0.09503 (0.07133) | LR: 0.00000089 | TIME: 0:23:26 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0760/1465 | LOSS: 0.08926 (0.07161) | LR: 0.00000080 | TIME: 0:24:45 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0800/1465 | LOSS: 0.06087 (0.07154) | LR: 0.00000071 | TIME: 0:26:01 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0840/1465 | LOSS: 0.04453 (0.07176) | LR: 0.00000063 | TIME: 0:27:29 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0880/1465 | LOSS: 0.10582 (0.07159) | LR: 0.00000055 | TIME: 0:28:45 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0920/1465 | LOSS: 0.04927 (0.07177) | LR: 0.00000048 | TIME: 0:30:09 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0960/1465 | LOSS: 0.05729 (0.07140) | LR: 0.00000041 | TIME: 0:31:27 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1000/1465 | LOSS: 0.12804 (0.07133) | LR: 0.00000035 | TIME: 0:32:42 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1040/1465 | LOSS: 0.07303 (0.07155) | LR: 0.00000029 | TIME: 0:34:02 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1080/1465 | LOSS: 0.13384 (0.07140) | LR: 0.00000024 | TIME: 0:35:09 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1120/1465 | LOSS: 0.08512 (0.07116) | LR: 0.00000019 | TIME: 0:36:25 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1160/1465 | LOSS: 0.10678 (0.07077) | LR: 0.00000015 | TIME: 0:37:43 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1200/1465 | LOSS: 0.08334 (0.07054) | LR: 0.00000011 | TIME: 0:38:59 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1240/1465 | LOSS: 0.19392 (0.07102) | LR: 0.00000008 | TIME: 0:40:25 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1280/1465 | LOSS: 0.13770 (0.07104) | LR: 0.00000006 | TIME: 0:41:43 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1320/1465 | LOSS: 0.06884 (0.07104) | LR: 0.00000003 | TIME: 0:42:59 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1360/1465 | LOSS: 0.04188 (0.07087) | LR: 0.00000002 | TIME: 0:44:16 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1400/1465 | LOSS: 0.04067 (0.07070) | LR: 0.00000001 | TIME: 0:45:34 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1440/1465 | LOSS: 0.07192 (0.07085) | LR: 0.00000000 | TIME: 0:46:50 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1464/1465 | LOSS: 0.07040 (0.07081) | LR: 0.00000000 | TIME: 0:47:35 |

VALID_LOOP
[VALID F1] EPOCH: 4/4 | STEP: 000/491 | LOSS: 0.19168 (0.19168) | TIME: 0:00:01 |
[VALID F1] EPOCH: 4/4 | STEP: 040/491 | LOSS: 0.06394 (0.10422) | TIME: 0:00:14 |
[VALID F1] EPOCH: 4/4 | STEP: 080/491 | LOSS: 0.15753 (0.11362) | TIME: 0:00:28 |
[VALID F1] EPOCH: 4/4 | STEP: 120/491 | LOSS: 0.14574 (0.10580) | TIME: 0:00:42 |
[VALID F1] EPOCH: 4/4 | STEP: 160/491 | LOSS: 0.08590 (0.10675) | TIME: 0:00:55 |
[VALID F1] EPOCH: 4/4 | STEP: 200/491 | LOSS: 0.06691 (0.10277) | TIME: 0:01:09 |
[VALID F1] EPOCH: 4/4 | STEP: 240/491 | LOSS: 0.06952 (0.10389) | TIME: 0:01:22 |
[VALID F1] EPOCH: 4/4 | STEP: 280/491 | LOSS: 0.14908 (0.10234) | TIME: 0:01:36 |
[VALID F1] EPOCH: 4/4 | STEP: 320/491 | LOSS: 0.05375 (0.10224) | TIME: 0:01:50 |
[VALID F1] EPOCH: 4/4 | STEP: 360/491 | LOSS: 0.05587 (0.10198) | TIME: 0:02:03 |
[VALID F1] EPOCH: 4/4 | STEP: 400/491 | LOSS: 0.07270 (0.10269) | TIME: 0:02:17 |
[VALID F1] EPOCH: 4/4 | STEP: 440/491 | LOSS: 0.06329 (0.10354) | TIME: 0:02:30 |
[VALID F1] EPOCH: 4/4 | STEP: 480/491 | LOSS: 0.05695 (0.10448) | TIME: 0:02:44 |
[VALID F1] EPOCH: 4/4 | STEP: 490/491 | LOSS: 0.03939 (0.10396) | TIME: 0:02:47 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.07081 |      0.10396 |  0.45694 | 0.479 | 0.449 | 0.418 | 0.468 | 0.474 | 0.453 | 0:50:23 |


[SAVED] EPOCH: 4 | MCRMSE: 0.45693734288215637


----------------------------------- FOLD 1 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.45694     0.47929   0.44902       0.41786        0.46801    0.47412        0.45333

################################### END OF FOlD 1 ###################################


Date: 2022-11-27 13:11:26.153430+07:00 (GMT+7)
Mode: CV_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: microsoft/deberta-v3-large
Model_config: DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0.0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.20.1",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Pooling_strategy: concat_attn_mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 367, 'num_training_steps': 5876}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 768

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 1/4 | STEP: 0000/1469 | LOSS: 1.95832 (1.95832) | LR: 0.00000005 | TIME: 0:00:04 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0040/1469 | LOSS: 1.97350 (2.35730) | LR: 0.00000223 | TIME: 0:01:21 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0080/1469 | LOSS: 0.31123 (1.74779) | LR: 0.00000441 | TIME: 0:02:40 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0120/1469 | LOSS: 0.33923 (1.25849) | LR: 0.00000659 | TIME: 0:03:58 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0160/1469 | LOSS: 0.08866 (0.99208) | LR: 0.00000877 | TIME: 0:05:12 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0200/1469 | LOSS: 0.28022 (0.83063) | LR: 0.00001095 | TIME: 0:06:35 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0240/1469 | LOSS: 0.12836 (0.72073) | LR: 0.00001313 | TIME: 0:07:56 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0280/1469 | LOSS: 0.16247 (0.64025) | LR: 0.00001531 | TIME: 0:09:14 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0320/1469 | LOSS: 0.09330 (0.57914) | LR: 0.00001749 | TIME: 0:10:34 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0360/1469 | LOSS: 0.08115 (0.53139) | LR: 0.00001967 | TIME: 0:11:56 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0400/1469 | LOSS: 0.06376 (0.49341) | LR: 0.00002000 | TIME: 0:13:17 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0440/1469 | LOSS: 0.12581 (0.46256) | LR: 0.00001999 | TIME: 0:14:40 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0480/1469 | LOSS: 0.08766 (0.43547) | LR: 0.00001998 | TIME: 0:15:55 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0520/1469 | LOSS: 0.17469 (0.41188) | LR: 0.00001996 | TIME: 0:17:08 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0560/1469 | LOSS: 0.07593 (0.39275) | LR: 0.00001994 | TIME: 0:18:26 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0600/1469 | LOSS: 0.19243 (0.37665) | LR: 0.00001991 | TIME: 0:19:45 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0640/1469 | LOSS: 0.14339 (0.36234) | LR: 0.00001988 | TIME: 0:21:01 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0680/1469 | LOSS: 0.06978 (0.34923) | LR: 0.00001984 | TIME: 0:22:17 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0720/1469 | LOSS: 0.15842 (0.33748) | LR: 0.00001980 | TIME: 0:23:37 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0760/1469 | LOSS: 0.07331 (0.32619) | LR: 0.00001975 | TIME: 0:24:53 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0800/1469 | LOSS: 0.10060 (0.31727) | LR: 0.00001970 | TIME: 0:26:12 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0840/1469 | LOSS: 0.13095 (0.30807) | LR: 0.00001964 | TIME: 0:27:40 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0880/1469 | LOSS: 0.06496 (0.30023) | LR: 0.00001957 | TIME: 0:29:00 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0920/1469 | LOSS: 0.14303 (0.29336) | LR: 0.00001951 | TIME: 0:30:17 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0960/1469 | LOSS: 0.13981 (0.28654) | LR: 0.00001943 | TIME: 0:31:33 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1000/1469 | LOSS: 0.07347 (0.27995) | LR: 0.00001935 | TIME: 0:32:53 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1040/1469 | LOSS: 0.10982 (0.27378) | LR: 0.00001927 | TIME: 0:34:14 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1080/1469 | LOSS: 0.07375 (0.26912) | LR: 0.00001918 | TIME: 0:35:35 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1120/1469 | LOSS: 0.22260 (0.26431) | LR: 0.00001909 | TIME: 0:36:51 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1160/1469 | LOSS: 0.24546 (0.25963) | LR: 0.00001899 | TIME: 0:38:10 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1200/1469 | LOSS: 0.10668 (0.25556) | LR: 0.00001889 | TIME: 0:39:23 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1240/1469 | LOSS: 0.07425 (0.25180) | LR: 0.00001878 | TIME: 0:40:35 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1280/1469 | LOSS: 0.07281 (0.24869) | LR: 0.00001867 | TIME: 0:42:02 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1320/1469 | LOSS: 0.16949 (0.24551) | LR: 0.00001856 | TIME: 0:43:24 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1360/1469 | LOSS: 0.09628 (0.24256) | LR: 0.00001844 | TIME: 0:44:42 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1400/1469 | LOSS: 0.12123 (0.23924) | LR: 0.00001831 | TIME: 0:45:59 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1440/1469 | LOSS: 0.15902 (0.23619) | LR: 0.00001818 | TIME: 0:47:14 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1468/1469 | LOSS: 0.07874 (0.23465) | LR: 0.00001809 | TIME: 0:48:08 |

VALID_LOOP
[VALID F2] EPOCH: 1/4 | STEP: 000/486 | LOSS: 0.09576 (0.09576) | TIME: 0:00:01 |
[VALID F2] EPOCH: 1/4 | STEP: 040/486 | LOSS: 0.13431 (0.12161) | TIME: 0:00:14 |
[VALID F2] EPOCH: 1/4 | STEP: 080/486 | LOSS: 0.12435 (0.11818) | TIME: 0:00:28 |
[VALID F2] EPOCH: 1/4 | STEP: 120/486 | LOSS: 0.11345 (0.11699) | TIME: 0:00:42 |
[VALID F2] EPOCH: 1/4 | STEP: 160/486 | LOSS: 0.06038 (0.11966) | TIME: 0:00:55 |
[VALID F2] EPOCH: 1/4 | STEP: 200/486 | LOSS: 0.07801 (0.11726) | TIME: 0:01:09 |
[VALID F2] EPOCH: 1/4 | STEP: 240/486 | LOSS: 0.09262 (0.11832) | TIME: 0:01:23 |
[VALID F2] EPOCH: 1/4 | STEP: 280/486 | LOSS: 0.14019 (0.11819) | TIME: 0:01:36 |
[VALID F2] EPOCH: 1/4 | STEP: 320/486 | LOSS: 0.10332 (0.11810) | TIME: 0:01:50 |
[VALID F2] EPOCH: 1/4 | STEP: 360/486 | LOSS: 0.10529 (0.11754) | TIME: 0:02:04 |
[VALID F2] EPOCH: 1/4 | STEP: 400/486 | LOSS: 0.10458 (0.11708) | TIME: 0:02:17 |
[VALID F2] EPOCH: 1/4 | STEP: 440/486 | LOSS: 0.13150 (0.11713) | TIME: 0:02:31 |
[VALID F2] EPOCH: 1/4 | STEP: 480/486 | LOSS: 0.12544 (0.11725) | TIME: 0:02:45 |
[VALID F2] EPOCH: 1/4 | STEP: 485/486 | LOSS: 0.08944 (0.11730) | TIME: 0:02:46 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.23465 |       0.1173 |  0.48362 | 0.582 | 0.499 | 0.423 | 0.454 | 0.485 | 0.459 | 0:50:55 |


[SAVED] EPOCH: 1 | MCRMSE: 0.4836219549179077

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 2/4 | STEP: 0000/1469 | LOSS: 0.04712 (0.04712) | LR: 0.00001809 | TIME: 0:00:02 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0040/1469 | LOSS: 0.12241 (0.14223) | LR: 0.00001795 | TIME: 0:01:24 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0080/1469 | LOSS: 0.27672 (0.12911) | LR: 0.00001781 | TIME: 0:02:44 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0120/1469 | LOSS: 0.24094 (0.12917) | LR: 0.00001766 | TIME: 0:04:01 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0160/1469 | LOSS: 0.12154 (0.12356) | LR: 0.00001752 | TIME: 0:05:14 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0200/1469 | LOSS: 0.08723 (0.12466) | LR: 0.00001736 | TIME: 0:06:32 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0240/1469 | LOSS: 0.05573 (0.12198) | LR: 0.00001721 | TIME: 0:07:54 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0280/1469 | LOSS: 0.02480 (0.11879) | LR: 0.00001705 | TIME: 0:09:14 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0320/1469 | LOSS: 0.14081 (0.11817) | LR: 0.00001688 | TIME: 0:10:33 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0360/1469 | LOSS: 0.09332 (0.11908) | LR: 0.00001672 | TIME: 0:11:55 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0400/1469 | LOSS: 0.05702 (0.12049) | LR: 0.00001655 | TIME: 0:13:14 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0440/1469 | LOSS: 0.12485 (0.12006) | LR: 0.00001637 | TIME: 0:14:27 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0480/1469 | LOSS: 0.07416 (0.11844) | LR: 0.00001619 | TIME: 0:15:43 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0520/1469 | LOSS: 0.11786 (0.11817) | LR: 0.00001601 | TIME: 0:17:05 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0560/1469 | LOSS: 0.07674 (0.11685) | LR: 0.00001583 | TIME: 0:18:16 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0600/1469 | LOSS: 0.11420 (0.11713) | LR: 0.00001564 | TIME: 0:19:29 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0640/1469 | LOSS: 0.16769 (0.11698) | LR: 0.00001545 | TIME: 0:20:52 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0680/1469 | LOSS: 0.09240 (0.11630) | LR: 0.00001526 | TIME: 0:22:07 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0720/1469 | LOSS: 0.12405 (0.11587) | LR: 0.00001507 | TIME: 0:23:25 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0760/1469 | LOSS: 0.16518 (0.11664) | LR: 0.00001487 | TIME: 0:24:46 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0800/1469 | LOSS: 0.04027 (0.11657) | LR: 0.00001467 | TIME: 0:26:04 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0840/1469 | LOSS: 0.11505 (0.11698) | LR: 0.00001446 | TIME: 0:27:20 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0880/1469 | LOSS: 0.09080 (0.11595) | LR: 0.00001426 | TIME: 0:28:38 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0920/1469 | LOSS: 0.13752 (0.11660) | LR: 0.00001405 | TIME: 0:29:55 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0960/1469 | LOSS: 0.09286 (0.11679) | LR: 0.00001384 | TIME: 0:31:12 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1000/1469 | LOSS: 0.12763 (0.11724) | LR: 0.00001363 | TIME: 0:32:30 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1040/1469 | LOSS: 0.09027 (0.11711) | LR: 0.00001342 | TIME: 0:33:51 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1080/1469 | LOSS: 0.13850 (0.11698) | LR: 0.00001320 | TIME: 0:35:11 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1120/1469 | LOSS: 0.16529 (0.11682) | LR: 0.00001298 | TIME: 0:36:35 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1160/1469 | LOSS: 0.04416 (0.11651) | LR: 0.00001277 | TIME: 0:37:55 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1200/1469 | LOSS: 0.16336 (0.11585) | LR: 0.00001255 | TIME: 0:39:15 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1240/1469 | LOSS: 0.08372 (0.11560) | LR: 0.00001233 | TIME: 0:40:35 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1280/1469 | LOSS: 0.08060 (0.11521) | LR: 0.00001210 | TIME: 0:41:54 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1320/1469 | LOSS: 0.12888 (0.11486) | LR: 0.00001188 | TIME: 0:43:18 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1360/1469 | LOSS: 0.05982 (0.11457) | LR: 0.00001165 | TIME: 0:44:38 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1400/1469 | LOSS: 0.06789 (0.11455) | LR: 0.00001143 | TIME: 0:45:52 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1440/1469 | LOSS: 0.12680 (0.11403) | LR: 0.00001120 | TIME: 0:47:11 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1468/1469 | LOSS: 0.20581 (0.11389) | LR: 0.00001104 | TIME: 0:48:05 |

VALID_LOOP
[VALID F2] EPOCH: 2/4 | STEP: 000/486 | LOSS: 0.08433 (0.08433) | TIME: 0:00:01 |
[VALID F2] EPOCH: 2/4 | STEP: 040/486 | LOSS: 0.12495 (0.10845) | TIME: 0:00:14 |
[VALID F2] EPOCH: 2/4 | STEP: 080/486 | LOSS: 0.07950 (0.10780) | TIME: 0:00:28 |
[VALID F2] EPOCH: 2/4 | STEP: 120/486 | LOSS: 0.12917 (0.10792) | TIME: 0:00:42 |
[VALID F2] EPOCH: 2/4 | STEP: 160/486 | LOSS: 0.06313 (0.11240) | TIME: 0:00:55 |
[VALID F2] EPOCH: 2/4 | STEP: 200/486 | LOSS: 0.07043 (0.10953) | TIME: 0:01:09 |
[VALID F2] EPOCH: 2/4 | STEP: 240/486 | LOSS: 0.06623 (0.11029) | TIME: 0:01:23 |
[VALID F2] EPOCH: 2/4 | STEP: 280/486 | LOSS: 0.12202 (0.10949) | TIME: 0:01:36 |
[VALID F2] EPOCH: 2/4 | STEP: 320/486 | LOSS: 0.08995 (0.10939) | TIME: 0:01:50 |
[VALID F2] EPOCH: 2/4 | STEP: 360/486 | LOSS: 0.09221 (0.10798) | TIME: 0:02:04 |
[VALID F2] EPOCH: 2/4 | STEP: 400/486 | LOSS: 0.08570 (0.10733) | TIME: 0:02:17 |
[VALID F2] EPOCH: 2/4 | STEP: 440/486 | LOSS: 0.10432 (0.10739) | TIME: 0:02:31 |
[VALID F2] EPOCH: 2/4 | STEP: 480/486 | LOSS: 0.09237 (0.10733) | TIME: 0:02:45 |
[VALID F2] EPOCH: 2/4 | STEP: 485/486 | LOSS: 0.08144 (0.10730) | TIME: 0:02:46 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11389 |       0.1073 |  0.46416 | 0.480 | 0.457 | 0.437 | 0.475 | 0.472 | 0.464 | 0:50:52 |


[SAVED] EPOCH: 2 | MCRMSE: 0.4641590416431427

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 3/4 | STEP: 0000/1469 | LOSS: 0.06873 (0.06873) | LR: 0.00001104 | TIME: 0:00:02 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0040/1469 | LOSS: 0.07904 (0.08590) | LR: 0.00001081 | TIME: 0:01:22 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0080/1469 | LOSS: 0.04521 (0.08565) | LR: 0.00001058 | TIME: 0:02:43 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0120/1469 | LOSS: 0.15052 (0.08664) | LR: 0.00001036 | TIME: 0:04:03 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0160/1469 | LOSS: 0.09839 (0.08844) | LR: 0.00001013 | TIME: 0:05:21 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0200/1469 | LOSS: 0.09315 (0.09111) | LR: 0.00000990 | TIME: 0:06:41 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0240/1469 | LOSS: 0.17323 (0.09384) | LR: 0.00000967 | TIME: 0:08:01 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0280/1469 | LOSS: 0.06399 (0.09226) | LR: 0.00000944 | TIME: 0:09:21 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0320/1469 | LOSS: 0.07617 (0.09184) | LR: 0.00000922 | TIME: 0:10:42 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0360/1469 | LOSS: 0.10134 (0.09134) | LR: 0.00000899 | TIME: 0:12:03 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0400/1469 | LOSS: 0.05104 (0.09191) | LR: 0.00000876 | TIME: 0:13:22 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0440/1469 | LOSS: 0.06827 (0.09090) | LR: 0.00000854 | TIME: 0:14:38 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0480/1469 | LOSS: 0.16058 (0.09081) | LR: 0.00000831 | TIME: 0:15:54 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0520/1469 | LOSS: 0.04242 (0.09155) | LR: 0.00000809 | TIME: 0:17:15 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0560/1469 | LOSS: 0.07108 (0.09071) | LR: 0.00000786 | TIME: 0:18:32 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0600/1469 | LOSS: 0.08613 (0.09143) | LR: 0.00000764 | TIME: 0:19:51 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0640/1469 | LOSS: 0.09672 (0.09091) | LR: 0.00000742 | TIME: 0:21:09 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0680/1469 | LOSS: 0.04051 (0.09183) | LR: 0.00000720 | TIME: 0:22:25 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0720/1469 | LOSS: 0.18865 (0.09193) | LR: 0.00000698 | TIME: 0:23:45 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0760/1469 | LOSS: 0.06155 (0.09170) | LR: 0.00000677 | TIME: 0:25:03 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0800/1469 | LOSS: 0.10817 (0.09178) | LR: 0.00000655 | TIME: 0:26:21 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0840/1469 | LOSS: 0.05345 (0.09157) | LR: 0.00000634 | TIME: 0:27:39 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0880/1469 | LOSS: 0.09517 (0.09092) | LR: 0.00000613 | TIME: 0:28:54 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0920/1469 | LOSS: 0.07961 (0.09048) | LR: 0.00000592 | TIME: 0:30:11 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0960/1469 | LOSS: 0.06375 (0.09023) | LR: 0.00000571 | TIME: 0:31:31 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1000/1469 | LOSS: 0.03749 (0.09007) | LR: 0.00000551 | TIME: 0:32:49 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1040/1469 | LOSS: 0.04039 (0.08970) | LR: 0.00000530 | TIME: 0:34:09 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1080/1469 | LOSS: 0.09734 (0.08961) | LR: 0.00000510 | TIME: 0:35:30 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1120/1469 | LOSS: 0.05922 (0.08957) | LR: 0.00000490 | TIME: 0:36:48 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1160/1469 | LOSS: 0.08236 (0.08947) | LR: 0.00000471 | TIME: 0:38:06 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1200/1469 | LOSS: 0.12791 (0.08907) | LR: 0.00000452 | TIME: 0:39:22 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1240/1469 | LOSS: 0.15704 (0.08914) | LR: 0.00000433 | TIME: 0:40:39 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1280/1469 | LOSS: 0.06459 (0.08890) | LR: 0.00000414 | TIME: 0:42:02 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1320/1469 | LOSS: 0.20485 (0.08931) | LR: 0.00000396 | TIME: 0:43:18 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1360/1469 | LOSS: 0.09330 (0.08926) | LR: 0.00000378 | TIME: 0:44:40 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1400/1469 | LOSS: 0.03981 (0.08918) | LR: 0.00000360 | TIME: 0:46:04 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1440/1469 | LOSS: 0.04630 (0.08913) | LR: 0.00000343 | TIME: 0:47:16 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1468/1469 | LOSS: 0.06585 (0.08914) | LR: 0.00000331 | TIME: 0:48:08 |

VALID_LOOP
[VALID F2] EPOCH: 3/4 | STEP: 000/486 | LOSS: 0.06785 (0.06785) | TIME: 0:00:01 |
[VALID F2] EPOCH: 3/4 | STEP: 040/486 | LOSS: 0.11993 (0.10544) | TIME: 0:00:14 |
[VALID F2] EPOCH: 3/4 | STEP: 080/486 | LOSS: 0.09106 (0.10483) | TIME: 0:00:28 |
[VALID F2] EPOCH: 3/4 | STEP: 120/486 | LOSS: 0.12895 (0.10465) | TIME: 0:00:42 |
[VALID F2] EPOCH: 3/4 | STEP: 160/486 | LOSS: 0.06515 (0.10787) | TIME: 0:00:55 |
[VALID F2] EPOCH: 3/4 | STEP: 200/486 | LOSS: 0.06663 (0.10470) | TIME: 0:01:09 |
[VALID F2] EPOCH: 3/4 | STEP: 240/486 | LOSS: 0.04344 (0.10509) | TIME: 0:01:23 |
[VALID F2] EPOCH: 3/4 | STEP: 280/486 | LOSS: 0.11100 (0.10384) | TIME: 0:01:36 |
[VALID F2] EPOCH: 3/4 | STEP: 320/486 | LOSS: 0.06016 (0.10405) | TIME: 0:01:50 |
[VALID F2] EPOCH: 3/4 | STEP: 360/486 | LOSS: 0.08915 (0.10276) | TIME: 0:02:04 |
[VALID F2] EPOCH: 3/4 | STEP: 400/486 | LOSS: 0.06918 (0.10249) | TIME: 0:02:17 |
[VALID F2] EPOCH: 3/4 | STEP: 440/486 | LOSS: 0.09877 (0.10266) | TIME: 0:02:31 |
[VALID F2] EPOCH: 3/4 | STEP: 480/486 | LOSS: 0.07461 (0.10256) | TIME: 0:02:45 |
[VALID F2] EPOCH: 3/4 | STEP: 485/486 | LOSS: 0.05431 (0.10244) | TIME: 0:02:46 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.08914 |      0.10244 |  0.45307 | 0.471 | 0.471 | 0.419 | 0.444 | 0.480 | 0.434 | 0:50:55 |


[SAVED] EPOCH: 3 | MCRMSE: 0.4530709683895111

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 4/4 | STEP: 0000/1469 | LOSS: 0.11243 (0.11243) | LR: 0.00000330 | TIME: 0:00:03 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0040/1469 | LOSS: 0.07030 (0.07425) | LR: 0.00000314 | TIME: 0:01:22 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0080/1469 | LOSS: 0.03644 (0.06683) | LR: 0.00000297 | TIME: 0:02:36 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0120/1469 | LOSS: 0.06384 (0.06959) | LR: 0.00000281 | TIME: 0:03:49 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0160/1469 | LOSS: 0.05146 (0.07124) | LR: 0.00000266 | TIME: 0:05:05 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0200/1469 | LOSS: 0.07693 (0.07274) | LR: 0.00000250 | TIME: 0:06:18 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0240/1469 | LOSS: 0.06956 (0.07195) | LR: 0.00000235 | TIME: 0:07:35 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0280/1469 | LOSS: 0.06171 (0.07154) | LR: 0.00000221 | TIME: 0:08:53 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0320/1469 | LOSS: 0.05571 (0.07157) | LR: 0.00000207 | TIME: 0:10:09 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0360/1469 | LOSS: 0.04139 (0.07062) | LR: 0.00000193 | TIME: 0:11:26 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0400/1469 | LOSS: 0.05977 (0.07024) | LR: 0.00000180 | TIME: 0:12:47 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0440/1469 | LOSS: 0.05338 (0.07016) | LR: 0.00000167 | TIME: 0:14:05 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0480/1469 | LOSS: 0.05945 (0.06965) | LR: 0.00000155 | TIME: 0:15:25 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0520/1469 | LOSS: 0.08571 (0.07043) | LR: 0.00000143 | TIME: 0:16:52 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0560/1469 | LOSS: 0.10061 (0.07023) | LR: 0.00000131 | TIME: 0:18:07 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0600/1469 | LOSS: 0.11715 (0.07089) | LR: 0.00000120 | TIME: 0:19:25 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0640/1469 | LOSS: 0.10530 (0.07107) | LR: 0.00000109 | TIME: 0:20:46 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0680/1469 | LOSS: 0.22670 (0.07162) | LR: 0.00000099 | TIME: 0:22:02 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0720/1469 | LOSS: 0.08032 (0.07181) | LR: 0.00000090 | TIME: 0:23:21 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0760/1469 | LOSS: 0.08634 (0.07193) | LR: 0.00000080 | TIME: 0:24:41 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0800/1469 | LOSS: 0.02504 (0.07179) | LR: 0.00000072 | TIME: 0:26:06 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0840/1469 | LOSS: 0.02468 (0.07171) | LR: 0.00000063 | TIME: 0:27:26 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0880/1469 | LOSS: 0.02904 (0.07152) | LR: 0.00000056 | TIME: 0:28:45 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0920/1469 | LOSS: 0.02689 (0.07170) | LR: 0.00000048 | TIME: 0:30:01 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0960/1469 | LOSS: 0.05955 (0.07154) | LR: 0.00000042 | TIME: 0:31:21 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1000/1469 | LOSS: 0.09436 (0.07136) | LR: 0.00000035 | TIME: 0:32:41 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1040/1469 | LOSS: 0.03080 (0.07168) | LR: 0.00000030 | TIME: 0:34:00 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1080/1469 | LOSS: 0.04314 (0.07169) | LR: 0.00000024 | TIME: 0:35:19 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1120/1469 | LOSS: 0.10671 (0.07169) | LR: 0.00000020 | TIME: 0:36:41 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1160/1469 | LOSS: 0.02798 (0.07155) | LR: 0.00000015 | TIME: 0:37:57 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1200/1469 | LOSS: 0.09114 (0.07161) | LR: 0.00000012 | TIME: 0:39:21 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1240/1469 | LOSS: 0.05422 (0.07183) | LR: 0.00000008 | TIME: 0:40:34 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1280/1469 | LOSS: 0.03938 (0.07212) | LR: 0.00000006 | TIME: 0:41:53 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1320/1469 | LOSS: 0.03922 (0.07225) | LR: 0.00000004 | TIME: 0:43:14 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1360/1469 | LOSS: 0.06009 (0.07240) | LR: 0.00000002 | TIME: 0:44:32 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1400/1469 | LOSS: 0.04463 (0.07221) | LR: 0.00000001 | TIME: 0:45:49 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1440/1469 | LOSS: 0.06045 (0.07196) | LR: 0.00000000 | TIME: 0:47:09 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1468/1469 | LOSS: 0.06214 (0.07188) | LR: 0.00000000 | TIME: 0:48:04 |

VALID_LOOP
[VALID F2] EPOCH: 4/4 | STEP: 000/486 | LOSS: 0.07085 (0.07085) | TIME: 0:00:01 |
[VALID F2] EPOCH: 4/4 | STEP: 040/486 | LOSS: 0.13089 (0.10358) | TIME: 0:00:14 |
[VALID F2] EPOCH: 4/4 | STEP: 080/486 | LOSS: 0.09506 (0.10311) | TIME: 0:00:28 |
[VALID F2] EPOCH: 4/4 | STEP: 120/486 | LOSS: 0.14894 (0.10346) | TIME: 0:00:42 |
[VALID F2] EPOCH: 4/4 | STEP: 160/486 | LOSS: 0.05372 (0.10594) | TIME: 0:00:55 |
[VALID F2] EPOCH: 4/4 | STEP: 200/486 | LOSS: 0.06269 (0.10318) | TIME: 0:01:09 |
[VALID F2] EPOCH: 4/4 | STEP: 240/486 | LOSS: 0.04050 (0.10367) | TIME: 0:01:23 |
[VALID F2] EPOCH: 4/4 | STEP: 280/486 | LOSS: 0.11207 (0.10226) | TIME: 0:01:36 |
[VALID F2] EPOCH: 4/4 | STEP: 320/486 | LOSS: 0.05151 (0.10227) | TIME: 0:01:50 |
[VALID F2] EPOCH: 4/4 | STEP: 360/486 | LOSS: 0.07667 (0.10092) | TIME: 0:02:04 |
[VALID F2] EPOCH: 4/4 | STEP: 400/486 | LOSS: 0.08539 (0.10043) | TIME: 0:02:17 |
[VALID F2] EPOCH: 4/4 | STEP: 440/486 | LOSS: 0.08530 (0.10084) | TIME: 0:02:31 |
[VALID F2] EPOCH: 4/4 | STEP: 480/486 | LOSS: 0.05189 (0.10038) | TIME: 0:02:45 |
[VALID F2] EPOCH: 4/4 | STEP: 485/486 | LOSS: 0.06356 (0.10021) | TIME: 0:02:46 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.07188 |      0.10021 |   0.4481 | 0.471 | 0.452 | 0.412 | 0.443 | 0.475 | 0.435 | 0:50:51 |


[SAVED] EPOCH: 4 | MCRMSE: 0.4480989873409271


----------------------------------- FOLD 2 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
  0.4481     0.47139   0.45193       0.41173        0.44338    0.47518        0.43498

################################### END OF FOlD 2 ###################################


Date: 2022-11-27 16:35:31.264407+07:00 (GMT+7)
Mode: CV_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: microsoft/deberta-v3-large
Model_config: DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0.0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.20.1",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Pooling_strategy: concat_attn_mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 365, 'num_training_steps': 5844}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 768

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 1/4 | STEP: 0000/1461 | LOSS: 2.20284 (2.20284) | LR: 0.00000005 | TIME: 0:00:01 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0040/1461 | LOSS: 2.50411 (2.42984) | LR: 0.00000225 | TIME: 0:01:26 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0080/1461 | LOSS: 0.45568 (1.84025) | LR: 0.00000444 | TIME: 0:02:45 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0120/1461 | LOSS: 0.14117 (1.31198) | LR: 0.00000663 | TIME: 0:04:06 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0160/1461 | LOSS: 0.37852 (1.03355) | LR: 0.00000882 | TIME: 0:05:32 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0200/1461 | LOSS: 0.06252 (0.86233) | LR: 0.00001101 | TIME: 0:06:52 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0240/1461 | LOSS: 0.29664 (0.74335) | LR: 0.00001321 | TIME: 0:08:12 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0280/1461 | LOSS: 0.15919 (0.66108) | LR: 0.00001540 | TIME: 0:09:32 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0320/1461 | LOSS: 0.09533 (0.60088) | LR: 0.00001759 | TIME: 0:10:54 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0360/1461 | LOSS: 0.14095 (0.55064) | LR: 0.00001978 | TIME: 0:12:10 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0400/1461 | LOSS: 0.18696 (0.51069) | LR: 0.00002000 | TIME: 0:13:25 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0440/1461 | LOSS: 0.11811 (0.47797) | LR: 0.00001999 | TIME: 0:14:48 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0480/1461 | LOSS: 0.12620 (0.45183) | LR: 0.00001998 | TIME: 0:16:09 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0520/1461 | LOSS: 0.12755 (0.42917) | LR: 0.00001996 | TIME: 0:17:25 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0560/1461 | LOSS: 0.08239 (0.40974) | LR: 0.00001994 | TIME: 0:18:48 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0600/1461 | LOSS: 0.10621 (0.39192) | LR: 0.00001991 | TIME: 0:20:03 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0640/1461 | LOSS: 0.16593 (0.37575) | LR: 0.00001988 | TIME: 0:21:25 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0680/1461 | LOSS: 0.15285 (0.36202) | LR: 0.00001984 | TIME: 0:22:41 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0720/1461 | LOSS: 0.11179 (0.34912) | LR: 0.00001979 | TIME: 0:24:01 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0760/1461 | LOSS: 0.32338 (0.33846) | LR: 0.00001974 | TIME: 0:25:19 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0800/1461 | LOSS: 0.08420 (0.32859) | LR: 0.00001969 | TIME: 0:26:30 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0840/1461 | LOSS: 0.20583 (0.31898) | LR: 0.00001963 | TIME: 0:27:48 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0880/1461 | LOSS: 0.05443 (0.31051) | LR: 0.00001957 | TIME: 0:29:10 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0920/1461 | LOSS: 0.07895 (0.30388) | LR: 0.00001950 | TIME: 0:30:33 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0960/1461 | LOSS: 0.08118 (0.29742) | LR: 0.00001942 | TIME: 0:31:53 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1000/1461 | LOSS: 0.09062 (0.29071) | LR: 0.00001934 | TIME: 0:33:07 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1040/1461 | LOSS: 0.05731 (0.28509) | LR: 0.00001926 | TIME: 0:34:18 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1080/1461 | LOSS: 0.19793 (0.27990) | LR: 0.00001917 | TIME: 0:35:39 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1120/1461 | LOSS: 0.11690 (0.27447) | LR: 0.00001908 | TIME: 0:36:59 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1160/1461 | LOSS: 0.12110 (0.26936) | LR: 0.00001898 | TIME: 0:38:15 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1200/1461 | LOSS: 0.10947 (0.26481) | LR: 0.00001887 | TIME: 0:39:36 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1240/1461 | LOSS: 0.07635 (0.25997) | LR: 0.00001876 | TIME: 0:40:52 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1280/1461 | LOSS: 0.18627 (0.25585) | LR: 0.00001865 | TIME: 0:42:10 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1320/1461 | LOSS: 0.08093 (0.25239) | LR: 0.00001853 | TIME: 0:43:31 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1360/1461 | LOSS: 0.12427 (0.24908) | LR: 0.00001841 | TIME: 0:44:48 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1400/1461 | LOSS: 0.15571 (0.24551) | LR: 0.00001829 | TIME: 0:46:01 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1440/1461 | LOSS: 0.07139 (0.24221) | LR: 0.00001816 | TIME: 0:47:24 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1460/1461 | LOSS: 0.16384 (0.24058) | LR: 0.00001809 | TIME: 0:48:02 |

VALID_LOOP
[VALID F3] EPOCH: 1/4 | STEP: 000/494 | LOSS: 0.11281 (0.11281) | TIME: 0:00:01 |
[VALID F3] EPOCH: 1/4 | STEP: 040/494 | LOSS: 0.08884 (0.11763) | TIME: 0:00:14 |
[VALID F3] EPOCH: 1/4 | STEP: 080/494 | LOSS: 0.19478 (0.11740) | TIME: 0:00:28 |
[VALID F3] EPOCH: 1/4 | STEP: 120/494 | LOSS: 0.04954 (0.11314) | TIME: 0:00:42 |
[VALID F3] EPOCH: 1/4 | STEP: 160/494 | LOSS: 0.18951 (0.11573) | TIME: 0:00:55 |
[VALID F3] EPOCH: 1/4 | STEP: 200/494 | LOSS: 0.03356 (0.11052) | TIME: 0:01:09 |
[VALID F3] EPOCH: 1/4 | STEP: 240/494 | LOSS: 0.15752 (0.11052) | TIME: 0:01:23 |
[VALID F3] EPOCH: 1/4 | STEP: 280/494 | LOSS: 0.11553 (0.11085) | TIME: 0:01:36 |
[VALID F3] EPOCH: 1/4 | STEP: 320/494 | LOSS: 0.06093 (0.11109) | TIME: 0:01:50 |
[VALID F3] EPOCH: 1/4 | STEP: 360/494 | LOSS: 0.08570 (0.11194) | TIME: 0:02:04 |
[VALID F3] EPOCH: 1/4 | STEP: 400/494 | LOSS: 0.07761 (0.11200) | TIME: 0:02:17 |
[VALID F3] EPOCH: 1/4 | STEP: 440/494 | LOSS: 0.10440 (0.11461) | TIME: 0:02:31 |
[VALID F3] EPOCH: 1/4 | STEP: 480/494 | LOSS: 0.06048 (0.11440) | TIME: 0:02:45 |
[VALID F3] EPOCH: 1/4 | STEP: 493/494 | LOSS: 0.11616 (0.11371) | TIME: 0:02:49 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.24058 |      0.11371 |   0.4779 | 0.523 | 0.447 | 0.438 | 0.467 | 0.480 | 0.512 | 0:50:52 |


[SAVED] EPOCH: 1 | MCRMSE: 0.47789573669433594

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 2/4 | STEP: 0000/1461 | LOSS: 0.05854 (0.05854) | LR: 0.00001809 | TIME: 0:00:02 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0040/1461 | LOSS: 0.10215 (0.10821) | LR: 0.00001795 | TIME: 0:01:14 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0080/1461 | LOSS: 0.07193 (0.11276) | LR: 0.00001781 | TIME: 0:02:31 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0120/1461 | LOSS: 0.44242 (0.11627) | LR: 0.00001766 | TIME: 0:03:51 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0160/1461 | LOSS: 0.11029 (0.11564) | LR: 0.00001751 | TIME: 0:05:02 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0200/1461 | LOSS: 0.07017 (0.11577) | LR: 0.00001736 | TIME: 0:06:27 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0240/1461 | LOSS: 0.08421 (0.11530) | LR: 0.00001720 | TIME: 0:07:45 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0280/1461 | LOSS: 0.09267 (0.11429) | LR: 0.00001704 | TIME: 0:09:06 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0320/1461 | LOSS: 0.15012 (0.11317) | LR: 0.00001688 | TIME: 0:10:23 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0360/1461 | LOSS: 0.08112 (0.11298) | LR: 0.00001671 | TIME: 0:11:46 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0400/1461 | LOSS: 0.04349 (0.11305) | LR: 0.00001654 | TIME: 0:13:05 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0440/1461 | LOSS: 0.06366 (0.11363) | LR: 0.00001636 | TIME: 0:14:26 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0480/1461 | LOSS: 0.09547 (0.11378) | LR: 0.00001618 | TIME: 0:15:44 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0520/1461 | LOSS: 0.08530 (0.11423) | LR: 0.00001600 | TIME: 0:17:01 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0560/1461 | LOSS: 0.12645 (0.11351) | LR: 0.00001582 | TIME: 0:18:21 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0600/1461 | LOSS: 0.08558 (0.11386) | LR: 0.00001563 | TIME: 0:19:37 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0640/1461 | LOSS: 0.08623 (0.11395) | LR: 0.00001544 | TIME: 0:20:56 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0680/1461 | LOSS: 0.04554 (0.11424) | LR: 0.00001524 | TIME: 0:22:21 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0720/1461 | LOSS: 0.05236 (0.11359) | LR: 0.00001505 | TIME: 0:23:43 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0760/1461 | LOSS: 0.18134 (0.11384) | LR: 0.00001485 | TIME: 0:25:00 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0800/1461 | LOSS: 0.06323 (0.11415) | LR: 0.00001465 | TIME: 0:26:19 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0840/1461 | LOSS: 0.09674 (0.11391) | LR: 0.00001444 | TIME: 0:27:34 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0880/1461 | LOSS: 0.09866 (0.11365) | LR: 0.00001423 | TIME: 0:28:41 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0920/1461 | LOSS: 0.06343 (0.11408) | LR: 0.00001403 | TIME: 0:30:04 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0960/1461 | LOSS: 0.14748 (0.11305) | LR: 0.00001381 | TIME: 0:31:20 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1000/1461 | LOSS: 0.01657 (0.11290) | LR: 0.00001360 | TIME: 0:32:39 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1040/1461 | LOSS: 0.05239 (0.11353) | LR: 0.00001339 | TIME: 0:33:56 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1080/1461 | LOSS: 0.15190 (0.11379) | LR: 0.00001317 | TIME: 0:35:07 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1120/1461 | LOSS: 0.07556 (0.11338) | LR: 0.00001295 | TIME: 0:36:27 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1160/1461 | LOSS: 0.13607 (0.11355) | LR: 0.00001273 | TIME: 0:37:44 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1200/1461 | LOSS: 0.11402 (0.11377) | LR: 0.00001251 | TIME: 0:39:05 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1240/1461 | LOSS: 0.07952 (0.11348) | LR: 0.00001229 | TIME: 0:40:24 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1280/1461 | LOSS: 0.11262 (0.11315) | LR: 0.00001206 | TIME: 0:41:48 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1320/1461 | LOSS: 0.07220 (0.11295) | LR: 0.00001184 | TIME: 0:43:06 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1360/1461 | LOSS: 0.14750 (0.11283) | LR: 0.00001161 | TIME: 0:44:26 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1400/1461 | LOSS: 0.12696 (0.11260) | LR: 0.00001139 | TIME: 0:45:40 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1440/1461 | LOSS: 0.17292 (0.11239) | LR: 0.00001116 | TIME: 0:46:59 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1460/1461 | LOSS: 0.07266 (0.11241) | LR: 0.00001104 | TIME: 0:47:41 |

VALID_LOOP
[VALID F3] EPOCH: 2/4 | STEP: 000/494 | LOSS: 0.09116 (0.09116) | TIME: 0:00:01 |
[VALID F3] EPOCH: 2/4 | STEP: 040/494 | LOSS: 0.06560 (0.10605) | TIME: 0:00:15 |
[VALID F3] EPOCH: 2/4 | STEP: 080/494 | LOSS: 0.22480 (0.10973) | TIME: 0:00:28 |
[VALID F3] EPOCH: 2/4 | STEP: 120/494 | LOSS: 0.05217 (0.10591) | TIME: 0:00:42 |
[VALID F3] EPOCH: 2/4 | STEP: 160/494 | LOSS: 0.20286 (0.10862) | TIME: 0:00:56 |
[VALID F3] EPOCH: 2/4 | STEP: 200/494 | LOSS: 0.04852 (0.10563) | TIME: 0:01:09 |
[VALID F3] EPOCH: 2/4 | STEP: 240/494 | LOSS: 0.13202 (0.10609) | TIME: 0:01:23 |
[VALID F3] EPOCH: 2/4 | STEP: 280/494 | LOSS: 0.09742 (0.10613) | TIME: 0:01:37 |
[VALID F3] EPOCH: 2/4 | STEP: 320/494 | LOSS: 0.05653 (0.10669) | TIME: 0:01:50 |
[VALID F3] EPOCH: 2/4 | STEP: 360/494 | LOSS: 0.08514 (0.10688) | TIME: 0:02:04 |
[VALID F3] EPOCH: 2/4 | STEP: 400/494 | LOSS: 0.07397 (0.10707) | TIME: 0:02:18 |
[VALID F3] EPOCH: 2/4 | STEP: 440/494 | LOSS: 0.10266 (0.10927) | TIME: 0:02:31 |
[VALID F3] EPOCH: 2/4 | STEP: 480/494 | LOSS: 0.09381 (0.10901) | TIME: 0:02:45 |
[VALID F3] EPOCH: 2/4 | STEP: 493/494 | LOSS: 0.13329 (0.10854) | TIME: 0:02:49 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11241 |      0.10854 |  0.46724 | 0.493 | 0.472 | 0.448 | 0.462 | 0.474 | 0.454 | 0:50:31 |


[SAVED] EPOCH: 2 | MCRMSE: 0.46723616123199463

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 3/4 | STEP: 0000/1461 | LOSS: 0.14159 (0.14159) | LR: 0.00001104 | TIME: 0:00:03 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0040/1461 | LOSS: 0.06852 (0.08950) | LR: 0.00001081 | TIME: 0:01:17 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0080/1461 | LOSS: 0.07239 (0.09410) | LR: 0.00001058 | TIME: 0:02:35 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0120/1461 | LOSS: 0.01688 (0.08882) | LR: 0.00001035 | TIME: 0:03:50 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0160/1461 | LOSS: 0.05770 (0.08846) | LR: 0.00001012 | TIME: 0:05:07 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0200/1461 | LOSS: 0.11005 (0.08903) | LR: 0.00000989 | TIME: 0:06:30 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0240/1461 | LOSS: 0.04119 (0.09036) | LR: 0.00000966 | TIME: 0:07:51 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0280/1461 | LOSS: 0.06737 (0.09224) | LR: 0.00000944 | TIME: 0:09:10 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0320/1461 | LOSS: 0.09027 (0.09275) | LR: 0.00000921 | TIME: 0:10:29 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0360/1461 | LOSS: 0.13417 (0.09299) | LR: 0.00000898 | TIME: 0:11:46 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0400/1461 | LOSS: 0.10119 (0.09420) | LR: 0.00000875 | TIME: 0:13:11 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0440/1461 | LOSS: 0.05873 (0.09399) | LR: 0.00000852 | TIME: 0:14:31 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0480/1461 | LOSS: 0.04846 (0.09382) | LR: 0.00000830 | TIME: 0:15:48 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0520/1461 | LOSS: 0.16024 (0.09383) | LR: 0.00000807 | TIME: 0:17:08 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0560/1461 | LOSS: 0.11842 (0.09308) | LR: 0.00000785 | TIME: 0:18:21 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0600/1461 | LOSS: 0.07426 (0.09283) | LR: 0.00000762 | TIME: 0:19:37 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0640/1461 | LOSS: 0.05076 (0.09293) | LR: 0.00000740 | TIME: 0:20:59 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0680/1461 | LOSS: 0.08541 (0.09218) | LR: 0.00000718 | TIME: 0:22:23 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0720/1461 | LOSS: 0.05142 (0.09142) | LR: 0.00000696 | TIME: 0:23:38 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0760/1461 | LOSS: 0.12153 (0.09082) | LR: 0.00000674 | TIME: 0:24:57 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0800/1461 | LOSS: 0.07379 (0.09005) | LR: 0.00000653 | TIME: 0:26:11 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0840/1461 | LOSS: 0.04772 (0.09027) | LR: 0.00000631 | TIME: 0:27:25 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0880/1461 | LOSS: 0.08868 (0.08983) | LR: 0.00000610 | TIME: 0:28:48 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0920/1461 | LOSS: 0.08162 (0.08985) | LR: 0.00000589 | TIME: 0:30:08 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0960/1461 | LOSS: 0.05095 (0.08971) | LR: 0.00000568 | TIME: 0:31:23 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1000/1461 | LOSS: 0.05001 (0.08938) | LR: 0.00000548 | TIME: 0:32:45 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1040/1461 | LOSS: 0.07144 (0.08945) | LR: 0.00000527 | TIME: 0:34:06 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1080/1461 | LOSS: 0.11372 (0.08928) | LR: 0.00000507 | TIME: 0:35:29 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1120/1461 | LOSS: 0.04396 (0.08882) | LR: 0.00000487 | TIME: 0:36:43 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1160/1461 | LOSS: 0.17735 (0.08934) | LR: 0.00000468 | TIME: 0:38:08 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1200/1461 | LOSS: 0.02309 (0.08907) | LR: 0.00000449 | TIME: 0:39:29 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1240/1461 | LOSS: 0.07777 (0.08851) | LR: 0.00000430 | TIME: 0:40:47 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1280/1461 | LOSS: 0.12119 (0.08878) | LR: 0.00000411 | TIME: 0:42:01 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1320/1461 | LOSS: 0.07782 (0.08877) | LR: 0.00000393 | TIME: 0:43:25 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1360/1461 | LOSS: 0.08745 (0.08846) | LR: 0.00000375 | TIME: 0:44:40 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1400/1461 | LOSS: 0.08216 (0.08830) | LR: 0.00000357 | TIME: 0:45:54 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1440/1461 | LOSS: 0.17860 (0.08847) | LR: 0.00000339 | TIME: 0:47:12 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1460/1461 | LOSS: 0.05591 (0.08842) | LR: 0.00000331 | TIME: 0:47:52 |

VALID_LOOP
[VALID F3] EPOCH: 3/4 | STEP: 000/494 | LOSS: 0.09848 (0.09848) | TIME: 0:00:01 |
[VALID F3] EPOCH: 3/4 | STEP: 040/494 | LOSS: 0.07517 (0.10390) | TIME: 0:00:14 |
[VALID F3] EPOCH: 3/4 | STEP: 080/494 | LOSS: 0.21676 (0.10517) | TIME: 0:00:28 |
[VALID F3] EPOCH: 3/4 | STEP: 120/494 | LOSS: 0.05151 (0.10161) | TIME: 0:00:42 |
[VALID F3] EPOCH: 3/4 | STEP: 160/494 | LOSS: 0.19914 (0.10352) | TIME: 0:00:55 |
[VALID F3] EPOCH: 3/4 | STEP: 200/494 | LOSS: 0.05541 (0.10149) | TIME: 0:01:09 |
[VALID F3] EPOCH: 3/4 | STEP: 240/494 | LOSS: 0.14297 (0.10245) | TIME: 0:01:23 |
[VALID F3] EPOCH: 3/4 | STEP: 280/494 | LOSS: 0.12971 (0.10326) | TIME: 0:01:36 |
[VALID F3] EPOCH: 3/4 | STEP: 320/494 | LOSS: 0.04952 (0.10343) | TIME: 0:01:50 |
[VALID F3] EPOCH: 3/4 | STEP: 360/494 | LOSS: 0.06443 (0.10367) | TIME: 0:02:04 |
[VALID F3] EPOCH: 3/4 | STEP: 400/494 | LOSS: 0.05363 (0.10366) | TIME: 0:02:17 |
[VALID F3] EPOCH: 3/4 | STEP: 440/494 | LOSS: 0.11252 (0.10552) | TIME: 0:02:31 |
[VALID F3] EPOCH: 3/4 | STEP: 480/494 | LOSS: 0.11336 (0.10512) | TIME: 0:02:45 |
[VALID F3] EPOCH: 3/4 | STEP: 493/494 | LOSS: 0.10556 (0.10466) | TIME: 0:02:49 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.08842 |      0.10466 |  0.45864 | 0.485 | 0.443 | 0.432 | 0.461 | 0.472 | 0.459 | 0:50:41 |


[SAVED] EPOCH: 3 | MCRMSE: 0.4586356580257416

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 4/4 | STEP: 0000/1461 | LOSS: 0.09737 (0.09737) | LR: 0.00000330 | TIME: 0:00:03 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0040/1461 | LOSS: 0.05419 (0.07302) | LR: 0.00000314 | TIME: 0:01:20 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0080/1461 | LOSS: 0.13647 (0.07366) | LR: 0.00000297 | TIME: 0:02:37 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0120/1461 | LOSS: 0.06124 (0.07319) | LR: 0.00000281 | TIME: 0:04:01 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0160/1461 | LOSS: 0.03861 (0.07311) | LR: 0.00000265 | TIME: 0:05:19 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0200/1461 | LOSS: 0.07132 (0.07186) | LR: 0.00000250 | TIME: 0:06:38 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0240/1461 | LOSS: 0.12804 (0.07314) | LR: 0.00000235 | TIME: 0:07:56 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0280/1461 | LOSS: 0.06866 (0.07290) | LR: 0.00000220 | TIME: 0:09:14 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0320/1461 | LOSS: 0.02217 (0.07211) | LR: 0.00000206 | TIME: 0:10:28 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0360/1461 | LOSS: 0.05332 (0.07217) | LR: 0.00000192 | TIME: 0:11:46 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0400/1461 | LOSS: 0.19985 (0.07263) | LR: 0.00000179 | TIME: 0:13:07 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0440/1461 | LOSS: 0.05684 (0.07210) | LR: 0.00000166 | TIME: 0:14:26 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0480/1461 | LOSS: 0.03445 (0.07201) | LR: 0.00000154 | TIME: 0:15:46 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0520/1461 | LOSS: 0.08542 (0.07164) | LR: 0.00000142 | TIME: 0:17:04 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0560/1461 | LOSS: 0.13462 (0.07156) | LR: 0.00000130 | TIME: 0:18:20 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0600/1461 | LOSS: 0.05217 (0.07179) | LR: 0.00000119 | TIME: 0:19:42 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0640/1461 | LOSS: 0.04859 (0.07184) | LR: 0.00000109 | TIME: 0:21:00 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0680/1461 | LOSS: 0.07634 (0.07159) | LR: 0.00000098 | TIME: 0:22:20 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0720/1461 | LOSS: 0.03301 (0.07152) | LR: 0.00000089 | TIME: 0:23:43 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0760/1461 | LOSS: 0.05342 (0.07140) | LR: 0.00000079 | TIME: 0:24:59 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0800/1461 | LOSS: 0.08495 (0.07159) | LR: 0.00000071 | TIME: 0:26:22 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0840/1461 | LOSS: 0.01542 (0.07176) | LR: 0.00000063 | TIME: 0:27:41 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0880/1461 | LOSS: 0.06236 (0.07186) | LR: 0.00000055 | TIME: 0:28:59 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0920/1461 | LOSS: 0.07625 (0.07209) | LR: 0.00000048 | TIME: 0:30:17 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0960/1461 | LOSS: 0.12133 (0.07247) | LR: 0.00000041 | TIME: 0:31:40 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1000/1461 | LOSS: 0.05485 (0.07226) | LR: 0.00000035 | TIME: 0:33:00 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1040/1461 | LOSS: 0.10399 (0.07233) | LR: 0.00000029 | TIME: 0:34:21 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1080/1461 | LOSS: 0.05035 (0.07270) | LR: 0.00000024 | TIME: 0:35:38 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1120/1461 | LOSS: 0.15917 (0.07279) | LR: 0.00000019 | TIME: 0:37:00 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1160/1461 | LOSS: 0.07173 (0.07263) | LR: 0.00000015 | TIME: 0:38:17 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1200/1461 | LOSS: 0.13658 (0.07278) | LR: 0.00000011 | TIME: 0:39:35 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1240/1461 | LOSS: 0.03869 (0.07255) | LR: 0.00000008 | TIME: 0:40:52 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1280/1461 | LOSS: 0.04252 (0.07232) | LR: 0.00000005 | TIME: 0:42:06 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1320/1461 | LOSS: 0.06591 (0.07222) | LR: 0.00000003 | TIME: 0:43:20 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1360/1461 | LOSS: 0.05410 (0.07251) | LR: 0.00000002 | TIME: 0:44:39 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1400/1461 | LOSS: 0.09713 (0.07250) | LR: 0.00000001 | TIME: 0:46:03 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1440/1461 | LOSS: 0.04958 (0.07229) | LR: 0.00000000 | TIME: 0:47:22 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1460/1461 | LOSS: 0.07002 (0.07228) | LR: 0.00000000 | TIME: 0:48:00 |

VALID_LOOP
[VALID F3] EPOCH: 4/4 | STEP: 000/494 | LOSS: 0.09155 (0.09155) | TIME: 0:00:01 |
[VALID F3] EPOCH: 4/4 | STEP: 040/494 | LOSS: 0.07512 (0.10078) | TIME: 0:00:15 |
[VALID F3] EPOCH: 4/4 | STEP: 080/494 | LOSS: 0.20521 (0.10349) | TIME: 0:00:28 |
[VALID F3] EPOCH: 4/4 | STEP: 120/494 | LOSS: 0.04504 (0.10011) | TIME: 0:00:42 |
[VALID F3] EPOCH: 4/4 | STEP: 160/494 | LOSS: 0.21319 (0.10173) | TIME: 0:00:56 |
[VALID F3] EPOCH: 4/4 | STEP: 200/494 | LOSS: 0.04976 (0.10010) | TIME: 0:01:09 |
[VALID F3] EPOCH: 4/4 | STEP: 240/494 | LOSS: 0.13436 (0.10088) | TIME: 0:01:23 |
[VALID F3] EPOCH: 4/4 | STEP: 280/494 | LOSS: 0.11936 (0.10174) | TIME: 0:01:37 |
[VALID F3] EPOCH: 4/4 | STEP: 320/494 | LOSS: 0.04279 (0.10216) | TIME: 0:01:50 |
[VALID F3] EPOCH: 4/4 | STEP: 360/494 | LOSS: 0.06214 (0.10225) | TIME: 0:02:04 |
[VALID F3] EPOCH: 4/4 | STEP: 400/494 | LOSS: 0.05556 (0.10212) | TIME: 0:02:18 |
[VALID F3] EPOCH: 4/4 | STEP: 440/494 | LOSS: 0.11535 (0.10387) | TIME: 0:02:31 |
[VALID F3] EPOCH: 4/4 | STEP: 480/494 | LOSS: 0.12337 (0.10351) | TIME: 0:02:45 |
[VALID F3] EPOCH: 4/4 | STEP: 493/494 | LOSS: 0.10541 (0.10314) | TIME: 0:02:50 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.07228 |      0.10314 |  0.45509 | 0.484 | 0.443 | 0.427 | 0.464 | 0.473 | 0.439 | 0:50:50 |


[SAVED] EPOCH: 4 | MCRMSE: 0.45508694648742676


----------------------------------- FOLD 3 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.45509     0.48426   0.44285       0.42737        0.46356    0.47307        0.43941

################################### END OF FOlD 3 ###################################


