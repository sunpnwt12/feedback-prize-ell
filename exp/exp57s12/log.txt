Date: 2022-11-22 16:51:01.402022+07:00 (GMT+7)
Mode: CV_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: allenai/longformer-large-4096
Model_config: LongformerConfig {
  "_name_or_path": "allenai/longformer-large-4096",
  "attention_mode": "longformer",
  "attention_probs_dropout_prob": 0.0,
  "attention_window": [
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "ignore_attention_mask": false,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 4098,
  "model_type": "longformer",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 1,
  "pooler_dropout": 0.0,
  "position_embedding_type": "absolute",
  "sep_token_id": 2,
  "transformers_version": "4.20.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Pooling_strategy: mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5864}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 1/4 | STEP: 0000/1466 | LOSS: 2.64112 (2.64112) | LR: 0.00000005 | TIME: 0:00:02 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0040/1466 | LOSS: 1.99312 (2.28486) | LR: 0.00000224 | TIME: 0:01:57 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0080/1466 | LOSS: 0.15658 (1.83955) | LR: 0.00000443 | TIME: 0:03:48 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0120/1466 | LOSS: 0.18053 (1.30905) | LR: 0.00000661 | TIME: 0:05:40 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0160/1466 | LOSS: 0.49592 (1.03961) | LR: 0.00000880 | TIME: 0:07:28 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0200/1466 | LOSS: 0.54487 (0.87679) | LR: 0.00001098 | TIME: 0:09:26 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0240/1466 | LOSS: 0.11467 (0.76020) | LR: 0.00001317 | TIME: 0:11:15 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0280/1466 | LOSS: 0.14151 (0.67643) | LR: 0.00001536 | TIME: 0:13:10 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0320/1466 | LOSS: 0.09835 (0.61057) | LR: 0.00001754 | TIME: 0:14:54 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0360/1466 | LOSS: 0.16534 (0.55939) | LR: 0.00001973 | TIME: 0:16:47 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0400/1466 | LOSS: 0.21996 (0.51972) | LR: 0.00002000 | TIME: 0:18:41 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0440/1466 | LOSS: 0.13427 (0.48585) | LR: 0.00001999 | TIME: 0:20:27 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0480/1466 | LOSS: 0.11577 (0.45778) | LR: 0.00001998 | TIME: 0:22:19 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0520/1466 | LOSS: 0.12245 (0.43418) | LR: 0.00001996 | TIME: 0:24:14 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0560/1466 | LOSS: 0.10108 (0.41366) | LR: 0.00001994 | TIME: 0:26:02 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0600/1466 | LOSS: 0.07325 (0.39527) | LR: 0.00001991 | TIME: 0:27:58 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0640/1466 | LOSS: 0.11893 (0.37779) | LR: 0.00001988 | TIME: 0:29:48 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0680/1466 | LOSS: 0.09972 (0.36414) | LR: 0.00001984 | TIME: 0:31:43 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0720/1466 | LOSS: 0.04455 (0.35200) | LR: 0.00001979 | TIME: 0:33:28 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0760/1466 | LOSS: 0.13843 (0.34028) | LR: 0.00001975 | TIME: 0:35:20 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0800/1466 | LOSS: 0.10839 (0.32983) | LR: 0.00001969 | TIME: 0:37:06 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0840/1466 | LOSS: 0.13147 (0.32025) | LR: 0.00001963 | TIME: 0:38:55 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0880/1466 | LOSS: 0.15004 (0.31313) | LR: 0.00001957 | TIME: 0:40:48 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0920/1466 | LOSS: 0.05563 (0.30536) | LR: 0.00001950 | TIME: 0:42:43 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0960/1466 | LOSS: 0.20740 (0.29855) | LR: 0.00001943 | TIME: 0:44:34 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1000/1466 | LOSS: 0.04311 (0.29215) | LR: 0.00001935 | TIME: 0:46:34 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1040/1466 | LOSS: 0.09389 (0.28597) | LR: 0.00001927 | TIME: 0:48:25 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1080/1466 | LOSS: 0.09500 (0.28137) | LR: 0.00001918 | TIME: 0:50:22 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1120/1466 | LOSS: 0.07405 (0.27584) | LR: 0.00001908 | TIME: 0:52:09 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1160/1466 | LOSS: 0.13603 (0.27050) | LR: 0.00001899 | TIME: 0:53:50 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1200/1466 | LOSS: 0.11888 (0.26588) | LR: 0.00001888 | TIME: 0:55:46 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1240/1466 | LOSS: 0.03814 (0.26141) | LR: 0.00001878 | TIME: 0:57:31 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1280/1466 | LOSS: 0.30275 (0.25730) | LR: 0.00001866 | TIME: 0:59:23 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1320/1466 | LOSS: 0.09875 (0.25341) | LR: 0.00001855 | TIME: 1:01:10 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1360/1466 | LOSS: 0.07488 (0.24940) | LR: 0.00001843 | TIME: 1:02:57 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1400/1466 | LOSS: 0.13176 (0.24544) | LR: 0.00001830 | TIME: 1:04:49 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1440/1466 | LOSS: 0.11810 (0.24188) | LR: 0.00001817 | TIME: 1:06:46 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1465/1466 | LOSS: 0.10155 (0.23989) | LR: 0.00001809 | TIME: 1:07:52 |

VALID_LOOP
[VALID F0] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.07207 (0.07207) | TIME: 0:00:01 |
[VALID F0] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.06036 (0.11790) | TIME: 0:00:24 |
[VALID F0] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.04658 (0.11589) | TIME: 0:00:48 |
[VALID F0] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.12799 (0.11875) | TIME: 0:01:11 |
[VALID F0] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.07611 (0.11804) | TIME: 0:01:34 |
[VALID F0] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.21973 (0.11903) | TIME: 0:01:58 |
[VALID F0] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.07357 (0.11704) | TIME: 0:02:21 |
[VALID F0] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.07464 (0.11602) | TIME: 0:02:44 |
[VALID F0] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.09430 (0.11629) | TIME: 0:03:07 |
[VALID F0] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.13745 (0.11502) | TIME: 0:03:31 |
[VALID F0] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.15790 (0.11434) | TIME: 0:03:54 |
[VALID F0] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.12380 (0.11440) | TIME: 0:04:17 |
[VALID F0] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.05275 (0.11597) | TIME: 0:04:41 |
[VALID F0] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.09485 (0.11613) | TIME: 0:04:45 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.23989 |      0.11613 |  0.48319 | 0.516 | 0.465 | 0.431 | 0.500 | 0.500 | 0.487 | 1:12:38 |


[SAVED] EPOCH: 1 | MCRMSE: 0.48319196701049805

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 2/4 | STEP: 0000/1466 | LOSS: 0.06615 (0.06615) | LR: 0.00001809 | TIME: 0:00:04 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0040/1466 | LOSS: 0.13358 (0.09483) | LR: 0.00001795 | TIME: 0:01:50 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0080/1466 | LOSS: 0.06744 (0.09877) | LR: 0.00001781 | TIME: 0:03:39 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0120/1466 | LOSS: 0.12269 (0.10322) | LR: 0.00001766 | TIME: 0:05:27 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0160/1466 | LOSS: 0.10214 (0.10725) | LR: 0.00001751 | TIME: 0:07:23 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0200/1466 | LOSS: 0.07170 (0.10956) | LR: 0.00001736 | TIME: 0:09:09 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0240/1466 | LOSS: 0.16041 (0.11281) | LR: 0.00001721 | TIME: 0:10:58 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0280/1466 | LOSS: 0.05781 (0.11649) | LR: 0.00001704 | TIME: 0:12:53 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0320/1466 | LOSS: 0.05294 (0.11505) | LR: 0.00001688 | TIME: 0:14:43 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0360/1466 | LOSS: 0.11904 (0.11436) | LR: 0.00001671 | TIME: 0:16:36 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0400/1466 | LOSS: 0.10280 (0.11539) | LR: 0.00001654 | TIME: 0:18:29 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0440/1466 | LOSS: 0.08424 (0.11506) | LR: 0.00001637 | TIME: 0:20:21 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0480/1466 | LOSS: 0.03931 (0.11569) | LR: 0.00001619 | TIME: 0:22:15 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0520/1466 | LOSS: 0.04738 (0.11548) | LR: 0.00001601 | TIME: 0:23:59 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0560/1466 | LOSS: 0.08893 (0.11560) | LR: 0.00001582 | TIME: 0:25:47 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0600/1466 | LOSS: 0.03442 (0.11552) | LR: 0.00001564 | TIME: 0:27:35 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0640/1466 | LOSS: 0.39102 (0.11677) | LR: 0.00001545 | TIME: 0:29:23 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0680/1466 | LOSS: 0.14429 (0.11687) | LR: 0.00001525 | TIME: 0:31:21 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0720/1466 | LOSS: 0.07049 (0.11620) | LR: 0.00001506 | TIME: 0:33:10 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0760/1466 | LOSS: 0.10439 (0.11695) | LR: 0.00001486 | TIME: 0:35:01 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0800/1466 | LOSS: 0.28312 (0.11701) | LR: 0.00001466 | TIME: 0:36:55 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0840/1466 | LOSS: 0.08321 (0.11650) | LR: 0.00001445 | TIME: 0:38:47 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0880/1466 | LOSS: 0.11771 (0.11646) | LR: 0.00001425 | TIME: 0:40:40 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0920/1466 | LOSS: 0.14630 (0.11608) | LR: 0.00001404 | TIME: 0:42:27 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0960/1466 | LOSS: 0.07011 (0.11560) | LR: 0.00001383 | TIME: 0:44:23 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1000/1466 | LOSS: 0.11350 (0.11558) | LR: 0.00001362 | TIME: 0:46:16 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1040/1466 | LOSS: 0.07739 (0.11507) | LR: 0.00001340 | TIME: 0:48:00 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1080/1466 | LOSS: 0.06075 (0.11460) | LR: 0.00001319 | TIME: 0:49:48 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1120/1466 | LOSS: 0.05393 (0.11398) | LR: 0.00001297 | TIME: 0:51:39 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1160/1466 | LOSS: 0.10087 (0.11435) | LR: 0.00001275 | TIME: 0:53:24 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1200/1466 | LOSS: 0.10612 (0.11488) | LR: 0.00001253 | TIME: 0:55:13 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1240/1466 | LOSS: 0.13092 (0.11544) | LR: 0.00001231 | TIME: 0:57:02 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1280/1466 | LOSS: 0.06924 (0.11548) | LR: 0.00001209 | TIME: 0:58:59 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1320/1466 | LOSS: 0.11625 (0.11577) | LR: 0.00001186 | TIME: 1:00:51 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1360/1466 | LOSS: 0.09298 (0.11522) | LR: 0.00001164 | TIME: 1:02:40 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1400/1466 | LOSS: 0.11574 (0.11488) | LR: 0.00001141 | TIME: 1:04:31 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1440/1466 | LOSS: 0.03384 (0.11480) | LR: 0.00001119 | TIME: 1:06:13 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1465/1466 | LOSS: 0.11388 (0.11492) | LR: 0.00001104 | TIME: 1:07:21 |

VALID_LOOP
[VALID F0] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.06101 (0.06101) | TIME: 0:00:01 |
[VALID F0] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.07665 (0.10921) | TIME: 0:00:24 |
[VALID F0] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.05573 (0.10980) | TIME: 0:00:47 |
[VALID F0] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.14652 (0.11178) | TIME: 0:01:11 |
[VALID F0] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.06263 (0.11395) | TIME: 0:01:34 |
[VALID F0] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.16748 (0.11377) | TIME: 0:01:57 |
[VALID F0] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.06038 (0.11261) | TIME: 0:02:21 |
[VALID F0] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.07863 (0.11127) | TIME: 0:02:44 |
[VALID F0] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.09010 (0.11146) | TIME: 0:03:07 |
[VALID F0] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.11212 (0.11040) | TIME: 0:03:31 |
[VALID F0] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.15411 (0.10992) | TIME: 0:03:54 |
[VALID F0] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.09060 (0.11018) | TIME: 0:04:17 |
[VALID F0] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.06541 (0.11128) | TIME: 0:04:41 |
[VALID F0] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.05131 (0.11140) | TIME: 0:04:45 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11492 |       0.1114 |  0.47277 | 0.526 | 0.441 | 0.423 | 0.479 | 0.486 | 0.481 | 1:12:07 |


[SAVED] EPOCH: 2 | MCRMSE: 0.4727722406387329

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 3/4 | STEP: 0000/1466 | LOSS: 0.07896 (0.07896) | LR: 0.00001104 | TIME: 0:00:02 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0040/1466 | LOSS: 0.09638 (0.09927) | LR: 0.00001081 | TIME: 0:01:54 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0080/1466 | LOSS: 0.01533 (0.10208) | LR: 0.00001058 | TIME: 0:03:46 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0120/1466 | LOSS: 0.10152 (0.10328) | LR: 0.00001035 | TIME: 0:05:38 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0160/1466 | LOSS: 0.03885 (0.10043) | LR: 0.00001013 | TIME: 0:07:28 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0200/1466 | LOSS: 0.06386 (0.09650) | LR: 0.00000990 | TIME: 0:09:13 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0240/1466 | LOSS: 0.06150 (0.09654) | LR: 0.00000967 | TIME: 0:10:58 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0280/1466 | LOSS: 0.13484 (0.09730) | LR: 0.00000944 | TIME: 0:12:46 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0320/1466 | LOSS: 0.09929 (0.09831) | LR: 0.00000921 | TIME: 0:14:33 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0360/1466 | LOSS: 0.09830 (0.09856) | LR: 0.00000898 | TIME: 0:16:32 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0400/1466 | LOSS: 0.06760 (0.09816) | LR: 0.00000876 | TIME: 0:18:23 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0440/1466 | LOSS: 0.12599 (0.09788) | LR: 0.00000853 | TIME: 0:20:24 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0480/1466 | LOSS: 0.09883 (0.09717) | LR: 0.00000831 | TIME: 0:22:20 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0520/1466 | LOSS: 0.04423 (0.09650) | LR: 0.00000808 | TIME: 0:24:09 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0560/1466 | LOSS: 0.06232 (0.09615) | LR: 0.00000786 | TIME: 0:25:53 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0600/1466 | LOSS: 0.10277 (0.09600) | LR: 0.00000763 | TIME: 0:27:52 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0640/1466 | LOSS: 0.09520 (0.09572) | LR: 0.00000741 | TIME: 0:29:40 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0680/1466 | LOSS: 0.09491 (0.09571) | LR: 0.00000719 | TIME: 0:31:27 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0720/1466 | LOSS: 0.09599 (0.09576) | LR: 0.00000697 | TIME: 0:33:20 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0760/1466 | LOSS: 0.08256 (0.09680) | LR: 0.00000676 | TIME: 0:35:13 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0800/1466 | LOSS: 0.08839 (0.09706) | LR: 0.00000654 | TIME: 0:36:57 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0840/1466 | LOSS: 0.06794 (0.09681) | LR: 0.00000633 | TIME: 0:38:53 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0880/1466 | LOSS: 0.06892 (0.09650) | LR: 0.00000612 | TIME: 0:40:42 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0920/1466 | LOSS: 0.04044 (0.09683) | LR: 0.00000591 | TIME: 0:42:34 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0960/1466 | LOSS: 0.14228 (0.09725) | LR: 0.00000570 | TIME: 0:44:33 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1000/1466 | LOSS: 0.08515 (0.09728) | LR: 0.00000549 | TIME: 0:46:32 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1040/1466 | LOSS: 0.11232 (0.09743) | LR: 0.00000529 | TIME: 0:48:27 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1080/1466 | LOSS: 0.07786 (0.09742) | LR: 0.00000509 | TIME: 0:50:24 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1120/1466 | LOSS: 0.03332 (0.09759) | LR: 0.00000489 | TIME: 0:52:20 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1160/1466 | LOSS: 0.03563 (0.09768) | LR: 0.00000470 | TIME: 0:54:08 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1200/1466 | LOSS: 0.07725 (0.09749) | LR: 0.00000451 | TIME: 0:55:58 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1240/1466 | LOSS: 0.07819 (0.09745) | LR: 0.00000432 | TIME: 0:57:51 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1280/1466 | LOSS: 0.16362 (0.09759) | LR: 0.00000413 | TIME: 0:59:49 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1320/1466 | LOSS: 0.09744 (0.09715) | LR: 0.00000395 | TIME: 1:01:37 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1360/1466 | LOSS: 0.09297 (0.09715) | LR: 0.00000377 | TIME: 1:03:28 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1400/1466 | LOSS: 0.10729 (0.09725) | LR: 0.00000359 | TIME: 1:05:24 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1440/1466 | LOSS: 0.07458 (0.09701) | LR: 0.00000341 | TIME: 1:07:15 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1465/1466 | LOSS: 0.14998 (0.09688) | LR: 0.00000331 | TIME: 1:08:26 |

VALID_LOOP
[VALID F0] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.06937 (0.06937) | TIME: 0:00:01 |
[VALID F0] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.06735 (0.10517) | TIME: 0:00:25 |
[VALID F0] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.05326 (0.10652) | TIME: 0:00:49 |
[VALID F0] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.14022 (0.10863) | TIME: 0:01:12 |
[VALID F0] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.06316 (0.10948) | TIME: 0:01:36 |
[VALID F0] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.20390 (0.11055) | TIME: 0:02:00 |
[VALID F0] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.07540 (0.10856) | TIME: 0:02:23 |
[VALID F0] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.07284 (0.10744) | TIME: 0:02:47 |
[VALID F0] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.08085 (0.10740) | TIME: 0:03:11 |
[VALID F0] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.12815 (0.10644) | TIME: 0:03:35 |
[VALID F0] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.14895 (0.10634) | TIME: 0:03:58 |
[VALID F0] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.09338 (0.10663) | TIME: 0:04:22 |
[VALID F0] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.06774 (0.10812) | TIME: 0:04:46 |
[VALID F0] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.05007 (0.10823) | TIME: 0:04:50 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.09688 |      0.10823 |  0.46573 | 0.523 | 0.439 | 0.422 | 0.472 | 0.477 | 0.461 | 1:13:16 |


[SAVED] EPOCH: 3 | MCRMSE: 0.465733140707016

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 4/4 | STEP: 0000/1466 | LOSS: 0.04401 (0.04401) | LR: 0.00000330 | TIME: 0:00:04 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0040/1466 | LOSS: 0.10708 (0.09046) | LR: 0.00000314 | TIME: 0:01:56 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0080/1466 | LOSS: 0.05310 (0.08814) | LR: 0.00000297 | TIME: 0:03:41 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0120/1466 | LOSS: 0.09089 (0.08612) | LR: 0.00000281 | TIME: 0:05:32 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0160/1466 | LOSS: 0.05726 (0.08383) | LR: 0.00000265 | TIME: 0:07:23 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0200/1466 | LOSS: 0.05430 (0.08472) | LR: 0.00000250 | TIME: 0:09:11 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0240/1466 | LOSS: 0.08194 (0.08373) | LR: 0.00000235 | TIME: 0:11:08 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0280/1466 | LOSS: 0.02663 (0.08353) | LR: 0.00000221 | TIME: 0:13:02 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0320/1466 | LOSS: 0.06288 (0.08316) | LR: 0.00000207 | TIME: 0:14:58 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0360/1466 | LOSS: 0.11818 (0.08491) | LR: 0.00000193 | TIME: 0:16:43 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0400/1466 | LOSS: 0.05437 (0.08452) | LR: 0.00000180 | TIME: 0:18:30 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0440/1466 | LOSS: 0.09908 (0.08524) | LR: 0.00000167 | TIME: 0:20:20 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0480/1466 | LOSS: 0.02915 (0.08529) | LR: 0.00000154 | TIME: 0:22:06 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0520/1466 | LOSS: 0.09285 (0.08469) | LR: 0.00000142 | TIME: 0:24:02 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0560/1466 | LOSS: 0.06189 (0.08477) | LR: 0.00000131 | TIME: 0:25:55 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0600/1466 | LOSS: 0.08630 (0.08428) | LR: 0.00000120 | TIME: 0:27:46 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0640/1466 | LOSS: 0.05980 (0.08424) | LR: 0.00000109 | TIME: 0:29:35 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0680/1466 | LOSS: 0.06326 (0.08417) | LR: 0.00000099 | TIME: 0:31:23 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0720/1466 | LOSS: 0.15254 (0.08395) | LR: 0.00000089 | TIME: 0:33:15 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0760/1466 | LOSS: 0.04333 (0.08362) | LR: 0.00000080 | TIME: 0:35:14 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0800/1466 | LOSS: 0.08106 (0.08383) | LR: 0.00000071 | TIME: 0:37:04 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0840/1466 | LOSS: 0.13195 (0.08361) | LR: 0.00000063 | TIME: 0:38:57 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0880/1466 | LOSS: 0.19640 (0.08365) | LR: 0.00000055 | TIME: 0:40:50 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0920/1466 | LOSS: 0.07903 (0.08382) | LR: 0.00000048 | TIME: 0:42:39 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0960/1466 | LOSS: 0.07082 (0.08404) | LR: 0.00000041 | TIME: 0:44:36 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1000/1466 | LOSS: 0.05179 (0.08370) | LR: 0.00000035 | TIME: 0:46:27 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1040/1466 | LOSS: 0.06440 (0.08409) | LR: 0.00000029 | TIME: 0:48:17 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1080/1466 | LOSS: 0.12977 (0.08404) | LR: 0.00000024 | TIME: 0:50:04 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1120/1466 | LOSS: 0.06598 (0.08407) | LR: 0.00000019 | TIME: 0:51:55 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1160/1466 | LOSS: 0.09968 (0.08411) | LR: 0.00000015 | TIME: 0:53:51 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1200/1466 | LOSS: 0.08919 (0.08411) | LR: 0.00000011 | TIME: 0:55:47 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1240/1466 | LOSS: 0.09667 (0.08408) | LR: 0.00000008 | TIME: 0:57:40 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1280/1466 | LOSS: 0.05637 (0.08419) | LR: 0.00000006 | TIME: 0:59:39 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1320/1466 | LOSS: 0.09981 (0.08408) | LR: 0.00000003 | TIME: 1:01:24 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1360/1466 | LOSS: 0.06763 (0.08392) | LR: 0.00000002 | TIME: 1:03:20 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1400/1466 | LOSS: 0.09891 (0.08371) | LR: 0.00000001 | TIME: 1:05:11 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1440/1466 | LOSS: 0.08405 (0.08370) | LR: 0.00000000 | TIME: 1:07:04 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1465/1466 | LOSS: 0.13901 (0.08383) | LR: 0.00000000 | TIME: 1:08:10 |

VALID_LOOP
[VALID F0] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.06177 (0.06177) | TIME: 0:00:01 |
[VALID F0] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.07332 (0.10197) | TIME: 0:00:25 |
[VALID F0] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.04620 (0.10368) | TIME: 0:00:48 |
[VALID F0] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.14809 (0.10550) | TIME: 0:01:12 |
[VALID F0] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.05761 (0.10652) | TIME: 0:01:36 |
[VALID F0] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.20169 (0.10746) | TIME: 0:02:00 |
[VALID F0] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.06749 (0.10577) | TIME: 0:02:24 |
[VALID F0] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.07011 (0.10467) | TIME: 0:02:47 |
[VALID F0] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.08388 (0.10456) | TIME: 0:03:11 |
[VALID F0] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.11117 (0.10369) | TIME: 0:03:35 |
[VALID F0] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.16322 (0.10396) | TIME: 0:03:58 |
[VALID F0] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.09187 (0.10434) | TIME: 0:04:22 |
[VALID F0] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.06631 (0.10606) | TIME: 0:04:46 |
[VALID F0] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.05811 (0.10621) | TIME: 0:04:51 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.08383 |      0.10621 |  0.46155 | 0.504 | 0.438 | 0.422 | 0.470 | 0.475 | 0.461 | 1:13:01 |


[SAVED] EPOCH: 4 | MCRMSE: 0.46154752373695374


----------------------------------- FOLD 0 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.46155     0.50376   0.43804       0.42167         0.4697    0.47505        0.46106

################################### END OF FOlD 0 ###################################


Date: 2022-11-22 21:42:58.635455+07:00 (GMT+7)
Mode: CV_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: allenai/longformer-large-4096
Model_config: LongformerConfig {
  "_name_or_path": "allenai/longformer-large-4096",
  "attention_mode": "longformer",
  "attention_probs_dropout_prob": 0.0,
  "attention_window": [
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "ignore_attention_mask": false,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 4098,
  "model_type": "longformer",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 1,
  "pooler_dropout": 0.0,
  "position_embedding_type": "absolute",
  "sep_token_id": 2,
  "transformers_version": "4.20.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Pooling_strategy: mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5868}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 1/4 | STEP: 0000/1467 | LOSS: 2.00942 (2.00942) | LR: 0.00000005 | TIME: 0:00:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0040/1467 | LOSS: 1.81526 (2.29021) | LR: 0.00000224 | TIME: 0:01:53 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0080/1467 | LOSS: 0.48009 (1.79926) | LR: 0.00000443 | TIME: 0:03:40 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0120/1467 | LOSS: 0.32078 (1.30643) | LR: 0.00000661 | TIME: 0:05:25 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0160/1467 | LOSS: 0.14119 (1.03079) | LR: 0.00000880 | TIME: 0:07:25 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0200/1467 | LOSS: 0.16441 (0.86743) | LR: 0.00001098 | TIME: 0:09:17 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0240/1467 | LOSS: 0.15906 (0.75141) | LR: 0.00001317 | TIME: 0:11:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0280/1467 | LOSS: 0.19746 (0.66816) | LR: 0.00001536 | TIME: 0:12:59 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0320/1467 | LOSS: 0.14156 (0.60573) | LR: 0.00001754 | TIME: 0:14:45 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0360/1467 | LOSS: 0.14394 (0.55462) | LR: 0.00001973 | TIME: 0:16:41 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0400/1467 | LOSS: 0.08947 (0.51364) | LR: 0.00002000 | TIME: 0:18:39 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0440/1467 | LOSS: 0.17514 (0.48145) | LR: 0.00001999 | TIME: 0:20:34 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0480/1467 | LOSS: 0.09593 (0.45275) | LR: 0.00001998 | TIME: 0:22:25 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0520/1467 | LOSS: 0.08119 (0.42952) | LR: 0.00001996 | TIME: 0:24:11 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0560/1467 | LOSS: 0.04616 (0.40994) | LR: 0.00001994 | TIME: 0:26:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0600/1467 | LOSS: 0.52339 (0.39243) | LR: 0.00001991 | TIME: 0:28:03 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0640/1467 | LOSS: 0.07841 (0.37729) | LR: 0.00001988 | TIME: 0:29:50 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0680/1467 | LOSS: 0.14428 (0.36309) | LR: 0.00001984 | TIME: 0:31:47 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0720/1467 | LOSS: 0.38715 (0.34993) | LR: 0.00001980 | TIME: 0:33:39 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0760/1467 | LOSS: 0.09346 (0.34010) | LR: 0.00001975 | TIME: 0:35:29 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0800/1467 | LOSS: 0.11133 (0.32958) | LR: 0.00001969 | TIME: 0:37:22 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0840/1467 | LOSS: 0.11883 (0.32142) | LR: 0.00001963 | TIME: 0:39:09 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0880/1467 | LOSS: 0.04759 (0.31358) | LR: 0.00001957 | TIME: 0:40:53 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0920/1467 | LOSS: 0.13614 (0.30586) | LR: 0.00001950 | TIME: 0:42:51 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0960/1467 | LOSS: 0.17943 (0.29904) | LR: 0.00001943 | TIME: 0:44:48 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1000/1467 | LOSS: 0.13914 (0.29247) | LR: 0.00001935 | TIME: 0:46:33 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1040/1467 | LOSS: 0.07004 (0.28581) | LR: 0.00001927 | TIME: 0:48:25 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1080/1467 | LOSS: 0.18703 (0.27929) | LR: 0.00001918 | TIME: 0:50:18 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1120/1467 | LOSS: 0.08662 (0.27349) | LR: 0.00001909 | TIME: 0:52:11 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1160/1467 | LOSS: 0.11747 (0.26924) | LR: 0.00001899 | TIME: 0:53:57 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1200/1467 | LOSS: 0.11506 (0.26464) | LR: 0.00001888 | TIME: 0:55:43 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1240/1467 | LOSS: 0.25281 (0.26026) | LR: 0.00001878 | TIME: 0:57:41 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1280/1467 | LOSS: 0.10542 (0.25619) | LR: 0.00001867 | TIME: 0:59:35 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1320/1467 | LOSS: 0.07006 (0.25206) | LR: 0.00001855 | TIME: 1:01:27 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1360/1467 | LOSS: 0.31947 (0.24876) | LR: 0.00001843 | TIME: 1:03:13 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1400/1467 | LOSS: 0.05882 (0.24529) | LR: 0.00001830 | TIME: 1:04:58 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1440/1467 | LOSS: 0.41508 (0.24197) | LR: 0.00001817 | TIME: 1:06:44 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1466/1467 | LOSS: 0.02467 (0.23945) | LR: 0.00001809 | TIME: 1:07:51 |

VALID_LOOP
[VALID F1] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.10647 (0.10647) | TIME: 0:00:01 |
[VALID F1] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.14280 (0.11703) | TIME: 0:00:25 |
[VALID F1] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.06497 (0.12311) | TIME: 0:00:49 |
[VALID F1] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.09531 (0.12094) | TIME: 0:01:12 |
[VALID F1] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.11616 (0.12050) | TIME: 0:01:36 |
[VALID F1] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.06083 (0.12093) | TIME: 0:02:00 |
[VALID F1] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.09067 (0.12108) | TIME: 0:02:23 |
[VALID F1] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.03667 (0.11992) | TIME: 0:02:47 |
[VALID F1] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.16917 (0.12116) | TIME: 0:03:11 |
[VALID F1] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.15061 (0.12133) | TIME: 0:03:35 |
[VALID F1] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.04728 (0.12018) | TIME: 0:03:58 |
[VALID F1] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.10998 (0.12064) | TIME: 0:04:22 |
[VALID F1] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.11145 (0.11997) | TIME: 0:04:46 |
[VALID F1] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.10538 (0.11929) | TIME: 0:04:50 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.23945 |      0.11929 |  0.49014 | 0.505 | 0.475 | 0.439 | 0.477 | 0.541 | 0.505 | 1:12:42 |


[SAVED] EPOCH: 1 | MCRMSE: 0.49014362692832947

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 2/4 | STEP: 0000/1467 | LOSS: 0.12661 (0.12661) | LR: 0.00001808 | TIME: 0:00:04 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0040/1467 | LOSS: 0.06817 (0.13484) | LR: 0.00001795 | TIME: 0:01:50 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0080/1467 | LOSS: 0.09652 (0.12852) | LR: 0.00001781 | TIME: 0:03:47 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0120/1467 | LOSS: 0.06027 (0.12397) | LR: 0.00001766 | TIME: 0:05:37 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0160/1467 | LOSS: 0.05224 (0.11865) | LR: 0.00001751 | TIME: 0:07:14 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0200/1467 | LOSS: 0.11949 (0.12012) | LR: 0.00001736 | TIME: 0:09:05 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0240/1467 | LOSS: 0.12548 (0.11815) | LR: 0.00001721 | TIME: 0:10:59 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0280/1467 | LOSS: 0.14341 (0.11883) | LR: 0.00001704 | TIME: 0:12:46 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0320/1467 | LOSS: 0.26869 (0.11859) | LR: 0.00001688 | TIME: 0:14:40 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0360/1467 | LOSS: 0.10609 (0.12007) | LR: 0.00001671 | TIME: 0:16:35 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0400/1467 | LOSS: 0.09775 (0.11918) | LR: 0.00001654 | TIME: 0:18:28 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0440/1467 | LOSS: 0.12246 (0.11896) | LR: 0.00001637 | TIME: 0:20:19 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0480/1467 | LOSS: 0.20058 (0.11768) | LR: 0.00001619 | TIME: 0:22:04 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0520/1467 | LOSS: 0.07087 (0.11739) | LR: 0.00001601 | TIME: 0:23:57 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0560/1467 | LOSS: 0.04671 (0.11771) | LR: 0.00001583 | TIME: 0:25:47 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0600/1467 | LOSS: 0.08497 (0.11802) | LR: 0.00001564 | TIME: 0:27:40 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0640/1467 | LOSS: 0.07550 (0.11716) | LR: 0.00001545 | TIME: 0:29:39 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0680/1467 | LOSS: 0.09576 (0.11612) | LR: 0.00001525 | TIME: 0:31:31 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0720/1467 | LOSS: 0.13688 (0.11618) | LR: 0.00001506 | TIME: 0:33:24 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0760/1467 | LOSS: 0.29539 (0.11659) | LR: 0.00001486 | TIME: 0:35:18 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0800/1467 | LOSS: 0.11690 (0.11727) | LR: 0.00001466 | TIME: 0:37:04 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0840/1467 | LOSS: 0.18623 (0.11714) | LR: 0.00001446 | TIME: 0:38:54 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0880/1467 | LOSS: 0.08715 (0.11670) | LR: 0.00001425 | TIME: 0:40:56 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0920/1467 | LOSS: 0.11689 (0.11649) | LR: 0.00001404 | TIME: 0:42:42 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0960/1467 | LOSS: 0.17779 (0.11658) | LR: 0.00001383 | TIME: 0:44:30 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1000/1467 | LOSS: 0.18049 (0.11680) | LR: 0.00001362 | TIME: 0:46:20 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1040/1467 | LOSS: 0.10136 (0.11730) | LR: 0.00001341 | TIME: 0:48:09 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1080/1467 | LOSS: 0.14741 (0.11673) | LR: 0.00001319 | TIME: 0:50:02 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1120/1467 | LOSS: 0.08861 (0.11601) | LR: 0.00001297 | TIME: 0:51:52 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1160/1467 | LOSS: 0.09513 (0.11639) | LR: 0.00001276 | TIME: 0:53:41 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1200/1467 | LOSS: 0.08810 (0.11584) | LR: 0.00001254 | TIME: 0:55:22 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1240/1467 | LOSS: 0.12082 (0.11598) | LR: 0.00001231 | TIME: 0:57:15 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1280/1467 | LOSS: 0.07945 (0.11644) | LR: 0.00001209 | TIME: 0:59:07 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1320/1467 | LOSS: 0.08947 (0.11632) | LR: 0.00001187 | TIME: 1:01:00 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1360/1467 | LOSS: 0.03087 (0.11627) | LR: 0.00001164 | TIME: 1:02:47 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1400/1467 | LOSS: 0.08785 (0.11623) | LR: 0.00001142 | TIME: 1:04:36 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1440/1467 | LOSS: 0.21255 (0.11612) | LR: 0.00001119 | TIME: 1:06:31 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1466/1467 | LOSS: 0.06933 (0.11583) | LR: 0.00001104 | TIME: 1:07:49 |

VALID_LOOP
[VALID F1] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.06137 (0.06137) | TIME: 0:00:01 |
[VALID F1] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.13109 (0.10443) | TIME: 0:00:25 |
[VALID F1] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.07743 (0.11393) | TIME: 0:00:49 |
[VALID F1] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.04177 (0.11125) | TIME: 0:01:12 |
[VALID F1] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.17657 (0.11132) | TIME: 0:01:36 |
[VALID F1] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.06298 (0.11112) | TIME: 0:02:00 |
[VALID F1] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.05105 (0.11037) | TIME: 0:02:24 |
[VALID F1] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.03010 (0.10967) | TIME: 0:02:47 |
[VALID F1] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.13343 (0.11139) | TIME: 0:03:11 |
[VALID F1] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.11533 (0.11187) | TIME: 0:03:35 |
[VALID F1] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.02192 (0.11180) | TIME: 0:03:59 |
[VALID F1] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.06976 (0.11312) | TIME: 0:04:22 |
[VALID F1] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.16179 (0.11273) | TIME: 0:04:46 |
[VALID F1] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.06744 (0.11223) | TIME: 0:04:51 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11583 |      0.11223 |  0.47505 | 0.507 | 0.463 | 0.466 | 0.463 | 0.487 | 0.465 | 1:12:40 |


[SAVED] EPOCH: 2 | MCRMSE: 0.4750455617904663

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 3/4 | STEP: 0000/1467 | LOSS: 0.10693 (0.10693) | LR: 0.00001104 | TIME: 0:00:04 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0040/1467 | LOSS: 0.17961 (0.09849) | LR: 0.00001081 | TIME: 0:02:04 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0080/1467 | LOSS: 0.06653 (0.09727) | LR: 0.00001058 | TIME: 0:03:56 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0120/1467 | LOSS: 0.14337 (0.09649) | LR: 0.00001035 | TIME: 0:05:52 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0160/1467 | LOSS: 0.07435 (0.09802) | LR: 0.00001013 | TIME: 0:07:42 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0200/1467 | LOSS: 0.22659 (0.09742) | LR: 0.00000990 | TIME: 0:09:43 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0240/1467 | LOSS: 0.05335 (0.09550) | LR: 0.00000967 | TIME: 0:11:33 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0280/1467 | LOSS: 0.03007 (0.09333) | LR: 0.00000944 | TIME: 0:13:26 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0320/1467 | LOSS: 0.21307 (0.09450) | LR: 0.00000921 | TIME: 0:15:18 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0360/1467 | LOSS: 0.06911 (0.09417) | LR: 0.00000899 | TIME: 0:17:11 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0400/1467 | LOSS: 0.05273 (0.09499) | LR: 0.00000876 | TIME: 0:18:55 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0440/1467 | LOSS: 0.06328 (0.09508) | LR: 0.00000853 | TIME: 0:20:53 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0480/1467 | LOSS: 0.10590 (0.09563) | LR: 0.00000831 | TIME: 0:22:43 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0520/1467 | LOSS: 0.04246 (0.09598) | LR: 0.00000808 | TIME: 0:24:28 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0560/1467 | LOSS: 0.06111 (0.09533) | LR: 0.00000786 | TIME: 0:26:16 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0600/1467 | LOSS: 0.14438 (0.09518) | LR: 0.00000764 | TIME: 0:28:04 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0640/1467 | LOSS: 0.10321 (0.09593) | LR: 0.00000741 | TIME: 0:29:53 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0680/1467 | LOSS: 0.04011 (0.09630) | LR: 0.00000719 | TIME: 0:31:43 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0720/1467 | LOSS: 0.03495 (0.09679) | LR: 0.00000698 | TIME: 0:33:36 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0760/1467 | LOSS: 0.03682 (0.09664) | LR: 0.00000676 | TIME: 0:35:23 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0800/1467 | LOSS: 0.06928 (0.09648) | LR: 0.00000654 | TIME: 0:37:12 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0840/1467 | LOSS: 0.04801 (0.09632) | LR: 0.00000633 | TIME: 0:38:58 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0880/1467 | LOSS: 0.04837 (0.09653) | LR: 0.00000612 | TIME: 0:40:45 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0920/1467 | LOSS: 0.09937 (0.09634) | LR: 0.00000591 | TIME: 0:42:37 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0960/1467 | LOSS: 0.12202 (0.09634) | LR: 0.00000570 | TIME: 0:44:20 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1000/1467 | LOSS: 0.05142 (0.09648) | LR: 0.00000550 | TIME: 0:46:13 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1040/1467 | LOSS: 0.08152 (0.09631) | LR: 0.00000529 | TIME: 0:48:07 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1080/1467 | LOSS: 0.12915 (0.09610) | LR: 0.00000509 | TIME: 0:50:05 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1120/1467 | LOSS: 0.10895 (0.09611) | LR: 0.00000490 | TIME: 0:52:01 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1160/1467 | LOSS: 0.09512 (0.09659) | LR: 0.00000470 | TIME: 0:53:50 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1200/1467 | LOSS: 0.17096 (0.09630) | LR: 0.00000451 | TIME: 0:55:39 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1240/1467 | LOSS: 0.09910 (0.09595) | LR: 0.00000432 | TIME: 0:57:27 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1280/1467 | LOSS: 0.05018 (0.09567) | LR: 0.00000413 | TIME: 0:59:18 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1320/1467 | LOSS: 0.17600 (0.09565) | LR: 0.00000395 | TIME: 1:01:02 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1360/1467 | LOSS: 0.05835 (0.09526) | LR: 0.00000377 | TIME: 1:02:58 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1400/1467 | LOSS: 0.10162 (0.09592) | LR: 0.00000359 | TIME: 1:04:52 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1440/1467 | LOSS: 0.13002 (0.09609) | LR: 0.00000342 | TIME: 1:06:40 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1466/1467 | LOSS: 0.16598 (0.09614) | LR: 0.00000331 | TIME: 1:07:51 |

VALID_LOOP
[VALID F1] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.07196 (0.07196) | TIME: 0:00:01 |
[VALID F1] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.11491 (0.09650) | TIME: 0:00:25 |
[VALID F1] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.06626 (0.10749) | TIME: 0:00:49 |
[VALID F1] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.05689 (0.10454) | TIME: 0:01:12 |
[VALID F1] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.15876 (0.10351) | TIME: 0:01:36 |
[VALID F1] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.05250 (0.10353) | TIME: 0:02:00 |
[VALID F1] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.04054 (0.10318) | TIME: 0:02:23 |
[VALID F1] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.03182 (0.10247) | TIME: 0:02:47 |
[VALID F1] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.13797 (0.10377) | TIME: 0:03:11 |
[VALID F1] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.08809 (0.10359) | TIME: 0:03:35 |
[VALID F1] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.03069 (0.10366) | TIME: 0:03:58 |
[VALID F1] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.07592 (0.10493) | TIME: 0:04:22 |
[VALID F1] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.15746 (0.10461) | TIME: 0:04:45 |
[VALID F1] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.06995 (0.10410) | TIME: 0:04:50 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.09614 |       0.1041 |  0.45724 | 0.491 | 0.461 | 0.408 | 0.452 | 0.481 | 0.451 | 1:12:42 |


[SAVED] EPOCH: 3 | MCRMSE: 0.45724478363990784

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 4/4 | STEP: 0000/1467 | LOSS: 0.13781 (0.13781) | LR: 0.00000330 | TIME: 0:00:04 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0040/1467 | LOSS: 0.06534 (0.09527) | LR: 0.00000314 | TIME: 0:02:00 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0080/1467 | LOSS: 0.04375 (0.09598) | LR: 0.00000297 | TIME: 0:03:55 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0120/1467 | LOSS: 0.04743 (0.08826) | LR: 0.00000281 | TIME: 0:05:43 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0160/1467 | LOSS: 0.07371 (0.08723) | LR: 0.00000265 | TIME: 0:07:36 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0200/1467 | LOSS: 0.05543 (0.08562) | LR: 0.00000250 | TIME: 0:09:28 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0240/1467 | LOSS: 0.03486 (0.08433) | LR: 0.00000235 | TIME: 0:11:11 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0280/1467 | LOSS: 0.08318 (0.08534) | LR: 0.00000221 | TIME: 0:13:08 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0320/1467 | LOSS: 0.14218 (0.08556) | LR: 0.00000207 | TIME: 0:15:06 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0360/1467 | LOSS: 0.13067 (0.08622) | LR: 0.00000193 | TIME: 0:16:54 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0400/1467 | LOSS: 0.04949 (0.08582) | LR: 0.00000180 | TIME: 0:18:52 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0440/1467 | LOSS: 0.06335 (0.08546) | LR: 0.00000167 | TIME: 0:20:30 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0480/1467 | LOSS: 0.03723 (0.08468) | LR: 0.00000154 | TIME: 0:22:13 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0520/1467 | LOSS: 0.09096 (0.08401) | LR: 0.00000142 | TIME: 0:24:02 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0560/1467 | LOSS: 0.09499 (0.08385) | LR: 0.00000131 | TIME: 0:26:00 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0600/1467 | LOSS: 0.19965 (0.08418) | LR: 0.00000120 | TIME: 0:27:49 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0640/1467 | LOSS: 0.08860 (0.08382) | LR: 0.00000109 | TIME: 0:29:41 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0680/1467 | LOSS: 0.13221 (0.08405) | LR: 0.00000099 | TIME: 0:31:38 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0720/1467 | LOSS: 0.13245 (0.08443) | LR: 0.00000089 | TIME: 0:33:33 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0760/1467 | LOSS: 0.10922 (0.08438) | LR: 0.00000080 | TIME: 0:35:21 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0800/1467 | LOSS: 0.09577 (0.08441) | LR: 0.00000071 | TIME: 0:37:15 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0840/1467 | LOSS: 0.05888 (0.08468) | LR: 0.00000063 | TIME: 0:39:10 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0880/1467 | LOSS: 0.07958 (0.08507) | LR: 0.00000055 | TIME: 0:41:02 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0920/1467 | LOSS: 0.04938 (0.08471) | LR: 0.00000048 | TIME: 0:42:51 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0960/1467 | LOSS: 0.03403 (0.08469) | LR: 0.00000041 | TIME: 0:44:39 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1000/1467 | LOSS: 0.03727 (0.08481) | LR: 0.00000035 | TIME: 0:46:31 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1040/1467 | LOSS: 0.07080 (0.08458) | LR: 0.00000029 | TIME: 0:48:13 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1080/1467 | LOSS: 0.13672 (0.08412) | LR: 0.00000024 | TIME: 0:50:06 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1120/1467 | LOSS: 0.07147 (0.08415) | LR: 0.00000019 | TIME: 0:51:57 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1160/1467 | LOSS: 0.06328 (0.08416) | LR: 0.00000015 | TIME: 0:53:42 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1200/1467 | LOSS: 0.06721 (0.08420) | LR: 0.00000012 | TIME: 0:55:31 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1240/1467 | LOSS: 0.08760 (0.08405) | LR: 0.00000008 | TIME: 0:57:18 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1280/1467 | LOSS: 0.10220 (0.08405) | LR: 0.00000006 | TIME: 0:59:11 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1320/1467 | LOSS: 0.05749 (0.08413) | LR: 0.00000003 | TIME: 1:00:53 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1360/1467 | LOSS: 0.03885 (0.08394) | LR: 0.00000002 | TIME: 1:02:41 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1400/1467 | LOSS: 0.04085 (0.08387) | LR: 0.00000001 | TIME: 1:04:34 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1440/1467 | LOSS: 0.08060 (0.08380) | LR: 0.00000000 | TIME: 1:06:28 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1466/1467 | LOSS: 0.07666 (0.08371) | LR: 0.00000000 | TIME: 1:07:40 |

VALID_LOOP
[VALID F1] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.08427 (0.08427) | TIME: 0:00:01 |
[VALID F1] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.11257 (0.09780) | TIME: 0:00:24 |
[VALID F1] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.06282 (0.10780) | TIME: 0:00:48 |
[VALID F1] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.06562 (0.10473) | TIME: 0:01:11 |
[VALID F1] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.14450 (0.10340) | TIME: 0:01:34 |
[VALID F1] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.04309 (0.10343) | TIME: 0:01:57 |
[VALID F1] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.05114 (0.10335) | TIME: 0:02:21 |
[VALID F1] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.04013 (0.10273) | TIME: 0:02:44 |
[VALID F1] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.15459 (0.10374) | TIME: 0:03:07 |
[VALID F1] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.09992 (0.10343) | TIME: 0:03:31 |
[VALID F1] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.03623 (0.10329) | TIME: 0:03:54 |
[VALID F1] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.06601 (0.10439) | TIME: 0:04:17 |
[VALID F1] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.13776 (0.10406) | TIME: 0:04:41 |
[VALID F1] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.06996 (0.10350) | TIME: 0:04:45 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.08371 |       0.1035 |  0.45589 | 0.487 | 0.458 | 0.408 | 0.450 | 0.481 | 0.451 | 1:12:26 |


[SAVED] EPOCH: 4 | MCRMSE: 0.45588934421539307


----------------------------------- FOLD 1 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.45589     0.48731   0.45813       0.40808        0.45014    0.48088        0.45081

################################### END OF FOlD 1 ###################################


Date: 2022-11-22 16:51:04.812643+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: allenai/longformer-large-4096
Model_config: LongformerConfig {
  "_name_or_path": "allenai/longformer-large-4096",
  "attention_mode": "longformer",
  "attention_probs_dropout_prob": 0.0,
  "attention_window": [
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "ignore_attention_mask": false,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 4098,
  "model_type": "longformer",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 1,
  "pooler_dropout": 0.0,
  "position_embedding_type": "absolute",
  "sep_token_id": 2,
  "transformers_version": "4.20.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Pooling_strategy: mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5864}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 1/4 | STEP: 0000/1466 | LOSS: 2.38074 (2.38074) | LR: 0.00000005 | TIME: 0:00:03 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0040/1466 | LOSS: 2.12059 (2.31252) | LR: 0.00000224 | TIME: 0:01:52 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0080/1466 | LOSS: 0.30287 (1.83856) | LR: 0.00000443 | TIME: 0:03:45 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0120/1466 | LOSS: 0.24742 (1.32242) | LR: 0.00000661 | TIME: 0:05:31 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0160/1466 | LOSS: 0.15644 (1.04624) | LR: 0.00000880 | TIME: 0:07:17 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0200/1466 | LOSS: 0.13198 (0.88035) | LR: 0.00001098 | TIME: 0:09:15 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0240/1466 | LOSS: 0.15378 (0.75983) | LR: 0.00001317 | TIME: 0:11:12 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0280/1466 | LOSS: 0.33626 (0.67490) | LR: 0.00001536 | TIME: 0:13:04 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0320/1466 | LOSS: 0.06629 (0.60907) | LR: 0.00001754 | TIME: 0:14:54 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0360/1466 | LOSS: 0.24007 (0.55870) | LR: 0.00001973 | TIME: 0:16:48 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0400/1466 | LOSS: 0.05403 (0.51579) | LR: 0.00002000 | TIME: 0:18:44 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0440/1466 | LOSS: 0.07814 (0.48088) | LR: 0.00001999 | TIME: 0:20:31 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0480/1466 | LOSS: 0.10469 (0.45233) | LR: 0.00001998 | TIME: 0:22:23 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0520/1466 | LOSS: 0.14744 (0.43036) | LR: 0.00001996 | TIME: 0:24:22 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0560/1466 | LOSS: 0.06500 (0.41049) | LR: 0.00001994 | TIME: 0:26:12 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0600/1466 | LOSS: 0.15294 (0.39305) | LR: 0.00001991 | TIME: 0:28:05 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0640/1466 | LOSS: 0.12473 (0.37765) | LR: 0.00001988 | TIME: 0:29:56 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0680/1466 | LOSS: 0.11732 (0.36227) | LR: 0.00001984 | TIME: 0:31:43 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0720/1466 | LOSS: 0.26372 (0.35028) | LR: 0.00001979 | TIME: 0:33:34 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0760/1466 | LOSS: 0.05213 (0.33772) | LR: 0.00001975 | TIME: 0:35:17 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0800/1466 | LOSS: 0.20055 (0.32871) | LR: 0.00001969 | TIME: 0:37:05 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0840/1466 | LOSS: 0.18502 (0.31958) | LR: 0.00001963 | TIME: 0:38:57 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0880/1466 | LOSS: 0.07800 (0.31170) | LR: 0.00001957 | TIME: 0:40:45 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0920/1466 | LOSS: 0.18091 (0.30482) | LR: 0.00001950 | TIME: 0:42:28 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0960/1466 | LOSS: 0.25525 (0.29807) | LR: 0.00001943 | TIME: 0:44:17 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1000/1466 | LOSS: 0.12273 (0.29075) | LR: 0.00001935 | TIME: 0:46:08 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1040/1466 | LOSS: 0.07063 (0.28564) | LR: 0.00001927 | TIME: 0:47:55 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1080/1466 | LOSS: 0.34490 (0.28013) | LR: 0.00001918 | TIME: 0:49:45 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1120/1466 | LOSS: 0.41816 (0.27544) | LR: 0.00001908 | TIME: 0:51:40 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1160/1466 | LOSS: 0.11977 (0.27179) | LR: 0.00001899 | TIME: 0:53:27 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1200/1466 | LOSS: 0.05583 (0.26709) | LR: 0.00001888 | TIME: 0:55:24 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1240/1466 | LOSS: 0.08630 (0.26269) | LR: 0.00001878 | TIME: 0:57:11 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1280/1466 | LOSS: 0.08454 (0.25853) | LR: 0.00001866 | TIME: 0:59:01 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1320/1466 | LOSS: 0.11082 (0.25499) | LR: 0.00001855 | TIME: 1:00:51 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1360/1466 | LOSS: 0.13742 (0.25132) | LR: 0.00001843 | TIME: 1:02:40 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1400/1466 | LOSS: 0.16101 (0.24786) | LR: 0.00001830 | TIME: 1:04:31 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1440/1466 | LOSS: 0.09820 (0.24483) | LR: 0.00001817 | TIME: 1:06:23 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1465/1466 | LOSS: 0.07524 (0.24258) | LR: 0.00001809 | TIME: 1:07:22 |

VALID_LOOP
[VALID F2] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.05231 (0.05231) | TIME: 0:00:01 |
[VALID F2] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.17620 (0.11726) | TIME: 0:00:24 |
[VALID F2] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.08001 (0.11234) | TIME: 0:00:47 |
[VALID F2] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.10301 (0.11224) | TIME: 0:01:10 |
[VALID F2] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.10919 (0.11522) | TIME: 0:01:33 |
[VALID F2] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.07198 (0.11321) | TIME: 0:01:56 |
[VALID F2] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.04814 (0.11654) | TIME: 0:02:19 |
[VALID F2] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.04857 (0.11620) | TIME: 0:02:42 |
[VALID F2] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.10541 (0.11585) | TIME: 0:03:05 |
[VALID F2] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.15057 (0.11669) | TIME: 0:03:28 |
[VALID F2] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.06713 (0.11633) | TIME: 0:03:51 |
[VALID F2] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.20349 (0.11700) | TIME: 0:04:14 |
[VALID F2] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.13924 (0.11677) | TIME: 0:04:36 |
[VALID F2] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.18683 (0.11632) | TIME: 0:04:41 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.24258 |      0.11632 |  0.48378 | 0.509 | 0.479 | 0.438 | 0.458 | 0.516 | 0.502 | 1:12:03 |


[SAVED] EPOCH: 1 | MCRMSE: 0.4837784469127655

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 2/4 | STEP: 0000/1466 | LOSS: 0.07854 (0.07854) | LR: 0.00001809 | TIME: 0:00:03 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0040/1466 | LOSS: 0.09945 (0.11642) | LR: 0.00001795 | TIME: 0:01:53 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0080/1466 | LOSS: 0.14747 (0.11930) | LR: 0.00001781 | TIME: 0:03:44 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0120/1466 | LOSS: 0.12394 (0.11859) | LR: 0.00001766 | TIME: 0:05:37 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0160/1466 | LOSS: 0.02056 (0.11730) | LR: 0.00001751 | TIME: 0:07:22 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0200/1466 | LOSS: 0.14125 (0.11768) | LR: 0.00001736 | TIME: 0:09:11 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0240/1466 | LOSS: 0.13516 (0.11551) | LR: 0.00001721 | TIME: 0:11:04 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0280/1466 | LOSS: 0.13708 (0.11411) | LR: 0.00001704 | TIME: 0:12:46 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0320/1466 | LOSS: 0.12077 (0.11480) | LR: 0.00001688 | TIME: 0:14:32 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0360/1466 | LOSS: 0.14579 (0.11534) | LR: 0.00001671 | TIME: 0:16:25 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0400/1466 | LOSS: 0.14290 (0.11686) | LR: 0.00001654 | TIME: 0:18:15 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0440/1466 | LOSS: 0.08493 (0.11740) | LR: 0.00001637 | TIME: 0:20:07 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0480/1466 | LOSS: 0.06154 (0.11806) | LR: 0.00001619 | TIME: 0:21:54 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0520/1466 | LOSS: 0.14324 (0.11750) | LR: 0.00001601 | TIME: 0:23:46 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0560/1466 | LOSS: 0.08060 (0.11780) | LR: 0.00001582 | TIME: 0:25:34 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0600/1466 | LOSS: 0.17740 (0.11866) | LR: 0.00001564 | TIME: 0:27:31 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0640/1466 | LOSS: 0.06445 (0.11794) | LR: 0.00001545 | TIME: 0:29:26 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0680/1466 | LOSS: 0.07794 (0.11769) | LR: 0.00001525 | TIME: 0:31:17 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0720/1466 | LOSS: 0.11387 (0.11808) | LR: 0.00001506 | TIME: 0:33:04 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0760/1466 | LOSS: 0.10484 (0.11735) | LR: 0.00001486 | TIME: 0:35:02 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0800/1466 | LOSS: 0.05369 (0.11716) | LR: 0.00001466 | TIME: 0:36:50 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0840/1466 | LOSS: 0.04210 (0.11699) | LR: 0.00001445 | TIME: 0:38:42 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0880/1466 | LOSS: 0.14600 (0.11738) | LR: 0.00001425 | TIME: 0:40:36 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0920/1466 | LOSS: 0.13470 (0.11718) | LR: 0.00001404 | TIME: 0:42:24 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0960/1466 | LOSS: 0.10163 (0.11722) | LR: 0.00001383 | TIME: 0:44:14 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1000/1466 | LOSS: 0.09694 (0.11720) | LR: 0.00001362 | TIME: 0:46:03 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1040/1466 | LOSS: 0.10761 (0.11657) | LR: 0.00001340 | TIME: 0:48:00 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1080/1466 | LOSS: 0.12775 (0.11651) | LR: 0.00001319 | TIME: 0:49:48 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1120/1466 | LOSS: 0.04506 (0.11624) | LR: 0.00001297 | TIME: 0:51:38 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1160/1466 | LOSS: 0.07808 (0.11668) | LR: 0.00001275 | TIME: 0:53:31 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1200/1466 | LOSS: 0.11534 (0.11683) | LR: 0.00001253 | TIME: 0:55:27 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1240/1466 | LOSS: 0.05244 (0.11665) | LR: 0.00001231 | TIME: 0:57:17 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1280/1466 | LOSS: 0.12657 (0.11657) | LR: 0.00001209 | TIME: 0:59:02 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1320/1466 | LOSS: 0.07692 (0.11658) | LR: 0.00001186 | TIME: 1:00:50 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1360/1466 | LOSS: 0.15584 (0.11670) | LR: 0.00001164 | TIME: 1:02:38 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1400/1466 | LOSS: 0.13356 (0.11642) | LR: 0.00001141 | TIME: 1:04:23 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1440/1466 | LOSS: 0.09062 (0.11643) | LR: 0.00001119 | TIME: 1:06:08 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1465/1466 | LOSS: 0.08446 (0.11692) | LR: 0.00001104 | TIME: 1:07:23 |

VALID_LOOP
[VALID F2] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.04451 (0.04451) | TIME: 0:00:01 |
[VALID F2] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.09811 (0.10366) | TIME: 0:00:24 |
[VALID F2] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.07774 (0.09807) | TIME: 0:00:47 |
[VALID F2] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.08882 (0.09749) | TIME: 0:01:10 |
[VALID F2] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.06546 (0.09980) | TIME: 0:01:33 |
[VALID F2] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.08747 (0.09902) | TIME: 0:01:56 |
[VALID F2] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.05566 (0.10162) | TIME: 0:02:19 |
[VALID F2] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.06796 (0.10095) | TIME: 0:02:42 |
[VALID F2] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.08623 (0.10076) | TIME: 0:03:05 |
[VALID F2] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.15402 (0.10167) | TIME: 0:03:27 |
[VALID F2] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.07343 (0.10177) | TIME: 0:03:50 |
[VALID F2] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.22025 (0.10238) | TIME: 0:04:13 |
[VALID F2] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.10956 (0.10242) | TIME: 0:04:36 |
[VALID F2] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.10486 (0.10205) | TIME: 0:04:41 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11692 |      0.10205 |  0.45242 | 0.482 | 0.452 | 0.409 | 0.459 | 0.473 | 0.440 | 1:12:04 |


[SAVED] EPOCH: 2 | MCRMSE: 0.45241808891296387

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 3/4 | STEP: 0000/1466 | LOSS: 0.04957 (0.04957) | LR: 0.00001104 | TIME: 0:00:04 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0040/1466 | LOSS: 0.08138 (0.11012) | LR: 0.00001081 | TIME: 0:01:57 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0080/1466 | LOSS: 0.07229 (0.10678) | LR: 0.00001058 | TIME: 0:03:53 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0120/1466 | LOSS: 0.05123 (0.10756) | LR: 0.00001035 | TIME: 0:05:41 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0160/1466 | LOSS: 0.04042 (0.10369) | LR: 0.00001013 | TIME: 0:07:38 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0200/1466 | LOSS: 0.08849 (0.10208) | LR: 0.00000990 | TIME: 0:09:28 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0240/1466 | LOSS: 0.06493 (0.10130) | LR: 0.00000967 | TIME: 0:11:15 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0280/1466 | LOSS: 0.06815 (0.10019) | LR: 0.00000944 | TIME: 0:13:08 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0320/1466 | LOSS: 0.08689 (0.10136) | LR: 0.00000921 | TIME: 0:14:51 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0360/1466 | LOSS: 0.21060 (0.10108) | LR: 0.00000898 | TIME: 0:16:47 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0400/1466 | LOSS: 0.07421 (0.10072) | LR: 0.00000876 | TIME: 0:18:40 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0440/1466 | LOSS: 0.09932 (0.10119) | LR: 0.00000853 | TIME: 0:20:30 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0480/1466 | LOSS: 0.17657 (0.10080) | LR: 0.00000831 | TIME: 0:22:17 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0520/1466 | LOSS: 0.11724 (0.10001) | LR: 0.00000808 | TIME: 0:24:04 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0560/1466 | LOSS: 0.12063 (0.09989) | LR: 0.00000786 | TIME: 0:25:52 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0600/1466 | LOSS: 0.11885 (0.10018) | LR: 0.00000763 | TIME: 0:27:45 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0640/1466 | LOSS: 0.13940 (0.10089) | LR: 0.00000741 | TIME: 0:29:39 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0680/1466 | LOSS: 0.12404 (0.10076) | LR: 0.00000719 | TIME: 0:31:25 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0720/1466 | LOSS: 0.10347 (0.10103) | LR: 0.00000697 | TIME: 0:33:25 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0760/1466 | LOSS: 0.04217 (0.10032) | LR: 0.00000676 | TIME: 0:35:14 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0800/1466 | LOSS: 0.04378 (0.09982) | LR: 0.00000654 | TIME: 0:37:04 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0840/1466 | LOSS: 0.03543 (0.10024) | LR: 0.00000633 | TIME: 0:38:57 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0880/1466 | LOSS: 0.10183 (0.10088) | LR: 0.00000612 | TIME: 0:40:55 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0920/1466 | LOSS: 0.03565 (0.10092) | LR: 0.00000591 | TIME: 0:42:51 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0960/1466 | LOSS: 0.08418 (0.10077) | LR: 0.00000570 | TIME: 0:44:42 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1000/1466 | LOSS: 0.11572 (0.10130) | LR: 0.00000549 | TIME: 0:46:26 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1040/1466 | LOSS: 0.28229 (0.10125) | LR: 0.00000529 | TIME: 0:48:10 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1080/1466 | LOSS: 0.02624 (0.10050) | LR: 0.00000509 | TIME: 0:50:08 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1120/1466 | LOSS: 0.05081 (0.10017) | LR: 0.00000489 | TIME: 0:51:54 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1160/1466 | LOSS: 0.09391 (0.10013) | LR: 0.00000470 | TIME: 0:53:48 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1200/1466 | LOSS: 0.06056 (0.09993) | LR: 0.00000451 | TIME: 0:55:38 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1240/1466 | LOSS: 0.13650 (0.09996) | LR: 0.00000432 | TIME: 0:57:23 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1280/1466 | LOSS: 0.03879 (0.09952) | LR: 0.00000413 | TIME: 0:59:13 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1320/1466 | LOSS: 0.04465 (0.09904) | LR: 0.00000395 | TIME: 1:00:57 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1360/1466 | LOSS: 0.11986 (0.09866) | LR: 0.00000377 | TIME: 1:02:42 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1400/1466 | LOSS: 0.05700 (0.09791) | LR: 0.00000359 | TIME: 1:04:39 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1440/1466 | LOSS: 0.05285 (0.09748) | LR: 0.00000341 | TIME: 1:06:27 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1465/1466 | LOSS: 0.05387 (0.09727) | LR: 0.00000331 | TIME: 1:07:39 |

VALID_LOOP
[VALID F2] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.04064 (0.04064) | TIME: 0:00:01 |
[VALID F2] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.11690 (0.10278) | TIME: 0:00:24 |
[VALID F2] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.07365 (0.09619) | TIME: 0:00:47 |
[VALID F2] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.06409 (0.09627) | TIME: 0:01:10 |
[VALID F2] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.08973 (0.09727) | TIME: 0:01:32 |
[VALID F2] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.07269 (0.09653) | TIME: 0:01:55 |
[VALID F2] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.06483 (0.09932) | TIME: 0:02:18 |
[VALID F2] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.04611 (0.09842) | TIME: 0:02:41 |
[VALID F2] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.09677 (0.09824) | TIME: 0:03:04 |
[VALID F2] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.16019 (0.09902) | TIME: 0:03:27 |
[VALID F2] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.07660 (0.09911) | TIME: 0:03:50 |
[VALID F2] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.21436 (0.09976) | TIME: 0:04:13 |
[VALID F2] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.11715 (0.10017) | TIME: 0:04:35 |
[VALID F2] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.11278 (0.09987) | TIME: 0:04:40 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.09727 |      0.09987 |  0.44752 | 0.469 | 0.452 | 0.409 | 0.445 | 0.475 | 0.436 | 1:12:19 |


[SAVED] EPOCH: 3 | MCRMSE: 0.4475215673446655

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 4/4 | STEP: 0000/1466 | LOSS: 0.06415 (0.06415) | LR: 0.00000330 | TIME: 0:00:04 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0040/1466 | LOSS: 0.07971 (0.08223) | LR: 0.00000314 | TIME: 0:01:51 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0080/1466 | LOSS: 0.06000 (0.07893) | LR: 0.00000297 | TIME: 0:03:38 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0120/1466 | LOSS: 0.03862 (0.08013) | LR: 0.00000281 | TIME: 0:05:24 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0160/1466 | LOSS: 0.05979 (0.08227) | LR: 0.00000265 | TIME: 0:07:11 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0200/1466 | LOSS: 0.06661 (0.08247) | LR: 0.00000250 | TIME: 0:09:08 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0240/1466 | LOSS: 0.04828 (0.08318) | LR: 0.00000235 | TIME: 0:11:01 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0280/1466 | LOSS: 0.07395 (0.08371) | LR: 0.00000221 | TIME: 0:12:51 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0320/1466 | LOSS: 0.07577 (0.08435) | LR: 0.00000207 | TIME: 0:14:46 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0360/1466 | LOSS: 0.06269 (0.08491) | LR: 0.00000193 | TIME: 0:16:30 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0400/1466 | LOSS: 0.07841 (0.08460) | LR: 0.00000180 | TIME: 0:18:25 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0440/1466 | LOSS: 0.05810 (0.08547) | LR: 0.00000167 | TIME: 0:20:18 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0480/1466 | LOSS: 0.13383 (0.08468) | LR: 0.00000154 | TIME: 0:22:13 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0520/1466 | LOSS: 0.13279 (0.08448) | LR: 0.00000142 | TIME: 0:24:11 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0560/1466 | LOSS: 0.04204 (0.08473) | LR: 0.00000131 | TIME: 0:25:59 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0600/1466 | LOSS: 0.09923 (0.08488) | LR: 0.00000120 | TIME: 0:27:36 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0640/1466 | LOSS: 0.06332 (0.08527) | LR: 0.00000109 | TIME: 0:29:25 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0680/1466 | LOSS: 0.05842 (0.08513) | LR: 0.00000099 | TIME: 0:31:13 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0720/1466 | LOSS: 0.12469 (0.08495) | LR: 0.00000089 | TIME: 0:32:59 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0760/1466 | LOSS: 0.06005 (0.08430) | LR: 0.00000080 | TIME: 0:34:43 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0800/1466 | LOSS: 0.06646 (0.08425) | LR: 0.00000071 | TIME: 0:36:35 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0840/1466 | LOSS: 0.04250 (0.08383) | LR: 0.00000063 | TIME: 0:38:29 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0880/1466 | LOSS: 0.10584 (0.08352) | LR: 0.00000055 | TIME: 0:40:16 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0920/1466 | LOSS: 0.04428 (0.08336) | LR: 0.00000048 | TIME: 0:42:03 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0960/1466 | LOSS: 0.01227 (0.08349) | LR: 0.00000041 | TIME: 0:43:52 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1000/1466 | LOSS: 0.09992 (0.08352) | LR: 0.00000035 | TIME: 0:45:36 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1040/1466 | LOSS: 0.04431 (0.08349) | LR: 0.00000029 | TIME: 0:47:23 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1080/1466 | LOSS: 0.11844 (0.08326) | LR: 0.00000024 | TIME: 0:49:19 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1120/1466 | LOSS: 0.05208 (0.08355) | LR: 0.00000019 | TIME: 0:51:13 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1160/1466 | LOSS: 0.12124 (0.08335) | LR: 0.00000015 | TIME: 0:53:07 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1200/1466 | LOSS: 0.04735 (0.08380) | LR: 0.00000011 | TIME: 0:55:04 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1240/1466 | LOSS: 0.18886 (0.08390) | LR: 0.00000008 | TIME: 0:56:47 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1280/1466 | LOSS: 0.09271 (0.08390) | LR: 0.00000006 | TIME: 0:58:37 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1320/1466 | LOSS: 0.06250 (0.08386) | LR: 0.00000003 | TIME: 1:00:37 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1360/1466 | LOSS: 0.13469 (0.08382) | LR: 0.00000002 | TIME: 1:02:27 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1400/1466 | LOSS: 0.09694 (0.08350) | LR: 0.00000001 | TIME: 1:04:18 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1440/1466 | LOSS: 0.09659 (0.08364) | LR: 0.00000000 | TIME: 1:06:11 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1465/1466 | LOSS: 0.12496 (0.08398) | LR: 0.00000000 | TIME: 1:07:23 |

VALID_LOOP
[VALID F2] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.03381 (0.03381) | TIME: 0:00:01 |
[VALID F2] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.10785 (0.10099) | TIME: 0:00:24 |
[VALID F2] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.06981 (0.09426) | TIME: 0:00:47 |
[VALID F2] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.07982 (0.09471) | TIME: 0:01:10 |
[VALID F2] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.08940 (0.09610) | TIME: 0:01:33 |
[VALID F2] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.06858 (0.09502) | TIME: 0:01:56 |
[VALID F2] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.06448 (0.09812) | TIME: 0:02:19 |
[VALID F2] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.04939 (0.09709) | TIME: 0:02:42 |
[VALID F2] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.08843 (0.09676) | TIME: 0:03:04 |
[VALID F2] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.14514 (0.09762) | TIME: 0:03:27 |
[VALID F2] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.07237 (0.09772) | TIME: 0:03:50 |
[VALID F2] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.19755 (0.09844) | TIME: 0:04:13 |
[VALID F2] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.12022 (0.09879) | TIME: 0:04:36 |
[VALID F2] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.10440 (0.09844) | TIME: 0:04:40 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.08398 |      0.09844 |  0.44427 | 0.467 | 0.446 | 0.405 | 0.445 | 0.468 | 0.434 | 1:12:04 |


[SAVED] EPOCH: 4 | MCRMSE: 0.4442712366580963


----------------------------------- FOLD 2 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.44427     0.46733   0.44613        0.4051        0.44492    0.46816        0.43398

################################### END OF FOlD 2 ###################################


Date: 2022-11-22 21:53:25.045474+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: allenai/longformer-large-4096
Model_config: LongformerConfig {
  "_name_or_path": "allenai/longformer-large-4096",
  "attention_mode": "longformer",
  "attention_probs_dropout_prob": 0.0,
  "attention_window": [
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "ignore_attention_mask": false,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 4098,
  "model_type": "longformer",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 1,
  "pooler_dropout": 0.0,
  "position_embedding_type": "absolute",
  "sep_token_id": 2,
  "transformers_version": "4.20.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Pooling_strategy: mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5864}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 1/4 | STEP: 0000/1466 | LOSS: 2.16065 (2.16065) | LR: 0.00000005 | TIME: 0:00:04 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0040/1466 | LOSS: 1.85500 (2.34389) | LR: 0.00000224 | TIME: 0:01:55 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0080/1466 | LOSS: 0.67614 (1.88405) | LR: 0.00000443 | TIME: 0:03:48 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0120/1466 | LOSS: 0.18161 (1.37410) | LR: 0.00000661 | TIME: 0:05:33 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0160/1466 | LOSS: 0.06831 (1.08119) | LR: 0.00000880 | TIME: 0:07:23 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0200/1466 | LOSS: 0.20466 (0.90611) | LR: 0.00001098 | TIME: 0:09:09 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0240/1466 | LOSS: 0.18200 (0.78550) | LR: 0.00001317 | TIME: 0:11:03 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0280/1466 | LOSS: 0.07949 (0.70023) | LR: 0.00001536 | TIME: 0:12:55 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0320/1466 | LOSS: 0.05753 (0.63137) | LR: 0.00001754 | TIME: 0:14:47 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0360/1466 | LOSS: 0.19832 (0.57967) | LR: 0.00001973 | TIME: 0:16:37 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0400/1466 | LOSS: 0.15968 (0.54501) | LR: 0.00002000 | TIME: 0:18:30 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0440/1466 | LOSS: 0.10986 (0.51188) | LR: 0.00001999 | TIME: 0:20:22 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0480/1466 | LOSS: 0.13872 (0.48249) | LR: 0.00001998 | TIME: 0:22:06 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0520/1466 | LOSS: 0.13535 (0.45918) | LR: 0.00001996 | TIME: 0:23:55 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0560/1466 | LOSS: 0.11246 (0.43664) | LR: 0.00001994 | TIME: 0:25:45 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0600/1466 | LOSS: 0.08159 (0.41699) | LR: 0.00001991 | TIME: 0:27:25 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0640/1466 | LOSS: 0.13765 (0.39901) | LR: 0.00001988 | TIME: 0:29:23 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0680/1466 | LOSS: 0.07765 (0.38441) | LR: 0.00001984 | TIME: 0:31:17 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0720/1466 | LOSS: 0.14120 (0.37106) | LR: 0.00001979 | TIME: 0:33:13 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0760/1466 | LOSS: 0.05960 (0.35783) | LR: 0.00001975 | TIME: 0:35:05 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0800/1466 | LOSS: 0.14412 (0.34632) | LR: 0.00001969 | TIME: 0:36:58 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0840/1466 | LOSS: 0.04796 (0.33697) | LR: 0.00001963 | TIME: 0:38:51 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0880/1466 | LOSS: 0.20907 (0.32779) | LR: 0.00001957 | TIME: 0:40:44 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0920/1466 | LOSS: 0.19128 (0.31937) | LR: 0.00001950 | TIME: 0:42:30 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0960/1466 | LOSS: 0.14252 (0.31268) | LR: 0.00001943 | TIME: 0:44:15 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1000/1466 | LOSS: 0.16167 (0.30521) | LR: 0.00001935 | TIME: 0:46:05 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1040/1466 | LOSS: 0.11610 (0.29879) | LR: 0.00001927 | TIME: 0:48:04 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1080/1466 | LOSS: 0.09950 (0.29185) | LR: 0.00001918 | TIME: 0:49:40 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1120/1466 | LOSS: 0.09604 (0.28590) | LR: 0.00001908 | TIME: 0:51:33 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1160/1466 | LOSS: 0.07727 (0.28138) | LR: 0.00001899 | TIME: 0:53:24 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1200/1466 | LOSS: 0.16820 (0.27617) | LR: 0.00001888 | TIME: 0:55:19 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1240/1466 | LOSS: 0.10379 (0.27116) | LR: 0.00001878 | TIME: 0:57:00 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1280/1466 | LOSS: 0.12399 (0.26684) | LR: 0.00001866 | TIME: 0:58:52 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1320/1466 | LOSS: 0.10564 (0.26238) | LR: 0.00001855 | TIME: 1:00:41 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1360/1466 | LOSS: 0.05813 (0.25840) | LR: 0.00001843 | TIME: 1:02:24 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1400/1466 | LOSS: 0.09052 (0.25481) | LR: 0.00001830 | TIME: 1:04:21 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1440/1466 | LOSS: 0.12941 (0.25126) | LR: 0.00001817 | TIME: 1:06:15 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1465/1466 | LOSS: 0.10503 (0.24913) | LR: 0.00001809 | TIME: 1:07:22 |

VALID_LOOP
[VALID F3] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.44721 (0.44721) | TIME: 0:00:01 |
[VALID F3] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.04939 (0.13126) | TIME: 0:00:24 |
[VALID F3] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.22252 (0.13110) | TIME: 0:00:47 |
[VALID F3] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.14282 (0.12486) | TIME: 0:01:10 |
[VALID F3] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.08538 (0.12325) | TIME: 0:01:33 |
[VALID F3] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.10386 (0.12163) | TIME: 0:01:57 |
[VALID F3] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.09195 (0.11636) | TIME: 0:02:20 |
[VALID F3] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.07767 (0.11853) | TIME: 0:02:43 |
[VALID F3] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.05377 (0.11903) | TIME: 0:03:06 |
[VALID F3] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.08355 (0.11714) | TIME: 0:03:29 |
[VALID F3] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.10349 (0.11719) | TIME: 0:03:52 |
[VALID F3] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.07975 (0.11734) | TIME: 0:04:15 |
[VALID F3] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.06324 (0.11547) | TIME: 0:04:38 |
[VALID F3] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.03313 (0.11537) | TIME: 0:04:42 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.24913 |      0.11537 |   0.4821 | 0.515 | 0.482 | 0.447 | 0.486 | 0.509 | 0.454 | 1:12:05 |


[SAVED] EPOCH: 1 | MCRMSE: 0.48210275173187256

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 2/4 | STEP: 0000/1466 | LOSS: 0.13180 (0.13180) | LR: 0.00001809 | TIME: 0:00:04 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0040/1466 | LOSS: 0.07850 (0.10938) | LR: 0.00001795 | TIME: 0:01:52 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0080/1466 | LOSS: 0.08948 (0.10711) | LR: 0.00001781 | TIME: 0:03:47 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0120/1466 | LOSS: 0.06959 (0.11294) | LR: 0.00001766 | TIME: 0:05:36 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0160/1466 | LOSS: 0.05881 (0.11307) | LR: 0.00001751 | TIME: 0:07:17 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0200/1466 | LOSS: 0.23758 (0.11774) | LR: 0.00001736 | TIME: 0:09:04 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0240/1466 | LOSS: 0.10587 (0.11710) | LR: 0.00001721 | TIME: 0:10:51 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0280/1466 | LOSS: 0.11194 (0.11763) | LR: 0.00001704 | TIME: 0:12:43 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0320/1466 | LOSS: 0.14799 (0.11744) | LR: 0.00001688 | TIME: 0:14:40 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0360/1466 | LOSS: 0.14737 (0.11773) | LR: 0.00001671 | TIME: 0:16:28 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0400/1466 | LOSS: 0.13768 (0.11896) | LR: 0.00001654 | TIME: 0:18:10 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0440/1466 | LOSS: 0.05984 (0.11752) | LR: 0.00001637 | TIME: 0:19:56 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0480/1466 | LOSS: 0.06926 (0.11653) | LR: 0.00001619 | TIME: 0:21:40 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0520/1466 | LOSS: 0.16810 (0.11742) | LR: 0.00001601 | TIME: 0:23:30 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0560/1466 | LOSS: 0.08711 (0.11726) | LR: 0.00001582 | TIME: 0:25:19 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0600/1466 | LOSS: 0.11169 (0.11722) | LR: 0.00001564 | TIME: 0:27:09 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0640/1466 | LOSS: 0.15146 (0.11820) | LR: 0.00001545 | TIME: 0:28:53 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0680/1466 | LOSS: 0.16426 (0.11760) | LR: 0.00001525 | TIME: 0:30:45 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0720/1466 | LOSS: 0.19434 (0.11701) | LR: 0.00001506 | TIME: 0:32:41 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0760/1466 | LOSS: 0.11089 (0.11691) | LR: 0.00001486 | TIME: 0:34:25 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0800/1466 | LOSS: 0.12801 (0.11644) | LR: 0.00001466 | TIME: 0:36:21 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0840/1466 | LOSS: 0.09813 (0.11624) | LR: 0.00001445 | TIME: 0:38:12 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0880/1466 | LOSS: 0.09470 (0.11564) | LR: 0.00001425 | TIME: 0:39:58 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0920/1466 | LOSS: 0.05558 (0.11470) | LR: 0.00001404 | TIME: 0:41:47 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0960/1466 | LOSS: 0.11985 (0.11520) | LR: 0.00001383 | TIME: 0:43:41 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1000/1466 | LOSS: 0.09893 (0.11541) | LR: 0.00001362 | TIME: 0:45:28 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1040/1466 | LOSS: 0.13079 (0.11505) | LR: 0.00001340 | TIME: 0:47:17 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1080/1466 | LOSS: 0.07721 (0.11580) | LR: 0.00001319 | TIME: 0:49:05 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1120/1466 | LOSS: 0.11095 (0.11573) | LR: 0.00001297 | TIME: 0:50:52 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1160/1466 | LOSS: 0.07099 (0.11563) | LR: 0.00001275 | TIME: 0:52:34 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1200/1466 | LOSS: 0.17684 (0.11587) | LR: 0.00001253 | TIME: 0:54:16 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1240/1466 | LOSS: 0.15606 (0.11586) | LR: 0.00001231 | TIME: 0:56:09 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1280/1466 | LOSS: 0.08183 (0.11619) | LR: 0.00001209 | TIME: 0:57:52 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1320/1466 | LOSS: 0.14499 (0.11598) | LR: 0.00001186 | TIME: 0:59:33 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1360/1466 | LOSS: 0.17251 (0.11603) | LR: 0.00001164 | TIME: 1:01:35 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1400/1466 | LOSS: 0.06413 (0.11625) | LR: 0.00001141 | TIME: 1:03:20 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1440/1466 | LOSS: 0.14107 (0.11619) | LR: 0.00001119 | TIME: 1:05:23 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1465/1466 | LOSS: 0.03257 (0.11591) | LR: 0.00001104 | TIME: 1:06:35 |

VALID_LOOP
[VALID F3] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.24690 (0.24690) | TIME: 0:00:01 |
[VALID F3] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.08242 (0.11967) | TIME: 0:00:24 |
[VALID F3] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.12366 (0.12234) | TIME: 0:00:47 |
[VALID F3] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.21351 (0.11761) | TIME: 0:01:10 |
[VALID F3] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.07594 (0.11719) | TIME: 0:01:33 |
[VALID F3] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.19335 (0.11585) | TIME: 0:01:56 |
[VALID F3] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.16580 (0.11480) | TIME: 0:02:19 |
[VALID F3] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.10047 (0.11930) | TIME: 0:02:42 |
[VALID F3] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.16860 (0.11999) | TIME: 0:03:05 |
[VALID F3] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.08761 (0.11915) | TIME: 0:03:28 |
[VALID F3] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.10215 (0.11976) | TIME: 0:03:51 |
[VALID F3] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.09238 (0.12146) | TIME: 0:04:14 |
[VALID F3] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.05191 (0.12151) | TIME: 0:04:38 |
[VALID F3] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.05306 (0.12139) | TIME: 0:04:42 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11591 |      0.12139 |  0.49315 | 0.536 | 0.454 | 0.427 | 0.469 | 0.537 | 0.537 | 1:11:17 |

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 3/4 | STEP: 0000/1466 | LOSS: 0.11317 (0.11317) | LR: 0.00001104 | TIME: 0:00:04 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0040/1466 | LOSS: 0.05134 (0.10535) | LR: 0.00001081 | TIME: 0:01:54 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0080/1466 | LOSS: 0.10183 (0.09973) | LR: 0.00001058 | TIME: 0:03:44 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0120/1466 | LOSS: 0.04212 (0.09855) | LR: 0.00001035 | TIME: 0:05:37 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0160/1466 | LOSS: 0.10801 (0.09486) | LR: 0.00001013 | TIME: 0:07:21 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0200/1466 | LOSS: 0.14237 (0.09910) | LR: 0.00000990 | TIME: 0:09:13 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0240/1466 | LOSS: 0.09628 (0.09769) | LR: 0.00000967 | TIME: 0:11:06 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0280/1466 | LOSS: 0.12315 (0.09804) | LR: 0.00000944 | TIME: 0:12:53 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0320/1466 | LOSS: 0.07842 (0.09882) | LR: 0.00000921 | TIME: 0:14:36 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0360/1466 | LOSS: 0.05163 (0.10024) | LR: 0.00000898 | TIME: 0:16:31 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0400/1466 | LOSS: 0.09598 (0.10031) | LR: 0.00000876 | TIME: 0:18:15 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0440/1466 | LOSS: 0.14887 (0.09992) | LR: 0.00000853 | TIME: 0:20:04 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0480/1466 | LOSS: 0.10804 (0.09983) | LR: 0.00000831 | TIME: 0:21:58 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0520/1466 | LOSS: 0.04089 (0.10003) | LR: 0.00000808 | TIME: 0:23:54 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0560/1466 | LOSS: 0.17242 (0.10038) | LR: 0.00000786 | TIME: 0:25:43 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0600/1466 | LOSS: 0.16710 (0.09992) | LR: 0.00000763 | TIME: 0:27:33 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0640/1466 | LOSS: 0.05327 (0.09958) | LR: 0.00000741 | TIME: 0:29:26 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0680/1466 | LOSS: 0.07235 (0.10013) | LR: 0.00000719 | TIME: 0:31:16 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0720/1466 | LOSS: 0.02157 (0.10012) | LR: 0.00000697 | TIME: 0:33:03 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0760/1466 | LOSS: 0.07949 (0.09999) | LR: 0.00000676 | TIME: 0:34:50 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0800/1466 | LOSS: 0.07198 (0.10005) | LR: 0.00000654 | TIME: 0:36:45 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0840/1466 | LOSS: 0.15812 (0.09959) | LR: 0.00000633 | TIME: 0:38:35 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0880/1466 | LOSS: 0.07181 (0.09959) | LR: 0.00000612 | TIME: 0:40:24 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0920/1466 | LOSS: 0.18423 (0.09970) | LR: 0.00000591 | TIME: 0:42:18 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0960/1466 | LOSS: 0.06463 (0.09961) | LR: 0.00000570 | TIME: 0:44:07 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1000/1466 | LOSS: 0.12049 (0.09928) | LR: 0.00000549 | TIME: 0:46:00 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1040/1466 | LOSS: 0.08726 (0.09956) | LR: 0.00000529 | TIME: 0:47:50 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1080/1466 | LOSS: 0.06579 (0.09905) | LR: 0.00000509 | TIME: 0:49:26 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1120/1466 | LOSS: 0.06742 (0.09867) | LR: 0.00000489 | TIME: 0:51:15 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1160/1466 | LOSS: 0.12069 (0.09845) | LR: 0.00000470 | TIME: 0:53:07 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1200/1466 | LOSS: 0.10420 (0.09883) | LR: 0.00000451 | TIME: 0:54:56 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1240/1466 | LOSS: 0.13384 (0.09903) | LR: 0.00000432 | TIME: 0:56:48 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1280/1466 | LOSS: 0.07120 (0.09890) | LR: 0.00000413 | TIME: 0:58:39 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1320/1466 | LOSS: 0.06015 (0.09896) | LR: 0.00000395 | TIME: 1:00:29 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1360/1466 | LOSS: 0.05136 (0.09850) | LR: 0.00000377 | TIME: 1:02:22 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1400/1466 | LOSS: 0.07534 (0.09847) | LR: 0.00000359 | TIME: 1:04:11 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1440/1466 | LOSS: 0.10333 (0.09825) | LR: 0.00000341 | TIME: 1:05:55 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1465/1466 | LOSS: 0.12493 (0.09832) | LR: 0.00000331 | TIME: 1:07:00 |

VALID_LOOP
[VALID F3] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.37157 (0.37157) | TIME: 0:00:01 |
[VALID F3] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.05880 (0.11189) | TIME: 0:00:24 |
[VALID F3] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.16544 (0.11187) | TIME: 0:00:47 |
[VALID F3] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.12282 (0.10650) | TIME: 0:01:10 |
[VALID F3] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.07664 (0.10562) | TIME: 0:01:33 |
[VALID F3] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.11492 (0.10355) | TIME: 0:01:56 |
[VALID F3] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.12574 (0.10102) | TIME: 0:02:19 |
[VALID F3] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.05141 (0.10437) | TIME: 0:02:42 |
[VALID F3] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.08992 (0.10532) | TIME: 0:03:05 |
[VALID F3] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.07783 (0.10397) | TIME: 0:03:28 |
[VALID F3] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.09023 (0.10476) | TIME: 0:03:51 |
[VALID F3] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.07067 (0.10498) | TIME: 0:04:14 |
[VALID F3] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.05139 (0.10385) | TIME: 0:04:37 |
[VALID F3] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.03789 (0.10380) | TIME: 0:04:42 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.09832 |       0.1038 |   0.4566 | 0.477 | 0.464 | 0.421 | 0.453 | 0.480 | 0.445 | 1:11:42 |


[SAVED] EPOCH: 3 | MCRMSE: 0.45659664273262024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 4/4 | STEP: 0000/1466 | LOSS: 0.04441 (0.04441) | LR: 0.00000330 | TIME: 0:00:02 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0040/1466 | LOSS: 0.12952 (0.07898) | LR: 0.00000314 | TIME: 0:01:47 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0080/1466 | LOSS: 0.04839 (0.08880) | LR: 0.00000297 | TIME: 0:03:36 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0120/1466 | LOSS: 0.16087 (0.08714) | LR: 0.00000281 | TIME: 0:05:24 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0160/1466 | LOSS: 0.06204 (0.08835) | LR: 0.00000265 | TIME: 0:07:09 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0200/1466 | LOSS: 0.03699 (0.08868) | LR: 0.00000250 | TIME: 0:08:56 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0240/1466 | LOSS: 0.09970 (0.08714) | LR: 0.00000235 | TIME: 0:10:47 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0280/1466 | LOSS: 0.05645 (0.08862) | LR: 0.00000221 | TIME: 0:12:39 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0320/1466 | LOSS: 0.08330 (0.08801) | LR: 0.00000207 | TIME: 0:14:23 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0360/1466 | LOSS: 0.02217 (0.08734) | LR: 0.00000193 | TIME: 0:16:10 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0400/1466 | LOSS: 0.06229 (0.08671) | LR: 0.00000180 | TIME: 0:18:00 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0440/1466 | LOSS: 0.03269 (0.08632) | LR: 0.00000167 | TIME: 0:19:50 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0480/1466 | LOSS: 0.06389 (0.08632) | LR: 0.00000154 | TIME: 0:21:33 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0520/1466 | LOSS: 0.07379 (0.08682) | LR: 0.00000142 | TIME: 0:23:21 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0560/1466 | LOSS: 0.05408 (0.08654) | LR: 0.00000131 | TIME: 0:25:09 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0600/1466 | LOSS: 0.06810 (0.08699) | LR: 0.00000120 | TIME: 0:26:58 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0640/1466 | LOSS: 0.07559 (0.08688) | LR: 0.00000109 | TIME: 0:28:44 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0680/1466 | LOSS: 0.05189 (0.08659) | LR: 0.00000099 | TIME: 0:30:28 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0720/1466 | LOSS: 0.17489 (0.08676) | LR: 0.00000089 | TIME: 0:32:25 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0760/1466 | LOSS: 0.05070 (0.08647) | LR: 0.00000080 | TIME: 0:34:13 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0800/1466 | LOSS: 0.16150 (0.08600) | LR: 0.00000071 | TIME: 0:36:04 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0840/1466 | LOSS: 0.04961 (0.08581) | LR: 0.00000063 | TIME: 0:37:53 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0880/1466 | LOSS: 0.12575 (0.08565) | LR: 0.00000055 | TIME: 0:39:43 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0920/1466 | LOSS: 0.09118 (0.08627) | LR: 0.00000048 | TIME: 0:41:34 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0960/1466 | LOSS: 0.09849 (0.08645) | LR: 0.00000041 | TIME: 0:43:26 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1000/1466 | LOSS: 0.07019 (0.08634) | LR: 0.00000035 | TIME: 0:45:21 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1040/1466 | LOSS: 0.10836 (0.08634) | LR: 0.00000029 | TIME: 0:47:06 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1080/1466 | LOSS: 0.07923 (0.08574) | LR: 0.00000024 | TIME: 0:49:08 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1120/1466 | LOSS: 0.10688 (0.08579) | LR: 0.00000019 | TIME: 0:50:58 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1160/1466 | LOSS: 0.07755 (0.08552) | LR: 0.00000015 | TIME: 0:52:45 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1200/1466 | LOSS: 0.08625 (0.08530) | LR: 0.00000011 | TIME: 0:54:32 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1240/1466 | LOSS: 0.05990 (0.08498) | LR: 0.00000008 | TIME: 0:56:21 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1280/1466 | LOSS: 0.04025 (0.08486) | LR: 0.00000006 | TIME: 0:58:15 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1320/1466 | LOSS: 0.07492 (0.08479) | LR: 0.00000003 | TIME: 1:00:14 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1360/1466 | LOSS: 0.08168 (0.08502) | LR: 0.00000002 | TIME: 1:02:08 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1400/1466 | LOSS: 0.13480 (0.08490) | LR: 0.00000001 | TIME: 1:04:02 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1440/1466 | LOSS: 0.11012 (0.08485) | LR: 0.00000000 | TIME: 1:05:55 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1465/1466 | LOSS: 0.06118 (0.08492) | LR: 0.00000000 | TIME: 1:07:01 |

VALID_LOOP
[VALID F3] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.33735 (0.33735) | TIME: 0:00:01 |
[VALID F3] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.05625 (0.10446) | TIME: 0:00:24 |
[VALID F3] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.14507 (0.10752) | TIME: 0:00:47 |
[VALID F3] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.13821 (0.10348) | TIME: 0:01:10 |
[VALID F3] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.07316 (0.10271) | TIME: 0:01:33 |
[VALID F3] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.13902 (0.10082) | TIME: 0:01:56 |
[VALID F3] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.14137 (0.09826) | TIME: 0:02:19 |
[VALID F3] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.05485 (0.10202) | TIME: 0:02:43 |
[VALID F3] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.10264 (0.10280) | TIME: 0:03:06 |
[VALID F3] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.07651 (0.10151) | TIME: 0:03:29 |
[VALID F3] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.08813 (0.10218) | TIME: 0:03:52 |
[VALID F3] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.06815 (0.10247) | TIME: 0:04:15 |
[VALID F3] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.04935 (0.10161) | TIME: 0:04:38 |
[VALID F3] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.04037 (0.10157) | TIME: 0:04:43 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.08492 |      0.10157 |  0.45158 | 0.474 | 0.447 | 0.420 | 0.453 | 0.474 | 0.442 | 1:11:45 |


[SAVED] EPOCH: 4 | MCRMSE: 0.45158207416534424


----------------------------------- FOLD 3 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.45158     0.47391   0.44735       0.42005        0.45258    0.47361          0.442

################################### END OF FOlD 3 ###################################


