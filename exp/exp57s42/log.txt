Date: 2022-11-20 23:29:41.107954+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: allenai/longformer-large-4096
Model_config: LongformerConfig {
  "_name_or_path": "allenai/longformer-large-4096",
  "attention_mode": "longformer",
  "attention_probs_dropout_prob": 0.0,
  "attention_window": [
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "ignore_attention_mask": false,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 4098,
  "model_type": "longformer",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 1,
  "pooler_dropout": 0.0,
  "position_embedding_type": "absolute",
  "sep_token_id": 2,
  "transformers_version": "4.20.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Pooling_strategy: mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5864}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 1/4 | STEP: 0000/1466 | LOSS: 2.35506 (2.35506) | LR: 0.00000005 | TIME: 0:00:03 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0040/1466 | LOSS: 2.69823 (2.37064) | LR: 0.00000224 | TIME: 0:01:41 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0080/1466 | LOSS: 0.65138 (1.87191) | LR: 0.00000443 | TIME: 0:03:27 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0120/1466 | LOSS: 0.03422 (1.33516) | LR: 0.00000661 | TIME: 0:05:03 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0160/1466 | LOSS: 0.42860 (1.06342) | LR: 0.00000880 | TIME: 0:06:45 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0200/1466 | LOSS: 0.05936 (0.88691) | LR: 0.00001098 | TIME: 0:08:27 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0240/1466 | LOSS: 0.17737 (0.76643) | LR: 0.00001317 | TIME: 0:10:09 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0280/1466 | LOSS: 0.26837 (0.68267) | LR: 0.00001536 | TIME: 0:11:51 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0320/1466 | LOSS: 0.08057 (0.61654) | LR: 0.00001754 | TIME: 0:13:24 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0360/1466 | LOSS: 0.26055 (0.56386) | LR: 0.00001973 | TIME: 0:15:04 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0400/1466 | LOSS: 0.11660 (0.52406) | LR: 0.00002000 | TIME: 0:16:45 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0440/1466 | LOSS: 0.04510 (0.49048) | LR: 0.00001999 | TIME: 0:18:23 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0480/1466 | LOSS: 0.16101 (0.46109) | LR: 0.00001998 | TIME: 0:20:03 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0520/1466 | LOSS: 0.12010 (0.43622) | LR: 0.00001996 | TIME: 0:21:39 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0560/1466 | LOSS: 0.29975 (0.41712) | LR: 0.00001994 | TIME: 0:23:20 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0600/1466 | LOSS: 0.15865 (0.39785) | LR: 0.00001991 | TIME: 0:25:01 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0640/1466 | LOSS: 0.14588 (0.38043) | LR: 0.00001988 | TIME: 0:26:41 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0680/1466 | LOSS: 0.28718 (0.36636) | LR: 0.00001984 | TIME: 0:28:17 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0720/1466 | LOSS: 0.19153 (0.35442) | LR: 0.00001979 | TIME: 0:29:53 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0760/1466 | LOSS: 0.05360 (0.34323) | LR: 0.00001975 | TIME: 0:31:30 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0800/1466 | LOSS: 0.12293 (0.33288) | LR: 0.00001969 | TIME: 0:33:12 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0840/1466 | LOSS: 0.27530 (0.32420) | LR: 0.00001963 | TIME: 0:34:46 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0880/1466 | LOSS: 0.09617 (0.31563) | LR: 0.00001957 | TIME: 0:36:29 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0920/1466 | LOSS: 0.07816 (0.30821) | LR: 0.00001950 | TIME: 0:38:14 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0960/1466 | LOSS: 0.13242 (0.30069) | LR: 0.00001943 | TIME: 0:39:48 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1000/1466 | LOSS: 0.02435 (0.29411) | LR: 0.00001935 | TIME: 0:41:32 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1040/1466 | LOSS: 0.11880 (0.28776) | LR: 0.00001927 | TIME: 0:43:07 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1080/1466 | LOSS: 0.04223 (0.28182) | LR: 0.00001918 | TIME: 0:44:47 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1120/1466 | LOSS: 0.13305 (0.27623) | LR: 0.00001908 | TIME: 0:46:23 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1160/1466 | LOSS: 0.09719 (0.27096) | LR: 0.00001899 | TIME: 0:48:00 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1200/1466 | LOSS: 0.24508 (0.26718) | LR: 0.00001888 | TIME: 0:49:37 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1240/1466 | LOSS: 0.04800 (0.26295) | LR: 0.00001878 | TIME: 0:51:13 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1280/1466 | LOSS: 0.19098 (0.25860) | LR: 0.00001866 | TIME: 0:52:51 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1320/1466 | LOSS: 0.09692 (0.25497) | LR: 0.00001855 | TIME: 0:54:36 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1360/1466 | LOSS: 0.21471 (0.25156) | LR: 0.00001843 | TIME: 0:56:13 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1400/1466 | LOSS: 0.07647 (0.24821) | LR: 0.00001830 | TIME: 0:58:01 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1440/1466 | LOSS: 0.13634 (0.24486) | LR: 0.00001817 | TIME: 0:59:43 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1465/1466 | LOSS: 0.12860 (0.24302) | LR: 0.00001809 | TIME: 1:00:46 |

VALID_LOOP
[VALID F0] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.09632 (0.09632) | TIME: 0:00:01 |
[VALID F0] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.07491 (0.12659) | TIME: 0:00:14 |
[VALID F0] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.18729 (0.11754) | TIME: 0:00:27 |
[VALID F0] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.05017 (0.11436) | TIME: 0:00:41 |
[VALID F0] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.11711 (0.11514) | TIME: 0:00:54 |
[VALID F0] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.10635 (0.11246) | TIME: 0:01:07 |
[VALID F0] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.08621 (0.11285) | TIME: 0:01:20 |
[VALID F0] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.06176 (0.11519) | TIME: 0:01:34 |
[VALID F0] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.08859 (0.11426) | TIME: 0:01:47 |
[VALID F0] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.11583 (0.11415) | TIME: 0:02:00 |
[VALID F0] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.14328 (0.11533) | TIME: 0:02:14 |
[VALID F0] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.08640 (0.11664) | TIME: 0:02:27 |
[VALID F0] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.17394 (0.11718) | TIME: 0:02:40 |
[VALID F0] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.17059 (0.11726) | TIME: 0:02:43 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.24302 |      0.11726 |  0.48276 | 0.596 | 0.454 | 0.418 | 0.458 | 0.522 | 0.448 | 1:03:29 |


[SAVED] EPOCH: 1 | MCRMSE: 0.48276302218437195

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 2/4 | STEP: 0000/1466 | LOSS: 0.22134 (0.22134) | LR: 0.00001809 | TIME: 0:00:04 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0040/1466 | LOSS: 0.04881 (0.10373) | LR: 0.00001795 | TIME: 0:01:36 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0080/1466 | LOSS: 0.10515 (0.10938) | LR: 0.00001781 | TIME: 0:03:18 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0120/1466 | LOSS: 0.23520 (0.10819) | LR: 0.00001766 | TIME: 0:04:56 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0160/1466 | LOSS: 0.09132 (0.11272) | LR: 0.00001751 | TIME: 0:06:33 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0200/1466 | LOSS: 0.07252 (0.11167) | LR: 0.00001736 | TIME: 0:08:17 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0240/1466 | LOSS: 0.07247 (0.11314) | LR: 0.00001721 | TIME: 0:09:57 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0280/1466 | LOSS: 0.11100 (0.11507) | LR: 0.00001704 | TIME: 0:11:37 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0320/1466 | LOSS: 0.16373 (0.11565) | LR: 0.00001688 | TIME: 0:13:11 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0360/1466 | LOSS: 0.09735 (0.11466) | LR: 0.00001671 | TIME: 0:14:52 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0400/1466 | LOSS: 0.16704 (0.11397) | LR: 0.00001654 | TIME: 0:16:26 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0440/1466 | LOSS: 0.15902 (0.11405) | LR: 0.00001637 | TIME: 0:18:03 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0480/1466 | LOSS: 0.12671 (0.11570) | LR: 0.00001619 | TIME: 0:19:35 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0520/1466 | LOSS: 0.11072 (0.11542) | LR: 0.00001601 | TIME: 0:21:17 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0560/1466 | LOSS: 0.20031 (0.11528) | LR: 0.00001582 | TIME: 0:22:55 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0600/1466 | LOSS: 0.46764 (0.11476) | LR: 0.00001564 | TIME: 0:24:40 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0640/1466 | LOSS: 0.14036 (0.11363) | LR: 0.00001545 | TIME: 0:26:22 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0680/1466 | LOSS: 0.06174 (0.11313) | LR: 0.00001525 | TIME: 0:27:56 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0720/1466 | LOSS: 0.16350 (0.11331) | LR: 0.00001506 | TIME: 0:29:36 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0760/1466 | LOSS: 0.19415 (0.11434) | LR: 0.00001486 | TIME: 0:31:23 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0800/1466 | LOSS: 0.08703 (0.11406) | LR: 0.00001466 | TIME: 0:33:02 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0840/1466 | LOSS: 0.10695 (0.11409) | LR: 0.00001445 | TIME: 0:34:43 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0880/1466 | LOSS: 0.15462 (0.11423) | LR: 0.00001425 | TIME: 0:36:27 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0920/1466 | LOSS: 0.17483 (0.11447) | LR: 0.00001404 | TIME: 0:38:00 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0960/1466 | LOSS: 0.02932 (0.11405) | LR: 0.00001383 | TIME: 0:39:43 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1000/1466 | LOSS: 0.08732 (0.11367) | LR: 0.00001362 | TIME: 0:41:23 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1040/1466 | LOSS: 0.16955 (0.11325) | LR: 0.00001340 | TIME: 0:43:03 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1080/1466 | LOSS: 0.20801 (0.11322) | LR: 0.00001319 | TIME: 0:44:49 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1120/1466 | LOSS: 0.10546 (0.11288) | LR: 0.00001297 | TIME: 0:46:29 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1160/1466 | LOSS: 0.06893 (0.11293) | LR: 0.00001275 | TIME: 0:48:10 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1200/1466 | LOSS: 0.18294 (0.11322) | LR: 0.00001253 | TIME: 0:49:52 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1240/1466 | LOSS: 0.08887 (0.11302) | LR: 0.00001231 | TIME: 0:51:28 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1280/1466 | LOSS: 0.13550 (0.11304) | LR: 0.00001209 | TIME: 0:53:07 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1320/1466 | LOSS: 0.08454 (0.11266) | LR: 0.00001186 | TIME: 0:54:45 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1360/1466 | LOSS: 0.11411 (0.11234) | LR: 0.00001164 | TIME: 0:56:17 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1400/1466 | LOSS: 0.11675 (0.11261) | LR: 0.00001141 | TIME: 0:57:53 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1440/1466 | LOSS: 0.10982 (0.11282) | LR: 0.00001119 | TIME: 0:59:33 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1465/1466 | LOSS: 0.06690 (0.11278) | LR: 0.00001104 | TIME: 1:00:36 |

VALID_LOOP
[VALID F0] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.05339 (0.05339) | TIME: 0:00:01 |
[VALID F0] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.06641 (0.11503) | TIME: 0:00:14 |
[VALID F0] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.11980 (0.10750) | TIME: 0:00:27 |
[VALID F0] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.06767 (0.10565) | TIME: 0:00:41 |
[VALID F0] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.10441 (0.10667) | TIME: 0:00:54 |
[VALID F0] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.11011 (0.10505) | TIME: 0:01:07 |
[VALID F0] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.07549 (0.10520) | TIME: 0:01:20 |
[VALID F0] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.09520 (0.10758) | TIME: 0:01:34 |
[VALID F0] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.10796 (0.10676) | TIME: 0:01:47 |
[VALID F0] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.07389 (0.10604) | TIME: 0:02:00 |
[VALID F0] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.12011 (0.10710) | TIME: 0:02:14 |
[VALID F0] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.10295 (0.10763) | TIME: 0:02:27 |
[VALID F0] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.10791 (0.10726) | TIME: 0:02:40 |
[VALID F0] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.08378 (0.10721) | TIME: 0:02:43 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11278 |      0.10721 |  0.46377 | 0.490 | 0.458 | 0.431 | 0.490 | 0.469 | 0.445 | 1:03:19 |


[SAVED] EPOCH: 2 | MCRMSE: 0.4637662470340729

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 3/4 | STEP: 0000/1466 | LOSS: 0.12001 (0.12001) | LR: 0.00001104 | TIME: 0:00:02 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0040/1466 | LOSS: 0.10522 (0.10131) | LR: 0.00001081 | TIME: 0:01:39 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0080/1466 | LOSS: 0.16531 (0.09744) | LR: 0.00001058 | TIME: 0:03:15 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0120/1466 | LOSS: 0.07360 (0.09586) | LR: 0.00001035 | TIME: 0:04:52 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0160/1466 | LOSS: 0.05320 (0.09467) | LR: 0.00001013 | TIME: 0:06:19 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0200/1466 | LOSS: 0.03046 (0.09422) | LR: 0.00000990 | TIME: 0:07:50 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0240/1466 | LOSS: 0.09559 (0.09456) | LR: 0.00000967 | TIME: 0:09:30 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0280/1466 | LOSS: 0.06853 (0.09560) | LR: 0.00000944 | TIME: 0:11:10 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0320/1466 | LOSS: 0.10985 (0.09765) | LR: 0.00000921 | TIME: 0:12:49 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0360/1466 | LOSS: 0.08834 (0.09874) | LR: 0.00000898 | TIME: 0:14:29 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0400/1466 | LOSS: 0.05682 (0.09876) | LR: 0.00000876 | TIME: 0:16:03 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0440/1466 | LOSS: 0.06669 (0.09812) | LR: 0.00000853 | TIME: 0:17:46 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0480/1466 | LOSS: 0.10134 (0.09930) | LR: 0.00000831 | TIME: 0:19:32 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0520/1466 | LOSS: 0.09586 (0.09874) | LR: 0.00000808 | TIME: 0:21:10 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0560/1466 | LOSS: 0.09911 (0.09844) | LR: 0.00000786 | TIME: 0:22:54 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0600/1466 | LOSS: 0.09855 (0.09810) | LR: 0.00000763 | TIME: 0:24:32 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0640/1466 | LOSS: 0.03927 (0.09657) | LR: 0.00000741 | TIME: 0:26:06 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0680/1466 | LOSS: 0.06920 (0.09609) | LR: 0.00000719 | TIME: 0:27:47 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0720/1466 | LOSS: 0.09796 (0.09601) | LR: 0.00000697 | TIME: 0:29:29 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0760/1466 | LOSS: 0.11441 (0.09601) | LR: 0.00000676 | TIME: 0:31:11 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0800/1466 | LOSS: 0.08049 (0.09531) | LR: 0.00000654 | TIME: 0:32:49 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0840/1466 | LOSS: 0.04900 (0.09482) | LR: 0.00000633 | TIME: 0:34:32 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0880/1466 | LOSS: 0.04374 (0.09439) | LR: 0.00000612 | TIME: 0:36:12 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0920/1466 | LOSS: 0.03656 (0.09458) | LR: 0.00000591 | TIME: 0:37:54 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0960/1466 | LOSS: 0.10299 (0.09417) | LR: 0.00000570 | TIME: 0:39:32 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1000/1466 | LOSS: 0.09738 (0.09409) | LR: 0.00000549 | TIME: 0:41:11 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1040/1466 | LOSS: 0.11570 (0.09408) | LR: 0.00000529 | TIME: 0:42:53 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1080/1466 | LOSS: 0.11455 (0.09398) | LR: 0.00000509 | TIME: 0:44:37 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1120/1466 | LOSS: 0.07873 (0.09397) | LR: 0.00000489 | TIME: 0:46:18 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1160/1466 | LOSS: 0.12988 (0.09375) | LR: 0.00000470 | TIME: 0:47:59 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1200/1466 | LOSS: 0.15407 (0.09347) | LR: 0.00000451 | TIME: 0:49:39 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1240/1466 | LOSS: 0.12016 (0.09353) | LR: 0.00000432 | TIME: 0:51:16 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1280/1466 | LOSS: 0.06755 (0.09375) | LR: 0.00000413 | TIME: 0:52:55 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1320/1466 | LOSS: 0.06931 (0.09347) | LR: 0.00000395 | TIME: 0:54:36 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1360/1466 | LOSS: 0.08208 (0.09319) | LR: 0.00000377 | TIME: 0:56:19 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1400/1466 | LOSS: 0.14789 (0.09340) | LR: 0.00000359 | TIME: 0:57:54 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1440/1466 | LOSS: 0.06626 (0.09346) | LR: 0.00000341 | TIME: 0:59:37 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1465/1466 | LOSS: 0.06211 (0.09344) | LR: 0.00000331 | TIME: 1:00:44 |

VALID_LOOP
[VALID F0] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.06257 (0.06257) | TIME: 0:00:01 |
[VALID F0] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.05419 (0.10711) | TIME: 0:00:14 |
[VALID F0] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.14464 (0.10113) | TIME: 0:00:27 |
[VALID F0] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.03618 (0.09891) | TIME: 0:00:40 |
[VALID F0] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.13477 (0.09996) | TIME: 0:00:54 |
[VALID F0] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.10197 (0.09756) | TIME: 0:01:07 |
[VALID F0] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.07349 (0.09761) | TIME: 0:01:20 |
[VALID F0] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.07323 (0.10071) | TIME: 0:01:34 |
[VALID F0] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.08730 (0.09958) | TIME: 0:01:47 |
[VALID F0] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.08121 (0.09916) | TIME: 0:02:00 |
[VALID F0] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.11625 (0.09997) | TIME: 0:02:14 |
[VALID F0] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.09802 (0.10065) | TIME: 0:02:27 |
[VALID F0] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.10773 (0.10057) | TIME: 0:02:40 |
[VALID F0] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.11463 (0.10061) | TIME: 0:02:43 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.09344 |      0.10061 |  0.44887 | 0.480 | 0.445 | 0.409 | 0.451 | 0.461 | 0.447 | 1:03:27 |


[SAVED] EPOCH: 3 | MCRMSE: 0.4488694965839386

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 4/4 | STEP: 0000/1466 | LOSS: 0.05358 (0.05358) | LR: 0.00000330 | TIME: 0:00:03 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0040/1466 | LOSS: 0.06740 (0.07084) | LR: 0.00000314 | TIME: 0:01:44 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0080/1466 | LOSS: 0.08522 (0.07218) | LR: 0.00000297 | TIME: 0:03:23 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0120/1466 | LOSS: 0.02994 (0.07706) | LR: 0.00000281 | TIME: 0:05:09 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0160/1466 | LOSS: 0.02454 (0.07580) | LR: 0.00000265 | TIME: 0:06:51 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0200/1466 | LOSS: 0.06781 (0.07797) | LR: 0.00000250 | TIME: 0:08:28 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0240/1466 | LOSS: 0.09215 (0.07755) | LR: 0.00000235 | TIME: 0:10:15 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0280/1466 | LOSS: 0.05752 (0.07670) | LR: 0.00000221 | TIME: 0:11:54 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0320/1466 | LOSS: 0.06595 (0.07727) | LR: 0.00000207 | TIME: 0:13:31 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0360/1466 | LOSS: 0.06770 (0.07716) | LR: 0.00000193 | TIME: 0:15:10 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0400/1466 | LOSS: 0.04082 (0.07680) | LR: 0.00000180 | TIME: 0:16:45 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0440/1466 | LOSS: 0.09181 (0.07696) | LR: 0.00000167 | TIME: 0:18:17 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0480/1466 | LOSS: 0.04015 (0.07766) | LR: 0.00000154 | TIME: 0:20:00 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0520/1466 | LOSS: 0.06752 (0.07733) | LR: 0.00000142 | TIME: 0:21:40 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0560/1466 | LOSS: 0.05240 (0.07756) | LR: 0.00000131 | TIME: 0:23:17 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0600/1466 | LOSS: 0.06287 (0.07788) | LR: 0.00000120 | TIME: 0:24:51 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0640/1466 | LOSS: 0.04101 (0.07812) | LR: 0.00000109 | TIME: 0:26:30 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0680/1466 | LOSS: 0.05316 (0.07882) | LR: 0.00000099 | TIME: 0:28:13 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0720/1466 | LOSS: 0.10814 (0.07937) | LR: 0.00000089 | TIME: 0:29:47 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0760/1466 | LOSS: 0.10541 (0.07940) | LR: 0.00000080 | TIME: 0:31:27 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0800/1466 | LOSS: 0.09230 (0.07998) | LR: 0.00000071 | TIME: 0:33:07 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0840/1466 | LOSS: 0.09852 (0.07976) | LR: 0.00000063 | TIME: 0:34:45 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0880/1466 | LOSS: 0.03809 (0.07996) | LR: 0.00000055 | TIME: 0:36:23 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0920/1466 | LOSS: 0.05350 (0.07973) | LR: 0.00000048 | TIME: 0:38:03 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0960/1466 | LOSS: 0.04767 (0.08006) | LR: 0.00000041 | TIME: 0:39:43 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1000/1466 | LOSS: 0.13933 (0.08010) | LR: 0.00000035 | TIME: 0:41:23 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1040/1466 | LOSS: 0.04412 (0.07998) | LR: 0.00000029 | TIME: 0:42:54 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1080/1466 | LOSS: 0.02644 (0.07967) | LR: 0.00000024 | TIME: 0:44:30 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1120/1466 | LOSS: 0.04597 (0.08024) | LR: 0.00000019 | TIME: 0:46:12 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1160/1466 | LOSS: 0.04142 (0.08010) | LR: 0.00000015 | TIME: 0:47:52 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1200/1466 | LOSS: 0.12077 (0.08016) | LR: 0.00000011 | TIME: 0:49:33 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1240/1466 | LOSS: 0.13983 (0.07998) | LR: 0.00000008 | TIME: 0:51:16 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1280/1466 | LOSS: 0.03464 (0.08020) | LR: 0.00000006 | TIME: 0:52:53 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1320/1466 | LOSS: 0.04293 (0.08013) | LR: 0.00000003 | TIME: 0:54:31 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1360/1466 | LOSS: 0.05606 (0.08018) | LR: 0.00000002 | TIME: 0:56:06 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1400/1466 | LOSS: 0.11462 (0.08033) | LR: 0.00000001 | TIME: 0:57:49 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1440/1466 | LOSS: 0.03952 (0.08043) | LR: 0.00000000 | TIME: 0:59:27 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1465/1466 | LOSS: 0.02105 (0.08040) | LR: 0.00000000 | TIME: 1:00:32 |

VALID_LOOP
[VALID F0] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.06179 (0.06179) | TIME: 0:00:01 |
[VALID F0] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.05083 (0.10503) | TIME: 0:00:14 |
[VALID F0] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.12893 (0.09938) | TIME: 0:00:27 |
[VALID F0] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.03992 (0.09785) | TIME: 0:00:40 |
[VALID F0] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.11679 (0.09990) | TIME: 0:00:54 |
[VALID F0] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.10424 (0.09735) | TIME: 0:01:07 |
[VALID F0] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.07061 (0.09744) | TIME: 0:01:20 |
[VALID F0] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.08056 (0.10059) | TIME: 0:01:34 |
[VALID F0] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.08171 (0.09910) | TIME: 0:01:47 |
[VALID F0] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.08825 (0.09865) | TIME: 0:02:00 |
[VALID F0] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.11918 (0.09969) | TIME: 0:02:13 |
[VALID F0] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.10833 (0.10019) | TIME: 0:02:27 |
[VALID F0] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.10424 (0.09988) | TIME: 0:02:40 |
[VALID F0] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.09977 (0.09988) | TIME: 0:02:43 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |       0.0804 |      0.09988 |  0.44729 | 0.481 | 0.443 | 0.408 | 0.451 | 0.461 | 0.441 | 1:03:15 |


[SAVED] EPOCH: 4 | MCRMSE: 0.44728541374206543


----------------------------------- FOLD 0 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.44729     0.48081   0.44281       0.40776        0.45081    0.46054        0.44097

################################### END OF FOlD 0 ###################################


Date: 2022-11-21 17:48:10.815210+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: allenai/longformer-large-4096
Model_config: LongformerConfig {
  "_name_or_path": "allenai/longformer-large-4096",
  "attention_mode": "longformer",
  "attention_probs_dropout_prob": 0.0,
  "attention_window": [
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "ignore_attention_mask": false,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 4098,
  "model_type": "longformer",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 1,
  "pooler_dropout": 0.0,
  "position_embedding_type": "absolute",
  "sep_token_id": 2,
  "transformers_version": "4.20.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Pooling_strategy: mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5868}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 1/4 | STEP: 0000/1467 | LOSS: 2.28302 (2.28302) | LR: 0.00000005 | TIME: 0:00:02 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0040/1467 | LOSS: 2.38210 (2.29140) | LR: 0.00000224 | TIME: 0:01:55 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0080/1467 | LOSS: 0.12259 (1.81910) | LR: 0.00000443 | TIME: 0:03:42 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0120/1467 | LOSS: 0.11784 (1.31620) | LR: 0.00000661 | TIME: 0:05:36 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0160/1467 | LOSS: 0.12663 (1.03926) | LR: 0.00000880 | TIME: 0:07:23 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0200/1467 | LOSS: 0.04600 (0.86418) | LR: 0.00001098 | TIME: 0:09:08 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0240/1467 | LOSS: 0.06859 (0.74830) | LR: 0.00001317 | TIME: 0:10:52 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0280/1467 | LOSS: 0.07623 (0.66480) | LR: 0.00001536 | TIME: 0:12:39 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0320/1467 | LOSS: 0.11050 (0.59991) | LR: 0.00001754 | TIME: 0:14:23 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0360/1467 | LOSS: 0.06962 (0.55037) | LR: 0.00001973 | TIME: 0:16:12 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0400/1467 | LOSS: 0.30163 (0.51121) | LR: 0.00002000 | TIME: 0:18:01 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0440/1467 | LOSS: 0.53992 (0.47950) | LR: 0.00001999 | TIME: 0:19:51 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0480/1467 | LOSS: 0.11133 (0.45097) | LR: 0.00001998 | TIME: 0:21:42 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0520/1467 | LOSS: 0.13453 (0.42709) | LR: 0.00001996 | TIME: 0:23:33 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0560/1467 | LOSS: 0.16087 (0.40799) | LR: 0.00001994 | TIME: 0:25:23 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0600/1467 | LOSS: 0.13043 (0.39013) | LR: 0.00001991 | TIME: 0:27:14 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0640/1467 | LOSS: 0.06413 (0.37492) | LR: 0.00001988 | TIME: 0:29:00 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0680/1467 | LOSS: 0.08081 (0.36009) | LR: 0.00001984 | TIME: 0:30:49 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0720/1467 | LOSS: 0.11544 (0.34697) | LR: 0.00001980 | TIME: 0:32:32 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0760/1467 | LOSS: 0.15949 (0.33538) | LR: 0.00001975 | TIME: 0:34:23 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0800/1467 | LOSS: 0.18077 (0.32587) | LR: 0.00001969 | TIME: 0:36:15 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0840/1467 | LOSS: 0.03282 (0.31716) | LR: 0.00001963 | TIME: 0:37:56 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0880/1467 | LOSS: 0.05296 (0.30884) | LR: 0.00001957 | TIME: 0:39:43 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0920/1467 | LOSS: 0.10960 (0.30136) | LR: 0.00001950 | TIME: 0:41:37 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0960/1467 | LOSS: 0.14235 (0.29412) | LR: 0.00001943 | TIME: 0:43:23 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1000/1467 | LOSS: 0.11826 (0.28628) | LR: 0.00001935 | TIME: 0:45:07 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1040/1467 | LOSS: 0.26208 (0.27991) | LR: 0.00001927 | TIME: 0:46:58 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1080/1467 | LOSS: 0.08058 (0.27542) | LR: 0.00001918 | TIME: 0:48:52 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1120/1467 | LOSS: 0.19600 (0.27039) | LR: 0.00001909 | TIME: 0:50:44 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1160/1467 | LOSS: 0.06013 (0.26590) | LR: 0.00001899 | TIME: 0:52:36 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1200/1467 | LOSS: 0.04131 (0.26177) | LR: 0.00001888 | TIME: 0:54:32 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1240/1467 | LOSS: 0.41228 (0.25804) | LR: 0.00001878 | TIME: 0:56:26 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1280/1467 | LOSS: 0.11660 (0.25381) | LR: 0.00001867 | TIME: 0:58:13 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1320/1467 | LOSS: 0.18060 (0.25010) | LR: 0.00001855 | TIME: 1:00:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1360/1467 | LOSS: 0.11498 (0.24649) | LR: 0.00001843 | TIME: 1:01:43 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1400/1467 | LOSS: 0.45856 (0.24379) | LR: 0.00001830 | TIME: 1:03:34 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1440/1467 | LOSS: 0.14226 (0.24037) | LR: 0.00001817 | TIME: 1:05:30 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1466/1467 | LOSS: 0.20390 (0.23823) | LR: 0.00001809 | TIME: 1:06:36 |

VALID_LOOP
[VALID F1] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.07798 (0.07798) | TIME: 0:00:01 |
[VALID F1] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.14480 (0.11746) | TIME: 0:00:24 |
[VALID F1] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.05570 (0.11961) | TIME: 0:00:46 |
[VALID F1] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.13491 (0.12262) | TIME: 0:01:09 |
[VALID F1] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.09985 (0.12483) | TIME: 0:01:32 |
[VALID F1] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.06088 (0.11918) | TIME: 0:01:55 |
[VALID F1] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.15495 (0.12060) | TIME: 0:02:17 |
[VALID F1] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.12922 (0.12046) | TIME: 0:02:40 |
[VALID F1] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.09632 (0.12170) | TIME: 0:03:02 |
[VALID F1] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.07459 (0.12054) | TIME: 0:03:25 |
[VALID F1] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.16084 (0.11945) | TIME: 0:03:48 |
[VALID F1] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.11244 (0.12010) | TIME: 0:04:10 |
[VALID F1] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.07878 (0.11958) | TIME: 0:04:33 |
[VALID F1] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.06834 (0.11920) | TIME: 0:04:37 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.23823 |       0.1192 |  0.48934 | 0.525 | 0.462 | 0.456 | 0.466 | 0.545 | 0.483 | 1:11:14 |


[SAVED] EPOCH: 1 | MCRMSE: 0.48933926224708557

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 2/4 | STEP: 0000/1467 | LOSS: 0.07420 (0.07420) | LR: 0.00001808 | TIME: 0:00:04 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0040/1467 | LOSS: 0.06113 (0.11410) | LR: 0.00001795 | TIME: 0:01:52 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0080/1467 | LOSS: 0.07568 (0.11439) | LR: 0.00001781 | TIME: 0:03:42 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0120/1467 | LOSS: 0.12998 (0.11406) | LR: 0.00001766 | TIME: 0:05:33 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0160/1467 | LOSS: 0.13639 (0.11489) | LR: 0.00001751 | TIME: 0:07:17 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0200/1467 | LOSS: 0.04886 (0.11665) | LR: 0.00001736 | TIME: 0:09:12 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0240/1467 | LOSS: 0.12274 (0.12018) | LR: 0.00001721 | TIME: 0:11:03 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0280/1467 | LOSS: 0.09134 (0.11822) | LR: 0.00001704 | TIME: 0:12:38 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0320/1467 | LOSS: 0.06381 (0.11974) | LR: 0.00001688 | TIME: 0:14:29 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0360/1467 | LOSS: 0.15982 (0.12143) | LR: 0.00001671 | TIME: 0:16:24 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0400/1467 | LOSS: 0.14473 (0.12077) | LR: 0.00001654 | TIME: 0:18:16 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0440/1467 | LOSS: 0.13208 (0.12100) | LR: 0.00001637 | TIME: 0:20:04 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0480/1467 | LOSS: 0.23957 (0.12213) | LR: 0.00001619 | TIME: 0:22:00 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0520/1467 | LOSS: 0.08614 (0.12205) | LR: 0.00001601 | TIME: 0:23:49 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0560/1467 | LOSS: 0.28454 (0.12329) | LR: 0.00001583 | TIME: 0:25:36 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0600/1467 | LOSS: 0.10847 (0.12357) | LR: 0.00001564 | TIME: 0:27:18 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0640/1467 | LOSS: 0.04542 (0.12284) | LR: 0.00001545 | TIME: 0:29:14 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0680/1467 | LOSS: 0.16309 (0.12239) | LR: 0.00001525 | TIME: 0:30:59 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0720/1467 | LOSS: 0.08795 (0.12118) | LR: 0.00001506 | TIME: 0:32:51 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0760/1467 | LOSS: 0.13652 (0.12043) | LR: 0.00001486 | TIME: 0:34:36 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0800/1467 | LOSS: 0.17517 (0.12052) | LR: 0.00001466 | TIME: 0:36:31 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0840/1467 | LOSS: 0.17801 (0.12073) | LR: 0.00001446 | TIME: 0:38:25 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0880/1467 | LOSS: 0.09016 (0.12011) | LR: 0.00001425 | TIME: 0:40:10 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0920/1467 | LOSS: 0.02684 (0.12031) | LR: 0.00001404 | TIME: 0:41:58 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0960/1467 | LOSS: 0.08094 (0.11993) | LR: 0.00001383 | TIME: 0:43:41 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1000/1467 | LOSS: 0.16579 (0.11962) | LR: 0.00001362 | TIME: 0:45:26 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1040/1467 | LOSS: 0.08758 (0.11982) | LR: 0.00001341 | TIME: 0:47:18 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1080/1467 | LOSS: 0.05493 (0.11950) | LR: 0.00001319 | TIME: 0:49:03 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1120/1467 | LOSS: 0.19544 (0.11975) | LR: 0.00001297 | TIME: 0:50:53 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1160/1467 | LOSS: 0.05459 (0.11984) | LR: 0.00001276 | TIME: 0:52:46 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1200/1467 | LOSS: 0.27071 (0.11976) | LR: 0.00001254 | TIME: 0:54:33 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1240/1467 | LOSS: 0.06281 (0.11919) | LR: 0.00001231 | TIME: 0:56:17 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1280/1467 | LOSS: 0.08151 (0.11853) | LR: 0.00001209 | TIME: 0:58:11 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1320/1467 | LOSS: 0.34588 (0.11799) | LR: 0.00001187 | TIME: 0:59:59 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1360/1467 | LOSS: 0.18777 (0.11767) | LR: 0.00001164 | TIME: 1:01:44 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1400/1467 | LOSS: 0.17343 (0.11720) | LR: 0.00001142 | TIME: 1:03:25 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1440/1467 | LOSS: 0.29179 (0.11703) | LR: 0.00001119 | TIME: 1:05:20 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1466/1467 | LOSS: 0.13396 (0.11706) | LR: 0.00001104 | TIME: 1:06:34 |

VALID_LOOP
[VALID F1] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.08588 (0.08588) | TIME: 0:00:01 |
[VALID F1] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.12567 (0.10610) | TIME: 0:00:24 |
[VALID F1] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.05819 (0.10620) | TIME: 0:00:46 |
[VALID F1] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.09149 (0.10842) | TIME: 0:01:09 |
[VALID F1] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.09006 (0.11063) | TIME: 0:01:32 |
[VALID F1] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.04744 (0.10659) | TIME: 0:01:54 |
[VALID F1] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.13277 (0.10774) | TIME: 0:02:17 |
[VALID F1] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.09064 (0.10829) | TIME: 0:02:40 |
[VALID F1] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.09501 (0.10969) | TIME: 0:03:02 |
[VALID F1] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.06028 (0.10843) | TIME: 0:03:25 |
[VALID F1] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.11151 (0.10728) | TIME: 0:03:48 |
[VALID F1] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.12247 (0.10810) | TIME: 0:04:10 |
[VALID F1] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.09579 (0.10810) | TIME: 0:04:33 |
[VALID F1] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.07315 (0.10772) | TIME: 0:04:37 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11706 |      0.10772 |  0.46521 | 0.498 | 0.449 | 0.434 | 0.457 | 0.478 | 0.475 | 1:11:12 |


[SAVED] EPOCH: 2 | MCRMSE: 0.46521106362342834

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 3/4 | STEP: 0000/1467 | LOSS: 0.08403 (0.08403) | LR: 0.00001104 | TIME: 0:00:04 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0040/1467 | LOSS: 0.09713 (0.09906) | LR: 0.00001081 | TIME: 0:01:54 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0080/1467 | LOSS: 0.04053 (0.09707) | LR: 0.00001058 | TIME: 0:03:32 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0120/1467 | LOSS: 0.07999 (0.10418) | LR: 0.00001035 | TIME: 0:05:18 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0160/1467 | LOSS: 0.12716 (0.10426) | LR: 0.00001013 | TIME: 0:07:08 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0200/1467 | LOSS: 0.10116 (0.10329) | LR: 0.00000990 | TIME: 0:08:49 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0240/1467 | LOSS: 0.08410 (0.10364) | LR: 0.00000967 | TIME: 0:10:36 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0280/1467 | LOSS: 0.09989 (0.10233) | LR: 0.00000944 | TIME: 0:12:26 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0320/1467 | LOSS: 0.13639 (0.10323) | LR: 0.00000921 | TIME: 0:14:16 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0360/1467 | LOSS: 0.07209 (0.10412) | LR: 0.00000899 | TIME: 0:16:13 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0400/1467 | LOSS: 0.09960 (0.10353) | LR: 0.00000876 | TIME: 0:18:04 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0440/1467 | LOSS: 0.10172 (0.10364) | LR: 0.00000853 | TIME: 0:19:50 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0480/1467 | LOSS: 0.09972 (0.10274) | LR: 0.00000831 | TIME: 0:21:43 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0520/1467 | LOSS: 0.17776 (0.10260) | LR: 0.00000808 | TIME: 0:23:38 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0560/1467 | LOSS: 0.14685 (0.10264) | LR: 0.00000786 | TIME: 0:25:29 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0600/1467 | LOSS: 0.13495 (0.10229) | LR: 0.00000764 | TIME: 0:27:14 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0640/1467 | LOSS: 0.09505 (0.10197) | LR: 0.00000741 | TIME: 0:29:07 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0680/1467 | LOSS: 0.09963 (0.10108) | LR: 0.00000719 | TIME: 0:30:49 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0720/1467 | LOSS: 0.04753 (0.10141) | LR: 0.00000698 | TIME: 0:32:41 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0760/1467 | LOSS: 0.05203 (0.10138) | LR: 0.00000676 | TIME: 0:34:25 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0800/1467 | LOSS: 0.24910 (0.10145) | LR: 0.00000654 | TIME: 0:36:15 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0840/1467 | LOSS: 0.05884 (0.10085) | LR: 0.00000633 | TIME: 0:38:04 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0880/1467 | LOSS: 0.08582 (0.10080) | LR: 0.00000612 | TIME: 0:39:52 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0920/1467 | LOSS: 0.08329 (0.10006) | LR: 0.00000591 | TIME: 0:41:50 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0960/1467 | LOSS: 0.02087 (0.09962) | LR: 0.00000570 | TIME: 0:43:34 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1000/1467 | LOSS: 0.09138 (0.09937) | LR: 0.00000550 | TIME: 0:45:30 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1040/1467 | LOSS: 0.07353 (0.09921) | LR: 0.00000529 | TIME: 0:47:14 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1080/1467 | LOSS: 0.07940 (0.09891) | LR: 0.00000509 | TIME: 0:49:07 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1120/1467 | LOSS: 0.09915 (0.09868) | LR: 0.00000490 | TIME: 0:50:53 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1160/1467 | LOSS: 0.03912 (0.09833) | LR: 0.00000470 | TIME: 0:52:39 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1200/1467 | LOSS: 0.08306 (0.09824) | LR: 0.00000451 | TIME: 0:54:32 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1240/1467 | LOSS: 0.13752 (0.09809) | LR: 0.00000432 | TIME: 0:56:24 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1280/1467 | LOSS: 0.14669 (0.09760) | LR: 0.00000413 | TIME: 0:58:12 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1320/1467 | LOSS: 0.04905 (0.09733) | LR: 0.00000395 | TIME: 1:00:06 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1360/1467 | LOSS: 0.15166 (0.09730) | LR: 0.00000377 | TIME: 1:01:51 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1400/1467 | LOSS: 0.09593 (0.09679) | LR: 0.00000359 | TIME: 1:03:45 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1440/1467 | LOSS: 0.19805 (0.09660) | LR: 0.00000342 | TIME: 1:05:26 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1466/1467 | LOSS: 0.16668 (0.09661) | LR: 0.00000331 | TIME: 1:06:33 |

VALID_LOOP
[VALID F1] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.11218 (0.11218) | TIME: 0:00:01 |
[VALID F1] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.12520 (0.10110) | TIME: 0:00:24 |
[VALID F1] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.03597 (0.10336) | TIME: 0:00:46 |
[VALID F1] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.08544 (0.10557) | TIME: 0:01:09 |
[VALID F1] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.07192 (0.10787) | TIME: 0:01:32 |
[VALID F1] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.06146 (0.10398) | TIME: 0:01:54 |
[VALID F1] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.12956 (0.10478) | TIME: 0:02:17 |
[VALID F1] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.08539 (0.10469) | TIME: 0:02:40 |
[VALID F1] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.08044 (0.10581) | TIME: 0:03:02 |
[VALID F1] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.05493 (0.10440) | TIME: 0:03:25 |
[VALID F1] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.11802 (0.10347) | TIME: 0:03:48 |
[VALID F1] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.10745 (0.10425) | TIME: 0:04:10 |
[VALID F1] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.08902 (0.10456) | TIME: 0:04:33 |
[VALID F1] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.05156 (0.10435) | TIME: 0:04:37 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.09661 |      0.10435 |  0.45731 | 0.502 | 0.443 | 0.418 | 0.454 | 0.474 | 0.452 | 1:11:11 |


[SAVED] EPOCH: 3 | MCRMSE: 0.4573139250278473

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 4/4 | STEP: 0000/1467 | LOSS: 0.04508 (0.04508) | LR: 0.00000330 | TIME: 0:00:02 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0040/1467 | LOSS: 0.12860 (0.07270) | LR: 0.00000314 | TIME: 0:01:55 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0080/1467 | LOSS: 0.02806 (0.07988) | LR: 0.00000297 | TIME: 0:03:50 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0120/1467 | LOSS: 0.01764 (0.08063) | LR: 0.00000281 | TIME: 0:05:41 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0160/1467 | LOSS: 0.06887 (0.08038) | LR: 0.00000265 | TIME: 0:07:28 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0200/1467 | LOSS: 0.04381 (0.07843) | LR: 0.00000250 | TIME: 0:09:19 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0240/1467 | LOSS: 0.06713 (0.07869) | LR: 0.00000235 | TIME: 0:11:17 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0280/1467 | LOSS: 0.04062 (0.08133) | LR: 0.00000221 | TIME: 0:13:08 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0320/1467 | LOSS: 0.04685 (0.08184) | LR: 0.00000207 | TIME: 0:14:59 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0360/1467 | LOSS: 0.03940 (0.08250) | LR: 0.00000193 | TIME: 0:16:46 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0400/1467 | LOSS: 0.08653 (0.08356) | LR: 0.00000180 | TIME: 0:18:41 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0440/1467 | LOSS: 0.12375 (0.08432) | LR: 0.00000167 | TIME: 0:20:36 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0480/1467 | LOSS: 0.05658 (0.08394) | LR: 0.00000154 | TIME: 0:22:27 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0520/1467 | LOSS: 0.10839 (0.08365) | LR: 0.00000142 | TIME: 0:24:18 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0560/1467 | LOSS: 0.07694 (0.08371) | LR: 0.00000131 | TIME: 0:26:15 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0600/1467 | LOSS: 0.04079 (0.08388) | LR: 0.00000120 | TIME: 0:28:00 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0640/1467 | LOSS: 0.05848 (0.08354) | LR: 0.00000109 | TIME: 0:29:49 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0680/1467 | LOSS: 0.09596 (0.08320) | LR: 0.00000099 | TIME: 0:31:40 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0720/1467 | LOSS: 0.04486 (0.08301) | LR: 0.00000089 | TIME: 0:33:28 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0760/1467 | LOSS: 0.03508 (0.08320) | LR: 0.00000080 | TIME: 0:35:19 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0800/1467 | LOSS: 0.07105 (0.08308) | LR: 0.00000071 | TIME: 0:37:13 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0840/1467 | LOSS: 0.04623 (0.08279) | LR: 0.00000063 | TIME: 0:38:58 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0880/1467 | LOSS: 0.09295 (0.08311) | LR: 0.00000055 | TIME: 0:40:42 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0920/1467 | LOSS: 0.02936 (0.08308) | LR: 0.00000048 | TIME: 0:42:30 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0960/1467 | LOSS: 0.04812 (0.08267) | LR: 0.00000041 | TIME: 0:44:11 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1000/1467 | LOSS: 0.14960 (0.08316) | LR: 0.00000035 | TIME: 0:46:00 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1040/1467 | LOSS: 0.07915 (0.08327) | LR: 0.00000029 | TIME: 0:47:53 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1080/1467 | LOSS: 0.17017 (0.08310) | LR: 0.00000024 | TIME: 0:49:39 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1120/1467 | LOSS: 0.09173 (0.08316) | LR: 0.00000019 | TIME: 0:51:26 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1160/1467 | LOSS: 0.06484 (0.08271) | LR: 0.00000015 | TIME: 0:53:07 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1200/1467 | LOSS: 0.10242 (0.08266) | LR: 0.00000012 | TIME: 0:54:58 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1240/1467 | LOSS: 0.08012 (0.08224) | LR: 0.00000008 | TIME: 0:56:41 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1280/1467 | LOSS: 0.05138 (0.08206) | LR: 0.00000006 | TIME: 0:58:24 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1320/1467 | LOSS: 0.03146 (0.08188) | LR: 0.00000003 | TIME: 1:00:07 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1360/1467 | LOSS: 0.06550 (0.08178) | LR: 0.00000002 | TIME: 1:02:00 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1400/1467 | LOSS: 0.04114 (0.08164) | LR: 0.00000001 | TIME: 1:03:52 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1440/1467 | LOSS: 0.05246 (0.08139) | LR: 0.00000000 | TIME: 1:05:44 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1466/1467 | LOSS: 0.11387 (0.08194) | LR: 0.00000000 | TIME: 1:06:56 |

VALID_LOOP
[VALID F1] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.11620 (0.11620) | TIME: 0:00:01 |
[VALID F1] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.10834 (0.09750) | TIME: 0:00:24 |
[VALID F1] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.03137 (0.09941) | TIME: 0:00:46 |
[VALID F1] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.09019 (0.10162) | TIME: 0:01:09 |
[VALID F1] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.05505 (0.10417) | TIME: 0:01:32 |
[VALID F1] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.04609 (0.09993) | TIME: 0:01:54 |
[VALID F1] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.11956 (0.10130) | TIME: 0:02:17 |
[VALID F1] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.08219 (0.10127) | TIME: 0:02:40 |
[VALID F1] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.08935 (0.10291) | TIME: 0:03:02 |
[VALID F1] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.04854 (0.10183) | TIME: 0:03:25 |
[VALID F1] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.10303 (0.10108) | TIME: 0:03:47 |
[VALID F1] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.11706 (0.10205) | TIME: 0:04:10 |
[VALID F1] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.09098 (0.10256) | TIME: 0:04:33 |
[VALID F1] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.05315 (0.10227) | TIME: 0:04:37 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.08194 |      0.10227 |  0.45292 | 0.483 | 0.442 | 0.418 | 0.454 | 0.472 | 0.450 | 1:11:34 |


[SAVED] EPOCH: 4 | MCRMSE: 0.4529167413711548


----------------------------------- FOLD 1 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.45292     0.48278   0.44155         0.418        0.45352     0.4717        0.44995

################################### END OF FOlD 1 ###################################


Date: 2022-11-21 22:42:19.746256+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: allenai/longformer-large-4096
Model_config: LongformerConfig {
  "_name_or_path": "allenai/longformer-large-4096",
  "attention_mode": "longformer",
  "attention_probs_dropout_prob": 0.0,
  "attention_window": [
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "ignore_attention_mask": false,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 4098,
  "model_type": "longformer",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 1,
  "pooler_dropout": 0.0,
  "position_embedding_type": "absolute",
  "sep_token_id": 2,
  "transformers_version": "4.20.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Pooling_strategy: mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5864}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 1/4 | STEP: 0000/1466 | LOSS: 2.85799 (2.85799) | LR: 0.00000005 | TIME: 0:00:02 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0040/1466 | LOSS: 2.59272 (2.31189) | LR: 0.00000224 | TIME: 0:01:59 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0080/1466 | LOSS: 0.38566 (1.83980) | LR: 0.00000443 | TIME: 0:03:53 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0120/1466 | LOSS: 0.37755 (1.32588) | LR: 0.00000661 | TIME: 0:05:48 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0160/1466 | LOSS: 0.05874 (1.04389) | LR: 0.00000880 | TIME: 0:07:33 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0200/1466 | LOSS: 0.13457 (0.87176) | LR: 0.00001098 | TIME: 0:09:26 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0240/1466 | LOSS: 0.08069 (0.75312) | LR: 0.00001317 | TIME: 0:11:22 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0280/1466 | LOSS: 0.08226 (0.66708) | LR: 0.00001536 | TIME: 0:13:17 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0320/1466 | LOSS: 0.06343 (0.60681) | LR: 0.00001754 | TIME: 0:15:04 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0360/1466 | LOSS: 0.10296 (0.55746) | LR: 0.00001973 | TIME: 0:16:56 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0400/1466 | LOSS: 0.32305 (0.51790) | LR: 0.00002000 | TIME: 0:18:52 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0440/1466 | LOSS: 0.07468 (0.48329) | LR: 0.00001999 | TIME: 0:20:48 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0480/1466 | LOSS: 0.13728 (0.45523) | LR: 0.00001998 | TIME: 0:22:44 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0520/1466 | LOSS: 0.06847 (0.43155) | LR: 0.00001996 | TIME: 0:24:31 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0560/1466 | LOSS: 0.11649 (0.41233) | LR: 0.00001994 | TIME: 0:26:25 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0600/1466 | LOSS: 0.39635 (0.39317) | LR: 0.00001991 | TIME: 0:28:19 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0640/1466 | LOSS: 0.09285 (0.37866) | LR: 0.00001988 | TIME: 0:30:17 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0680/1466 | LOSS: 0.19809 (0.36392) | LR: 0.00001984 | TIME: 0:32:10 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0720/1466 | LOSS: 0.12413 (0.35162) | LR: 0.00001979 | TIME: 0:34:07 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0760/1466 | LOSS: 0.20902 (0.34023) | LR: 0.00001975 | TIME: 0:35:55 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0800/1466 | LOSS: 0.19222 (0.32997) | LR: 0.00001969 | TIME: 0:37:55 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0840/1466 | LOSS: 0.08824 (0.32033) | LR: 0.00001963 | TIME: 0:39:45 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0880/1466 | LOSS: 0.11631 (0.31130) | LR: 0.00001957 | TIME: 0:41:40 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0920/1466 | LOSS: 0.13235 (0.30344) | LR: 0.00001950 | TIME: 0:43:39 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0960/1466 | LOSS: 0.18182 (0.29602) | LR: 0.00001943 | TIME: 0:45:29 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1000/1466 | LOSS: 0.15148 (0.28898) | LR: 0.00001935 | TIME: 0:47:25 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1040/1466 | LOSS: 0.24582 (0.28285) | LR: 0.00001927 | TIME: 0:49:19 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1080/1466 | LOSS: 0.10591 (0.27664) | LR: 0.00001918 | TIME: 0:51:16 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1120/1466 | LOSS: 0.08510 (0.27198) | LR: 0.00001908 | TIME: 0:53:10 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1160/1466 | LOSS: 0.33726 (0.26702) | LR: 0.00001899 | TIME: 0:55:03 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1200/1466 | LOSS: 0.24110 (0.26211) | LR: 0.00001888 | TIME: 0:56:52 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1240/1466 | LOSS: 0.11399 (0.25783) | LR: 0.00001878 | TIME: 0:58:45 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1280/1466 | LOSS: 0.07089 (0.25433) | LR: 0.00001866 | TIME: 1:00:38 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1320/1466 | LOSS: 0.05234 (0.25022) | LR: 0.00001855 | TIME: 1:02:29 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1360/1466 | LOSS: 0.15596 (0.24760) | LR: 0.00001843 | TIME: 1:04:32 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1400/1466 | LOSS: 0.12538 (0.24423) | LR: 0.00001830 | TIME: 1:06:29 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1440/1466 | LOSS: 0.09775 (0.24033) | LR: 0.00001817 | TIME: 1:08:25 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1465/1466 | LOSS: 0.12066 (0.23844) | LR: 0.00001809 | TIME: 1:09:36 |

VALID_LOOP
[VALID F2] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.22346 (0.22346) | TIME: 0:00:01 |
[VALID F2] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.05385 (0.10799) | TIME: 0:00:26 |
[VALID F2] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.08110 (0.11778) | TIME: 0:00:50 |
[VALID F2] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.07662 (0.11459) | TIME: 0:01:15 |
[VALID F2] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.03791 (0.11470) | TIME: 0:01:40 |
[VALID F2] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.08589 (0.11376) | TIME: 0:02:04 |
[VALID F2] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.44947 (0.11570) | TIME: 0:02:29 |
[VALID F2] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.20636 (0.11662) | TIME: 0:02:53 |
[VALID F2] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.05480 (0.11404) | TIME: 0:03:18 |
[VALID F2] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.08607 (0.11360) | TIME: 0:03:43 |
[VALID F2] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.08384 (0.11513) | TIME: 0:04:07 |
[VALID F2] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.06940 (0.11501) | TIME: 0:04:32 |
[VALID F2] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.13651 (0.11494) | TIME: 0:04:57 |
[VALID F2] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.11614 (0.11440) | TIME: 0:05:02 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.23844 |       0.1144 |  0.47988 | 0.501 | 0.463 | 0.443 | 0.496 | 0.491 | 0.485 | 1:14:38 |


[SAVED] EPOCH: 1 | MCRMSE: 0.47987639904022217

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 2/4 | STEP: 0000/1466 | LOSS: 0.12478 (0.12478) | LR: 0.00001809 | TIME: 0:00:02 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0040/1466 | LOSS: 0.12098 (0.11034) | LR: 0.00001795 | TIME: 0:01:47 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0080/1466 | LOSS: 0.10868 (0.11656) | LR: 0.00001781 | TIME: 0:03:37 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0120/1466 | LOSS: 0.09959 (0.11539) | LR: 0.00001766 | TIME: 0:05:28 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0160/1466 | LOSS: 0.08239 (0.11782) | LR: 0.00001751 | TIME: 0:07:28 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0200/1466 | LOSS: 0.11093 (0.11716) | LR: 0.00001736 | TIME: 0:09:24 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0240/1466 | LOSS: 0.06813 (0.11506) | LR: 0.00001721 | TIME: 0:11:22 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0280/1466 | LOSS: 0.07898 (0.11501) | LR: 0.00001704 | TIME: 0:13:14 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0320/1466 | LOSS: 0.07456 (0.11633) | LR: 0.00001688 | TIME: 0:15:10 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0360/1466 | LOSS: 0.05367 (0.11519) | LR: 0.00001671 | TIME: 0:16:58 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0400/1466 | LOSS: 0.10410 (0.11580) | LR: 0.00001654 | TIME: 0:18:52 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0440/1466 | LOSS: 0.18377 (0.11598) | LR: 0.00001637 | TIME: 0:20:48 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0480/1466 | LOSS: 0.23506 (0.11676) | LR: 0.00001619 | TIME: 0:22:40 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0520/1466 | LOSS: 0.10903 (0.11699) | LR: 0.00001601 | TIME: 0:24:30 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0560/1466 | LOSS: 0.04186 (0.11635) | LR: 0.00001582 | TIME: 0:26:24 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0600/1466 | LOSS: 0.27338 (0.11653) | LR: 0.00001564 | TIME: 0:28:10 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0640/1466 | LOSS: 0.15036 (0.11591) | LR: 0.00001545 | TIME: 0:30:05 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0680/1466 | LOSS: 0.17469 (0.11486) | LR: 0.00001525 | TIME: 0:31:54 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0720/1466 | LOSS: 0.11347 (0.11511) | LR: 0.00001506 | TIME: 0:33:46 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0760/1466 | LOSS: 0.12113 (0.11473) | LR: 0.00001486 | TIME: 0:35:45 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0800/1466 | LOSS: 0.06522 (0.11443) | LR: 0.00001466 | TIME: 0:37:45 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0840/1466 | LOSS: 0.07861 (0.11547) | LR: 0.00001445 | TIME: 0:39:38 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0880/1466 | LOSS: 0.07524 (0.11538) | LR: 0.00001425 | TIME: 0:41:36 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0920/1466 | LOSS: 0.12117 (0.11545) | LR: 0.00001404 | TIME: 0:43:30 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0960/1466 | LOSS: 0.14909 (0.11581) | LR: 0.00001383 | TIME: 0:45:21 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1000/1466 | LOSS: 0.05524 (0.11616) | LR: 0.00001362 | TIME: 0:47:09 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1040/1466 | LOSS: 0.20942 (0.11570) | LR: 0.00001340 | TIME: 0:49:02 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1080/1466 | LOSS: 0.09177 (0.11519) | LR: 0.00001319 | TIME: 0:51:01 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1120/1466 | LOSS: 0.12865 (0.11513) | LR: 0.00001297 | TIME: 0:52:58 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1160/1466 | LOSS: 0.16038 (0.11462) | LR: 0.00001275 | TIME: 0:54:56 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1200/1466 | LOSS: 0.08845 (0.11450) | LR: 0.00001253 | TIME: 0:56:50 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1240/1466 | LOSS: 0.27202 (0.11426) | LR: 0.00001231 | TIME: 0:58:40 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1280/1466 | LOSS: 0.07355 (0.11351) | LR: 0.00001209 | TIME: 1:00:39 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1320/1466 | LOSS: 0.03964 (0.11336) | LR: 0.00001186 | TIME: 1:02:34 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1360/1466 | LOSS: 0.08532 (0.11340) | LR: 0.00001164 | TIME: 1:04:31 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1400/1466 | LOSS: 0.04562 (0.11368) | LR: 0.00001141 | TIME: 1:06:28 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1440/1466 | LOSS: 0.06845 (0.11362) | LR: 0.00001119 | TIME: 1:08:21 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1465/1466 | LOSS: 0.13614 (0.11354) | LR: 0.00001104 | TIME: 1:09:35 |

VALID_LOOP
[VALID F2] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.27375 (0.27375) | TIME: 0:00:01 |
[VALID F2] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.05194 (0.11141) | TIME: 0:00:26 |
[VALID F2] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.11054 (0.12172) | TIME: 0:00:50 |
[VALID F2] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.05910 (0.11617) | TIME: 0:01:15 |
[VALID F2] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.05996 (0.11633) | TIME: 0:01:39 |
[VALID F2] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.10645 (0.11627) | TIME: 0:02:04 |
[VALID F2] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.33776 (0.11687) | TIME: 0:02:28 |
[VALID F2] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.19421 (0.11756) | TIME: 0:02:53 |
[VALID F2] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.06316 (0.11420) | TIME: 0:03:17 |
[VALID F2] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.05154 (0.11324) | TIME: 0:03:42 |
[VALID F2] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.07776 (0.11440) | TIME: 0:04:07 |
[VALID F2] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.05471 (0.11409) | TIME: 0:04:31 |
[VALID F2] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.17267 (0.11359) | TIME: 0:04:56 |
[VALID F2] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.18676 (0.11316) | TIME: 0:05:01 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11354 |      0.11316 |  0.47711 | 0.494 | 0.495 | 0.429 | 0.479 | 0.505 | 0.461 | 1:14:36 |


[SAVED] EPOCH: 2 | MCRMSE: 0.477110356092453

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 3/4 | STEP: 0000/1466 | LOSS: 0.06700 (0.06700) | LR: 0.00001104 | TIME: 0:00:02 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0040/1466 | LOSS: 0.07892 (0.09881) | LR: 0.00001081 | TIME: 0:01:53 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0080/1466 | LOSS: 0.13506 (0.09360) | LR: 0.00001058 | TIME: 0:03:50 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0120/1466 | LOSS: 0.05705 (0.09862) | LR: 0.00001035 | TIME: 0:05:45 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0160/1466 | LOSS: 0.08825 (0.09415) | LR: 0.00001013 | TIME: 0:07:41 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0200/1466 | LOSS: 0.04392 (0.09329) | LR: 0.00000990 | TIME: 0:09:38 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0240/1466 | LOSS: 0.08511 (0.09468) | LR: 0.00000967 | TIME: 0:11:42 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0280/1466 | LOSS: 0.06784 (0.09474) | LR: 0.00000944 | TIME: 0:13:32 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0320/1466 | LOSS: 0.06768 (0.09587) | LR: 0.00000921 | TIME: 0:15:25 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0360/1466 | LOSS: 0.21153 (0.09608) | LR: 0.00000898 | TIME: 0:17:17 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0400/1466 | LOSS: 0.08035 (0.09639) | LR: 0.00000876 | TIME: 0:19:12 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0440/1466 | LOSS: 0.07487 (0.09524) | LR: 0.00000853 | TIME: 0:20:59 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0480/1466 | LOSS: 0.18614 (0.09505) | LR: 0.00000831 | TIME: 0:22:54 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0520/1466 | LOSS: 0.07902 (0.09503) | LR: 0.00000808 | TIME: 0:24:41 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0560/1466 | LOSS: 0.18538 (0.09544) | LR: 0.00000786 | TIME: 0:26:46 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0600/1466 | LOSS: 0.05615 (0.09554) | LR: 0.00000763 | TIME: 0:28:42 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0640/1466 | LOSS: 0.11858 (0.09670) | LR: 0.00000741 | TIME: 0:30:40 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0680/1466 | LOSS: 0.16026 (0.09633) | LR: 0.00000719 | TIME: 0:32:34 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0720/1466 | LOSS: 0.08304 (0.09627) | LR: 0.00000697 | TIME: 0:34:26 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0760/1466 | LOSS: 0.03687 (0.09637) | LR: 0.00000676 | TIME: 0:36:21 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0800/1466 | LOSS: 0.03423 (0.09598) | LR: 0.00000654 | TIME: 0:38:15 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0840/1466 | LOSS: 0.09953 (0.09594) | LR: 0.00000633 | TIME: 0:40:01 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0880/1466 | LOSS: 0.09581 (0.09642) | LR: 0.00000612 | TIME: 0:41:58 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0920/1466 | LOSS: 0.13962 (0.09670) | LR: 0.00000591 | TIME: 0:43:52 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0960/1466 | LOSS: 0.06247 (0.09719) | LR: 0.00000570 | TIME: 0:45:44 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1000/1466 | LOSS: 0.04406 (0.09752) | LR: 0.00000549 | TIME: 0:47:38 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1040/1466 | LOSS: 0.05510 (0.09819) | LR: 0.00000529 | TIME: 0:49:32 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1080/1466 | LOSS: 0.04014 (0.09837) | LR: 0.00000509 | TIME: 0:51:28 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1120/1466 | LOSS: 0.05346 (0.09805) | LR: 0.00000489 | TIME: 0:53:22 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1160/1466 | LOSS: 0.07756 (0.09788) | LR: 0.00000470 | TIME: 0:55:17 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1200/1466 | LOSS: 0.15142 (0.09803) | LR: 0.00000451 | TIME: 0:57:13 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1240/1466 | LOSS: 0.05604 (0.09744) | LR: 0.00000432 | TIME: 0:59:05 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1280/1466 | LOSS: 0.08789 (0.09734) | LR: 0.00000413 | TIME: 1:00:56 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1320/1466 | LOSS: 0.16401 (0.09705) | LR: 0.00000395 | TIME: 1:02:51 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1360/1466 | LOSS: 0.11484 (0.09706) | LR: 0.00000377 | TIME: 1:04:50 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1400/1466 | LOSS: 0.04313 (0.09653) | LR: 0.00000359 | TIME: 1:06:43 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1440/1466 | LOSS: 0.27465 (0.09693) | LR: 0.00000341 | TIME: 1:08:40 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1465/1466 | LOSS: 0.12179 (0.09694) | LR: 0.00000331 | TIME: 1:09:45 |

VALID_LOOP
[VALID F2] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.31939 (0.31939) | TIME: 0:00:01 |
[VALID F2] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.06266 (0.10754) | TIME: 0:00:26 |
[VALID F2] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.09468 (0.11470) | TIME: 0:00:50 |
[VALID F2] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.06350 (0.11031) | TIME: 0:01:15 |
[VALID F2] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.04414 (0.10876) | TIME: 0:01:39 |
[VALID F2] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.10747 (0.10958) | TIME: 0:02:04 |
[VALID F2] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.37567 (0.11046) | TIME: 0:02:29 |
[VALID F2] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.16656 (0.11077) | TIME: 0:02:53 |
[VALID F2] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.04752 (0.10830) | TIME: 0:03:18 |
[VALID F2] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.06535 (0.10748) | TIME: 0:03:42 |
[VALID F2] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.08131 (0.10901) | TIME: 0:04:07 |
[VALID F2] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.05435 (0.10900) | TIME: 0:04:31 |
[VALID F2] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.16131 (0.10870) | TIME: 0:04:56 |
[VALID F2] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.14452 (0.10835) | TIME: 0:05:01 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.09694 |      0.10835 |  0.46666 | 0.490 | 0.459 | 0.431 | 0.471 | 0.484 | 0.465 | 1:14:46 |


[SAVED] EPOCH: 3 | MCRMSE: 0.4666639566421509

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 4/4 | STEP: 0000/1466 | LOSS: 0.07747 (0.07747) | LR: 0.00000330 | TIME: 0:00:04 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0040/1466 | LOSS: 0.08508 (0.09280) | LR: 0.00000314 | TIME: 0:01:56 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0080/1466 | LOSS: 0.05635 (0.08577) | LR: 0.00000297 | TIME: 0:03:52 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0120/1466 | LOSS: 0.18073 (0.08748) | LR: 0.00000281 | TIME: 0:05:44 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0160/1466 | LOSS: 0.16261 (0.08804) | LR: 0.00000265 | TIME: 0:07:31 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0200/1466 | LOSS: 0.09344 (0.08671) | LR: 0.00000250 | TIME: 0:09:18 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0240/1466 | LOSS: 0.04402 (0.08571) | LR: 0.00000235 | TIME: 0:11:18 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0280/1466 | LOSS: 0.11624 (0.08687) | LR: 0.00000221 | TIME: 0:13:10 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0320/1466 | LOSS: 0.07017 (0.08679) | LR: 0.00000207 | TIME: 0:15:05 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0360/1466 | LOSS: 0.12229 (0.08546) | LR: 0.00000193 | TIME: 0:17:03 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0400/1466 | LOSS: 0.07849 (0.08507) | LR: 0.00000180 | TIME: 0:18:51 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0440/1466 | LOSS: 0.04991 (0.08581) | LR: 0.00000167 | TIME: 0:20:49 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0480/1466 | LOSS: 0.07840 (0.08744) | LR: 0.00000154 | TIME: 0:22:50 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0520/1466 | LOSS: 0.08406 (0.08797) | LR: 0.00000142 | TIME: 0:24:43 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0560/1466 | LOSS: 0.07629 (0.08874) | LR: 0.00000131 | TIME: 0:26:45 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0600/1466 | LOSS: 0.03352 (0.08854) | LR: 0.00000120 | TIME: 0:28:40 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0640/1466 | LOSS: 0.07881 (0.08842) | LR: 0.00000109 | TIME: 0:30:34 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0680/1466 | LOSS: 0.08119 (0.08875) | LR: 0.00000099 | TIME: 0:32:37 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0720/1466 | LOSS: 0.11082 (0.08886) | LR: 0.00000089 | TIME: 0:34:31 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0760/1466 | LOSS: 0.05987 (0.08865) | LR: 0.00000080 | TIME: 0:36:21 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0800/1466 | LOSS: 0.04705 (0.08788) | LR: 0.00000071 | TIME: 0:38:12 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0840/1466 | LOSS: 0.09788 (0.08847) | LR: 0.00000063 | TIME: 0:40:08 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0880/1466 | LOSS: 0.28664 (0.08910) | LR: 0.00000055 | TIME: 0:41:57 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0920/1466 | LOSS: 0.09915 (0.08830) | LR: 0.00000048 | TIME: 0:43:53 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0960/1466 | LOSS: 0.06318 (0.08836) | LR: 0.00000041 | TIME: 0:45:48 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1000/1466 | LOSS: 0.03272 (0.08799) | LR: 0.00000035 | TIME: 0:47:35 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1040/1466 | LOSS: 0.06019 (0.08772) | LR: 0.00000029 | TIME: 0:49:36 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1080/1466 | LOSS: 0.12670 (0.08748) | LR: 0.00000024 | TIME: 0:51:24 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1120/1466 | LOSS: 0.06090 (0.08724) | LR: 0.00000019 | TIME: 0:53:07 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1160/1466 | LOSS: 0.05302 (0.08695) | LR: 0.00000015 | TIME: 0:55:04 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1200/1466 | LOSS: 0.14367 (0.08680) | LR: 0.00000011 | TIME: 0:56:58 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1240/1466 | LOSS: 0.16189 (0.08670) | LR: 0.00000008 | TIME: 0:58:55 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1280/1466 | LOSS: 0.07804 (0.08670) | LR: 0.00000006 | TIME: 1:00:47 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1320/1466 | LOSS: 0.07764 (0.08672) | LR: 0.00000003 | TIME: 1:02:42 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1360/1466 | LOSS: 0.09455 (0.08646) | LR: 0.00000002 | TIME: 1:04:39 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1400/1466 | LOSS: 0.08514 (0.08632) | LR: 0.00000001 | TIME: 1:06:29 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1440/1466 | LOSS: 0.07366 (0.08625) | LR: 0.00000000 | TIME: 1:08:19 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1465/1466 | LOSS: 0.07822 (0.08614) | LR: 0.00000000 | TIME: 1:09:25 |

VALID_LOOP
[VALID F2] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.28628 (0.28628) | TIME: 0:00:01 |
[VALID F2] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.06065 (0.10421) | TIME: 0:00:26 |
[VALID F2] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.08151 (0.11341) | TIME: 0:00:50 |
[VALID F2] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.06558 (0.10930) | TIME: 0:01:15 |
[VALID F2] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.04551 (0.10810) | TIME: 0:01:39 |
[VALID F2] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.09393 (0.10821) | TIME: 0:02:04 |
[VALID F2] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.37999 (0.10852) | TIME: 0:02:28 |
[VALID F2] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.20047 (0.10878) | TIME: 0:02:53 |
[VALID F2] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.04595 (0.10606) | TIME: 0:03:17 |
[VALID F2] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.06663 (0.10477) | TIME: 0:03:42 |
[VALID F2] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.09215 (0.10655) | TIME: 0:04:07 |
[VALID F2] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.05602 (0.10673) | TIME: 0:04:31 |
[VALID F2] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.16357 (0.10671) | TIME: 0:04:56 |
[VALID F2] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.11591 (0.10631) | TIME: 0:05:01 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.08614 |      0.10631 |  0.46209 | 0.485 | 0.455 | 0.420 | 0.471 | 0.482 | 0.460 | 1:14:27 |


[SAVED] EPOCH: 4 | MCRMSE: 0.4620855152606964


----------------------------------- FOLD 2 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.46209     0.48528   0.45476       0.42028         0.4705    0.48209         0.4596

################################### END OF FOlD 2 ###################################


Date: 2022-11-21 20:51:32.649068+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: allenai/longformer-large-4096
Model_config: LongformerConfig {
  "_name_or_path": "allenai/longformer-large-4096",
  "attention_mode": "longformer",
  "attention_probs_dropout_prob": 0.0,
  "attention_window": [
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "ignore_attention_mask": false,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 4098,
  "model_type": "longformer",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 1,
  "pooler_dropout": 0.0,
  "position_embedding_type": "absolute",
  "sep_token_id": 2,
  "transformers_version": "4.20.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Pooling_strategy: mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5864}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 1/4 | STEP: 0000/1466 | LOSS: 2.04401 (2.04401) | LR: 0.00000005 | TIME: 0:00:03 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0040/1466 | LOSS: 1.73724 (2.30991) | LR: 0.00000224 | TIME: 0:01:31 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0080/1466 | LOSS: 0.48142 (1.83140) | LR: 0.00000443 | TIME: 0:03:00 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0120/1466 | LOSS: 0.16679 (1.33792) | LR: 0.00000661 | TIME: 0:04:42 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0160/1466 | LOSS: 0.17901 (1.05914) | LR: 0.00000880 | TIME: 0:06:19 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0200/1466 | LOSS: 0.12188 (0.88167) | LR: 0.00001098 | TIME: 0:07:54 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0240/1466 | LOSS: 0.17372 (0.76403) | LR: 0.00001317 | TIME: 0:09:32 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0280/1466 | LOSS: 0.03824 (0.67847) | LR: 0.00001536 | TIME: 0:11:09 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0320/1466 | LOSS: 0.09284 (0.61431) | LR: 0.00001754 | TIME: 0:12:46 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0360/1466 | LOSS: 0.08124 (0.56277) | LR: 0.00001973 | TIME: 0:14:24 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0400/1466 | LOSS: 0.24737 (0.52439) | LR: 0.00002000 | TIME: 0:16:03 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0440/1466 | LOSS: 0.18110 (0.49055) | LR: 0.00001999 | TIME: 0:17:43 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0480/1466 | LOSS: 0.05675 (0.46186) | LR: 0.00001998 | TIME: 0:19:19 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0520/1466 | LOSS: 0.15939 (0.43682) | LR: 0.00001996 | TIME: 0:21:02 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0560/1466 | LOSS: 0.15932 (0.41610) | LR: 0.00001994 | TIME: 0:22:40 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0600/1466 | LOSS: 0.03897 (0.39677) | LR: 0.00001991 | TIME: 0:24:16 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0640/1466 | LOSS: 0.20843 (0.38112) | LR: 0.00001988 | TIME: 0:25:59 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0680/1466 | LOSS: 0.17535 (0.36697) | LR: 0.00001984 | TIME: 0:27:39 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0720/1466 | LOSS: 0.08005 (0.35371) | LR: 0.00001979 | TIME: 0:29:08 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0760/1466 | LOSS: 0.09156 (0.34192) | LR: 0.00001975 | TIME: 0:30:47 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0800/1466 | LOSS: 0.05902 (0.33148) | LR: 0.00001969 | TIME: 0:32:24 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0840/1466 | LOSS: 0.18909 (0.32433) | LR: 0.00001963 | TIME: 0:33:58 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0880/1466 | LOSS: 0.15192 (0.31564) | LR: 0.00001957 | TIME: 0:35:40 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0920/1466 | LOSS: 0.15655 (0.30804) | LR: 0.00001950 | TIME: 0:37:21 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0960/1466 | LOSS: 0.09900 (0.30019) | LR: 0.00001943 | TIME: 0:39:00 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1000/1466 | LOSS: 0.18251 (0.29343) | LR: 0.00001935 | TIME: 0:40:39 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1040/1466 | LOSS: 0.07364 (0.28763) | LR: 0.00001927 | TIME: 0:42:24 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1080/1466 | LOSS: 0.04902 (0.28216) | LR: 0.00001918 | TIME: 0:44:07 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1120/1466 | LOSS: 0.09594 (0.27706) | LR: 0.00001908 | TIME: 0:45:47 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1160/1466 | LOSS: 0.08942 (0.27159) | LR: 0.00001899 | TIME: 0:47:27 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1200/1466 | LOSS: 0.12659 (0.26679) | LR: 0.00001888 | TIME: 0:49:10 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1240/1466 | LOSS: 0.16228 (0.26256) | LR: 0.00001878 | TIME: 0:50:54 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1280/1466 | LOSS: 0.14911 (0.25843) | LR: 0.00001866 | TIME: 0:52:38 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1320/1466 | LOSS: 0.04876 (0.25467) | LR: 0.00001855 | TIME: 0:54:12 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1360/1466 | LOSS: 0.03301 (0.25083) | LR: 0.00001843 | TIME: 0:55:45 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1400/1466 | LOSS: 0.18007 (0.24725) | LR: 0.00001830 | TIME: 0:57:24 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1440/1466 | LOSS: 0.05911 (0.24419) | LR: 0.00001817 | TIME: 0:59:00 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1465/1466 | LOSS: 0.21533 (0.24213) | LR: 0.00001809 | TIME: 0:59:59 |

VALID_LOOP
[VALID F3] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.19877 (0.19877) | TIME: 0:00:01 |
[VALID F3] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.10318 (0.11320) | TIME: 0:00:14 |
[VALID F3] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.11683 (0.11710) | TIME: 0:00:27 |
[VALID F3] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.16750 (0.11402) | TIME: 0:00:40 |
[VALID F3] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.09535 (0.11281) | TIME: 0:00:54 |
[VALID F3] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.07977 (0.11601) | TIME: 0:01:07 |
[VALID F3] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.10534 (0.11583) | TIME: 0:01:20 |
[VALID F3] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.05291 (0.11722) | TIME: 0:01:34 |
[VALID F3] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.31746 (0.11919) | TIME: 0:01:47 |
[VALID F3] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.07707 (0.12018) | TIME: 0:02:00 |
[VALID F3] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.09679 (0.12024) | TIME: 0:02:14 |
[VALID F3] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.14509 (0.12047) | TIME: 0:02:27 |
[VALID F3] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.10156 (0.12005) | TIME: 0:02:40 |
[VALID F3] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.06692 (0.11945) | TIME: 0:02:43 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.24213 |      0.11945 |  0.49023 | 0.545 | 0.502 | 0.427 | 0.460 | 0.497 | 0.511 | 1:02:42 |


[SAVED] EPOCH: 1 | MCRMSE: 0.4902309477329254

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 2/4 | STEP: 0000/1466 | LOSS: 0.13988 (0.13988) | LR: 0.00001809 | TIME: 0:00:02 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0040/1466 | LOSS: 0.08938 (0.11378) | LR: 0.00001795 | TIME: 0:01:42 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0080/1466 | LOSS: 0.08577 (0.10548) | LR: 0.00001781 | TIME: 0:03:24 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0120/1466 | LOSS: 0.13324 (0.10952) | LR: 0.00001766 | TIME: 0:05:08 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0160/1466 | LOSS: 0.18838 (0.11192) | LR: 0.00001751 | TIME: 0:06:42 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0200/1466 | LOSS: 0.08820 (0.11169) | LR: 0.00001736 | TIME: 0:08:16 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0240/1466 | LOSS: 0.11564 (0.11614) | LR: 0.00001721 | TIME: 0:10:03 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0280/1466 | LOSS: 0.11954 (0.11641) | LR: 0.00001704 | TIME: 0:11:44 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0320/1466 | LOSS: 0.09298 (0.11595) | LR: 0.00001688 | TIME: 0:13:27 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0360/1466 | LOSS: 0.26106 (0.11558) | LR: 0.00001671 | TIME: 0:15:00 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0400/1466 | LOSS: 0.07754 (0.11612) | LR: 0.00001654 | TIME: 0:16:38 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0440/1466 | LOSS: 0.14145 (0.11726) | LR: 0.00001637 | TIME: 0:18:15 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0480/1466 | LOSS: 0.07441 (0.11639) | LR: 0.00001619 | TIME: 0:19:53 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0520/1466 | LOSS: 0.16149 (0.11605) | LR: 0.00001601 | TIME: 0:21:27 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0560/1466 | LOSS: 0.09374 (0.11550) | LR: 0.00001582 | TIME: 0:23:08 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0600/1466 | LOSS: 0.11978 (0.11676) | LR: 0.00001564 | TIME: 0:24:52 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0640/1466 | LOSS: 0.10180 (0.11600) | LR: 0.00001545 | TIME: 0:26:27 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0680/1466 | LOSS: 0.09589 (0.11540) | LR: 0.00001525 | TIME: 0:28:01 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0720/1466 | LOSS: 0.13652 (0.11557) | LR: 0.00001506 | TIME: 0:29:41 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0760/1466 | LOSS: 0.09476 (0.11568) | LR: 0.00001486 | TIME: 0:31:18 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0800/1466 | LOSS: 0.12030 (0.11577) | LR: 0.00001466 | TIME: 0:32:56 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0840/1466 | LOSS: 0.14051 (0.11559) | LR: 0.00001445 | TIME: 0:34:32 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0880/1466 | LOSS: 0.15763 (0.11581) | LR: 0.00001425 | TIME: 0:36:12 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0920/1466 | LOSS: 0.10606 (0.11574) | LR: 0.00001404 | TIME: 0:37:57 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0960/1466 | LOSS: 0.07379 (0.11578) | LR: 0.00001383 | TIME: 0:39:37 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1000/1466 | LOSS: 0.13035 (0.11583) | LR: 0.00001362 | TIME: 0:41:18 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1040/1466 | LOSS: 0.04863 (0.11586) | LR: 0.00001340 | TIME: 0:42:56 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1080/1466 | LOSS: 0.08590 (0.11543) | LR: 0.00001319 | TIME: 0:44:34 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1120/1466 | LOSS: 0.17137 (0.11554) | LR: 0.00001297 | TIME: 0:46:09 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1160/1466 | LOSS: 0.06696 (0.11528) | LR: 0.00001275 | TIME: 0:47:51 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1200/1466 | LOSS: 0.11336 (0.11536) | LR: 0.00001253 | TIME: 0:49:34 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1240/1466 | LOSS: 0.23532 (0.11576) | LR: 0.00001231 | TIME: 0:51:16 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1280/1466 | LOSS: 0.10322 (0.11526) | LR: 0.00001209 | TIME: 0:52:49 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1320/1466 | LOSS: 0.14997 (0.11542) | LR: 0.00001186 | TIME: 0:54:17 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1360/1466 | LOSS: 0.12136 (0.11562) | LR: 0.00001164 | TIME: 0:55:58 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1400/1466 | LOSS: 0.12372 (0.11552) | LR: 0.00001141 | TIME: 0:57:35 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1440/1466 | LOSS: 0.05591 (0.11497) | LR: 0.00001119 | TIME: 0:59:15 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1465/1466 | LOSS: 0.03310 (0.11466) | LR: 0.00001104 | TIME: 1:00:12 |

VALID_LOOP
[VALID F3] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.29375 (0.29375) | TIME: 0:00:01 |
[VALID F3] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.10846 (0.11400) | TIME: 0:00:14 |
[VALID F3] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.18007 (0.11572) | TIME: 0:00:27 |
[VALID F3] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.11651 (0.10793) | TIME: 0:00:41 |
[VALID F3] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.08691 (0.10698) | TIME: 0:00:54 |
[VALID F3] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.04865 (0.10761) | TIME: 0:01:07 |
[VALID F3] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.06476 (0.10704) | TIME: 0:01:20 |
[VALID F3] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.06278 (0.10788) | TIME: 0:01:34 |
[VALID F3] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.20715 (0.10928) | TIME: 0:01:47 |
[VALID F3] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.07140 (0.10926) | TIME: 0:02:00 |
[VALID F3] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.10118 (0.10893) | TIME: 0:02:14 |
[VALID F3] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.10313 (0.10895) | TIME: 0:02:27 |
[VALID F3] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.14672 (0.10869) | TIME: 0:02:40 |
[VALID F3] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.04280 (0.10815) | TIME: 0:02:43 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11466 |      0.10815 |  0.46621 | 0.493 | 0.490 | 0.419 | 0.448 | 0.488 | 0.460 | 1:02:56 |


[SAVED] EPOCH: 2 | MCRMSE: 0.46620526909828186

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 3/4 | STEP: 0000/1466 | LOSS: 0.28222 (0.28222) | LR: 0.00001104 | TIME: 0:00:03 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0040/1466 | LOSS: 0.05204 (0.09585) | LR: 0.00001081 | TIME: 0:01:43 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0080/1466 | LOSS: 0.05853 (0.09305) | LR: 0.00001058 | TIME: 0:03:21 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0120/1466 | LOSS: 0.10415 (0.09755) | LR: 0.00001035 | TIME: 0:04:55 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0160/1466 | LOSS: 0.02893 (0.09768) | LR: 0.00001013 | TIME: 0:06:37 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0200/1466 | LOSS: 0.05781 (0.09347) | LR: 0.00000990 | TIME: 0:08:19 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0240/1466 | LOSS: 0.08594 (0.09329) | LR: 0.00000967 | TIME: 0:10:02 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0280/1466 | LOSS: 0.10953 (0.09304) | LR: 0.00000944 | TIME: 0:11:42 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0320/1466 | LOSS: 0.07708 (0.09427) | LR: 0.00000921 | TIME: 0:13:17 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0360/1466 | LOSS: 0.07150 (0.09386) | LR: 0.00000898 | TIME: 0:14:52 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0400/1466 | LOSS: 0.09288 (0.09387) | LR: 0.00000876 | TIME: 0:16:32 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0440/1466 | LOSS: 0.08755 (0.09430) | LR: 0.00000853 | TIME: 0:18:09 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0480/1466 | LOSS: 0.07061 (0.09383) | LR: 0.00000831 | TIME: 0:19:47 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0520/1466 | LOSS: 0.23951 (0.09466) | LR: 0.00000808 | TIME: 0:21:29 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0560/1466 | LOSS: 0.07718 (0.09400) | LR: 0.00000786 | TIME: 0:23:04 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0600/1466 | LOSS: 0.10787 (0.09361) | LR: 0.00000763 | TIME: 0:24:39 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0640/1466 | LOSS: 0.04110 (0.09407) | LR: 0.00000741 | TIME: 0:26:22 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0680/1466 | LOSS: 0.11554 (0.09403) | LR: 0.00000719 | TIME: 0:28:08 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0720/1466 | LOSS: 0.12510 (0.09531) | LR: 0.00000697 | TIME: 0:29:49 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0760/1466 | LOSS: 0.08117 (0.09585) | LR: 0.00000676 | TIME: 0:31:30 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0800/1466 | LOSS: 0.09207 (0.09552) | LR: 0.00000654 | TIME: 0:33:04 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0840/1466 | LOSS: 0.05859 (0.09544) | LR: 0.00000633 | TIME: 0:34:42 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0880/1466 | LOSS: 0.15551 (0.09519) | LR: 0.00000612 | TIME: 0:36:22 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0920/1466 | LOSS: 0.13664 (0.09491) | LR: 0.00000591 | TIME: 0:37:56 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0960/1466 | LOSS: 0.10175 (0.09502) | LR: 0.00000570 | TIME: 0:39:36 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1000/1466 | LOSS: 0.03430 (0.09525) | LR: 0.00000549 | TIME: 0:41:15 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1040/1466 | LOSS: 0.10365 (0.09520) | LR: 0.00000529 | TIME: 0:42:50 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1080/1466 | LOSS: 0.09499 (0.09461) | LR: 0.00000509 | TIME: 0:44:24 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1120/1466 | LOSS: 0.19150 (0.09500) | LR: 0.00000489 | TIME: 0:46:08 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1160/1466 | LOSS: 0.09345 (0.09507) | LR: 0.00000470 | TIME: 0:47:47 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1200/1466 | LOSS: 0.07149 (0.09534) | LR: 0.00000451 | TIME: 0:49:26 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1240/1466 | LOSS: 0.09497 (0.09507) | LR: 0.00000432 | TIME: 0:51:04 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1280/1466 | LOSS: 0.12561 (0.09503) | LR: 0.00000413 | TIME: 0:52:46 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1320/1466 | LOSS: 0.09800 (0.09477) | LR: 0.00000395 | TIME: 0:54:23 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1360/1466 | LOSS: 0.06735 (0.09436) | LR: 0.00000377 | TIME: 0:55:57 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1400/1466 | LOSS: 0.08502 (0.09437) | LR: 0.00000359 | TIME: 0:57:42 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1440/1466 | LOSS: 0.05422 (0.09420) | LR: 0.00000341 | TIME: 0:59:20 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1465/1466 | LOSS: 0.03105 (0.09394) | LR: 0.00000331 | TIME: 1:00:24 |

VALID_LOOP
[VALID F3] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.24194 (0.24194) | TIME: 0:00:01 |
[VALID F3] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.12363 (0.10590) | TIME: 0:00:14 |
[VALID F3] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.15252 (0.10864) | TIME: 0:00:27 |
[VALID F3] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.12006 (0.10192) | TIME: 0:00:41 |
[VALID F3] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.06820 (0.10050) | TIME: 0:00:54 |
[VALID F3] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.04735 (0.10138) | TIME: 0:01:07 |
[VALID F3] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.05801 (0.10096) | TIME: 0:01:21 |
[VALID F3] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.04449 (0.10180) | TIME: 0:01:34 |
[VALID F3] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.26991 (0.10249) | TIME: 0:01:47 |
[VALID F3] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.07146 (0.10311) | TIME: 0:02:00 |
[VALID F3] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.07658 (0.10297) | TIME: 0:02:14 |
[VALID F3] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.07930 (0.10314) | TIME: 0:02:27 |
[VALID F3] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.09903 (0.10305) | TIME: 0:02:40 |
[VALID F3] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.03218 (0.10255) | TIME: 0:02:43 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.09394 |      0.10255 |  0.45378 | 0.486 | 0.452 | 0.416 | 0.447 | 0.482 | 0.439 | 1:03:08 |


[SAVED] EPOCH: 3 | MCRMSE: 0.453782320022583

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 4/4 | STEP: 0000/1466 | LOSS: 0.07818 (0.07818) | LR: 0.00000330 | TIME: 0:00:02 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0040/1466 | LOSS: 0.05100 (0.08496) | LR: 0.00000314 | TIME: 0:01:39 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0080/1466 | LOSS: 0.13159 (0.08074) | LR: 0.00000297 | TIME: 0:03:20 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0120/1466 | LOSS: 0.10931 (0.08241) | LR: 0.00000281 | TIME: 0:05:02 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0160/1466 | LOSS: 0.06011 (0.07982) | LR: 0.00000265 | TIME: 0:06:39 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0200/1466 | LOSS: 0.04427 (0.08077) | LR: 0.00000250 | TIME: 0:08:21 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0240/1466 | LOSS: 0.05663 (0.08201) | LR: 0.00000235 | TIME: 0:10:02 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0280/1466 | LOSS: 0.06532 (0.08034) | LR: 0.00000221 | TIME: 0:11:39 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0320/1466 | LOSS: 0.08767 (0.08039) | LR: 0.00000207 | TIME: 0:13:23 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0360/1466 | LOSS: 0.03417 (0.08113) | LR: 0.00000193 | TIME: 0:15:01 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0400/1466 | LOSS: 0.05975 (0.07999) | LR: 0.00000180 | TIME: 0:16:43 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0440/1466 | LOSS: 0.10265 (0.07982) | LR: 0.00000167 | TIME: 0:18:25 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0480/1466 | LOSS: 0.06156 (0.08064) | LR: 0.00000154 | TIME: 0:20:09 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0520/1466 | LOSS: 0.13597 (0.08128) | LR: 0.00000142 | TIME: 0:21:43 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0560/1466 | LOSS: 0.20541 (0.08248) | LR: 0.00000131 | TIME: 0:23:23 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0600/1466 | LOSS: 0.05523 (0.08193) | LR: 0.00000120 | TIME: 0:24:49 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0640/1466 | LOSS: 0.06234 (0.08179) | LR: 0.00000109 | TIME: 0:26:35 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0680/1466 | LOSS: 0.07071 (0.08170) | LR: 0.00000099 | TIME: 0:28:13 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0720/1466 | LOSS: 0.08864 (0.08129) | LR: 0.00000089 | TIME: 0:29:49 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0760/1466 | LOSS: 0.11056 (0.08181) | LR: 0.00000080 | TIME: 0:31:28 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0800/1466 | LOSS: 0.08404 (0.08145) | LR: 0.00000071 | TIME: 0:33:11 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0840/1466 | LOSS: 0.04556 (0.08133) | LR: 0.00000063 | TIME: 0:34:41 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0880/1466 | LOSS: 0.16928 (0.08145) | LR: 0.00000055 | TIME: 0:36:19 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0920/1466 | LOSS: 0.14398 (0.08124) | LR: 0.00000048 | TIME: 0:38:03 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0960/1466 | LOSS: 0.08227 (0.08119) | LR: 0.00000041 | TIME: 0:39:45 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1000/1466 | LOSS: 0.03002 (0.08091) | LR: 0.00000035 | TIME: 0:41:21 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1040/1466 | LOSS: 0.03443 (0.08081) | LR: 0.00000029 | TIME: 0:42:59 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1080/1466 | LOSS: 0.06199 (0.08120) | LR: 0.00000024 | TIME: 0:44:40 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1120/1466 | LOSS: 0.04566 (0.08091) | LR: 0.00000019 | TIME: 0:46:14 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1160/1466 | LOSS: 0.03344 (0.08066) | LR: 0.00000015 | TIME: 0:47:57 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1200/1466 | LOSS: 0.08828 (0.08046) | LR: 0.00000011 | TIME: 0:49:36 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1240/1466 | LOSS: 0.05563 (0.08063) | LR: 0.00000008 | TIME: 0:51:16 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1280/1466 | LOSS: 0.09860 (0.08064) | LR: 0.00000006 | TIME: 0:52:56 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1320/1466 | LOSS: 0.07718 (0.08077) | LR: 0.00000003 | TIME: 0:54:40 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1360/1466 | LOSS: 0.14107 (0.08059) | LR: 0.00000002 | TIME: 0:56:19 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1400/1466 | LOSS: 0.06012 (0.08031) | LR: 0.00000001 | TIME: 0:57:58 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1440/1466 | LOSS: 0.05385 (0.08044) | LR: 0.00000000 | TIME: 0:59:42 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1465/1466 | LOSS: 0.04867 (0.08040) | LR: 0.00000000 | TIME: 1:00:45 |

VALID_LOOP
[VALID F3] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.22824 (0.22824) | TIME: 0:00:01 |
[VALID F3] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.11234 (0.10182) | TIME: 0:00:14 |
[VALID F3] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.14327 (0.10468) | TIME: 0:00:27 |
[VALID F3] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.12061 (0.09986) | TIME: 0:00:41 |
[VALID F3] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.07796 (0.09829) | TIME: 0:00:54 |
[VALID F3] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.03951 (0.09958) | TIME: 0:01:07 |
[VALID F3] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.06698 (0.09892) | TIME: 0:01:21 |
[VALID F3] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.03933 (0.10014) | TIME: 0:01:34 |
[VALID F3] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.29693 (0.10113) | TIME: 0:01:47 |
[VALID F3] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.06971 (0.10185) | TIME: 0:02:00 |
[VALID F3] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.06859 (0.10159) | TIME: 0:02:14 |
[VALID F3] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.08721 (0.10206) | TIME: 0:02:27 |
[VALID F3] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.08841 (0.10210) | TIME: 0:02:40 |
[VALID F3] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.03268 (0.10163) | TIME: 0:02:43 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |       0.0804 |      0.10163 |  0.45175 | 0.485 | 0.453 | 0.412 | 0.445 | 0.475 | 0.441 | 1:03:28 |


[SAVED] EPOCH: 4 | MCRMSE: 0.45175424218177795


----------------------------------- FOLD 3 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.45175     0.48545   0.45257       0.41234        0.44484    0.47467        0.44065

################################### END OF FOlD 3 ###################################


