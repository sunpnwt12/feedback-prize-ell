Date: 2022-11-18 09:10:25.738619+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: microsoft/deberta-v3-large
Model_config: DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0.0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.20.1",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Pooling_strategy: concat_attn_mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5864}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 1/4 | STEP: 0000/1466 | LOSS: 2.83489 (2.83489) | LR: 0.00000005 | TIME: 0:00:02 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0040/1466 | LOSS: 1.22753 (1.95931) | LR: 0.00000224 | TIME: 0:01:39 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0080/1466 | LOSS: 0.35179 (1.44615) | LR: 0.00000443 | TIME: 0:02:56 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0120/1466 | LOSS: 0.22926 (1.04507) | LR: 0.00000661 | TIME: 0:04:22 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0160/1466 | LOSS: 0.10921 (0.83647) | LR: 0.00000880 | TIME: 0:06:03 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0200/1466 | LOSS: 0.20213 (0.70876) | LR: 0.00001098 | TIME: 0:07:40 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0240/1466 | LOSS: 0.13039 (0.61733) | LR: 0.00001317 | TIME: 0:09:26 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0280/1466 | LOSS: 0.17407 (0.55079) | LR: 0.00001536 | TIME: 0:11:00 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0320/1466 | LOSS: 0.14891 (0.50245) | LR: 0.00001754 | TIME: 0:12:20 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0360/1466 | LOSS: 0.11335 (0.46222) | LR: 0.00001973 | TIME: 0:13:49 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0400/1466 | LOSS: 0.08537 (0.43073) | LR: 0.00002000 | TIME: 0:15:22 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0440/1466 | LOSS: 0.23553 (0.40623) | LR: 0.00001999 | TIME: 0:16:50 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0480/1466 | LOSS: 0.45871 (0.38494) | LR: 0.00001998 | TIME: 0:18:44 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0520/1466 | LOSS: 0.15340 (0.36701) | LR: 0.00001996 | TIME: 0:20:02 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0560/1466 | LOSS: 0.15052 (0.35089) | LR: 0.00001994 | TIME: 0:21:28 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0600/1466 | LOSS: 0.37590 (0.33727) | LR: 0.00001991 | TIME: 0:22:59 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0640/1466 | LOSS: 0.10255 (0.32486) | LR: 0.00001988 | TIME: 0:24:39 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0680/1466 | LOSS: 0.09454 (0.31280) | LR: 0.00001984 | TIME: 0:26:11 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0720/1466 | LOSS: 0.16970 (0.30240) | LR: 0.00001979 | TIME: 0:27:34 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0760/1466 | LOSS: 0.15948 (0.29396) | LR: 0.00001975 | TIME: 0:29:23 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0800/1466 | LOSS: 0.17800 (0.28610) | LR: 0.00001969 | TIME: 0:31:03 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0840/1466 | LOSS: 0.06407 (0.27925) | LR: 0.00001963 | TIME: 0:32:38 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0880/1466 | LOSS: 0.17837 (0.27222) | LR: 0.00001957 | TIME: 0:34:15 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0920/1466 | LOSS: 0.13668 (0.26619) | LR: 0.00001950 | TIME: 0:35:43 |
[TRAIN F0] EPOCH: 1/4 | STEP: 0960/1466 | LOSS: 0.14001 (0.26139) | LR: 0.00001943 | TIME: 0:37:12 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1000/1466 | LOSS: 0.04353 (0.25580) | LR: 0.00001935 | TIME: 0:38:51 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1040/1466 | LOSS: 0.14340 (0.25125) | LR: 0.00001927 | TIME: 0:40:21 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1080/1466 | LOSS: 0.05393 (0.24713) | LR: 0.00001918 | TIME: 0:42:01 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1120/1466 | LOSS: 0.09814 (0.24302) | LR: 0.00001908 | TIME: 0:43:27 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1160/1466 | LOSS: 0.15303 (0.23958) | LR: 0.00001899 | TIME: 0:44:59 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1200/1466 | LOSS: 0.13253 (0.23527) | LR: 0.00001888 | TIME: 0:46:31 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1240/1466 | LOSS: 0.12698 (0.23186) | LR: 0.00001878 | TIME: 0:48:14 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1280/1466 | LOSS: 0.20661 (0.22852) | LR: 0.00001866 | TIME: 0:49:53 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1320/1466 | LOSS: 0.20679 (0.22539) | LR: 0.00001855 | TIME: 0:51:31 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1360/1466 | LOSS: 0.16559 (0.22296) | LR: 0.00001843 | TIME: 0:53:00 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1400/1466 | LOSS: 0.12332 (0.22058) | LR: 0.00001830 | TIME: 0:54:30 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1440/1466 | LOSS: 0.08668 (0.21837) | LR: 0.00001817 | TIME: 0:56:09 |
[TRAIN F0] EPOCH: 1/4 | STEP: 1465/1466 | LOSS: 0.11290 (0.21647) | LR: 0.00001809 | TIME: 0:57:19 |

VALID_LOOP
[VALID F0] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.08980 (0.08980) | TIME: 0:00:02 |
[VALID F0] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.10502 (0.11934) | TIME: 0:00:41 |
[VALID F0] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.09018 (0.12327) | TIME: 0:01:20 |
[VALID F0] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.15328 (0.12265) | TIME: 0:01:59 |
[VALID F0] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.07083 (0.12377) | TIME: 0:02:39 |
[VALID F0] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.20171 (0.12350) | TIME: 0:03:18 |
[VALID F0] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.09445 (0.12132) | TIME: 0:03:57 |
[VALID F0] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.08944 (0.12065) | TIME: 0:04:36 |
[VALID F0] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.06018 (0.12001) | TIME: 0:05:16 |
[VALID F0] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.11803 (0.11869) | TIME: 0:05:56 |
[VALID F0] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.17217 (0.11751) | TIME: 0:06:35 |
[VALID F0] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.14264 (0.11773) | TIME: 0:07:14 |
[VALID F0] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.06772 (0.11890) | TIME: 0:07:53 |
[VALID F0] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.05162 (0.11890) | TIME: 0:08:01 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.21647 |       0.1189 |  0.48899 | 0.539 | 0.440 | 0.488 | 0.470 | 0.498 | 0.499 | 1:05:20 |


[SAVED] EPOCH: 1 | MCRMSE: 0.4889880120754242

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 2/4 | STEP: 0000/1466 | LOSS: 0.10979 (0.10979) | LR: 0.00001809 | TIME: 0:00:02 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0040/1466 | LOSS: 0.06312 (0.10568) | LR: 0.00001795 | TIME: 0:01:32 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0080/1466 | LOSS: 0.18436 (0.10962) | LR: 0.00001781 | TIME: 0:03:18 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0120/1466 | LOSS: 0.10196 (0.10605) | LR: 0.00001766 | TIME: 0:04:54 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0160/1466 | LOSS: 0.13264 (0.10982) | LR: 0.00001751 | TIME: 0:06:17 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0200/1466 | LOSS: 0.10855 (0.10895) | LR: 0.00001736 | TIME: 0:07:41 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0240/1466 | LOSS: 0.18268 (0.10745) | LR: 0.00001721 | TIME: 0:09:05 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0280/1466 | LOSS: 0.21470 (0.10865) | LR: 0.00001704 | TIME: 0:10:30 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0320/1466 | LOSS: 0.04052 (0.11005) | LR: 0.00001688 | TIME: 0:12:02 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0360/1466 | LOSS: 0.05957 (0.11062) | LR: 0.00001671 | TIME: 0:13:33 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0400/1466 | LOSS: 0.08582 (0.11133) | LR: 0.00001654 | TIME: 0:15:10 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0440/1466 | LOSS: 0.08071 (0.11102) | LR: 0.00001637 | TIME: 0:16:35 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0480/1466 | LOSS: 0.09375 (0.11149) | LR: 0.00001619 | TIME: 0:18:10 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0520/1466 | LOSS: 0.05367 (0.11365) | LR: 0.00001601 | TIME: 0:19:52 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0560/1466 | LOSS: 0.03304 (0.11362) | LR: 0.00001582 | TIME: 0:21:14 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0600/1466 | LOSS: 0.13189 (0.11338) | LR: 0.00001564 | TIME: 0:22:34 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0640/1466 | LOSS: 0.15980 (0.11266) | LR: 0.00001545 | TIME: 0:24:10 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0680/1466 | LOSS: 0.10116 (0.11247) | LR: 0.00001525 | TIME: 0:25:32 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0720/1466 | LOSS: 0.13425 (0.11201) | LR: 0.00001506 | TIME: 0:26:55 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0760/1466 | LOSS: 0.10954 (0.11189) | LR: 0.00001486 | TIME: 0:28:33 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0800/1466 | LOSS: 0.11240 (0.11180) | LR: 0.00001466 | TIME: 0:30:04 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0840/1466 | LOSS: 0.07845 (0.11214) | LR: 0.00001445 | TIME: 0:31:38 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0880/1466 | LOSS: 0.09097 (0.11192) | LR: 0.00001425 | TIME: 0:33:08 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0920/1466 | LOSS: 0.10450 (0.11177) | LR: 0.00001404 | TIME: 0:34:32 |
[TRAIN F0] EPOCH: 2/4 | STEP: 0960/1466 | LOSS: 0.10781 (0.11160) | LR: 0.00001383 | TIME: 0:36:07 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1000/1466 | LOSS: 0.10704 (0.11110) | LR: 0.00001362 | TIME: 0:37:30 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1040/1466 | LOSS: 0.12985 (0.11111) | LR: 0.00001340 | TIME: 0:39:01 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1080/1466 | LOSS: 0.07531 (0.11128) | LR: 0.00001319 | TIME: 0:40:34 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1120/1466 | LOSS: 0.21363 (0.11178) | LR: 0.00001297 | TIME: 0:42:07 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1160/1466 | LOSS: 0.13772 (0.11164) | LR: 0.00001275 | TIME: 0:43:44 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1200/1466 | LOSS: 0.07866 (0.11185) | LR: 0.00001253 | TIME: 0:45:17 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1240/1466 | LOSS: 0.06172 (0.11226) | LR: 0.00001231 | TIME: 0:46:48 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1280/1466 | LOSS: 0.18745 (0.11208) | LR: 0.00001209 | TIME: 0:48:13 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1320/1466 | LOSS: 0.12587 (0.11256) | LR: 0.00001186 | TIME: 0:49:45 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1360/1466 | LOSS: 0.05693 (0.11220) | LR: 0.00001164 | TIME: 0:51:18 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1400/1466 | LOSS: 0.03791 (0.11179) | LR: 0.00001141 | TIME: 0:52:49 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1440/1466 | LOSS: 0.18979 (0.11161) | LR: 0.00001119 | TIME: 0:54:04 |
[TRAIN F0] EPOCH: 2/4 | STEP: 1465/1466 | LOSS: 0.04943 (0.11190) | LR: 0.00001104 | TIME: 0:55:08 |

VALID_LOOP
[VALID F0] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.05672 (0.05672) | TIME: 0:00:01 |
[VALID F0] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.08733 (0.10712) | TIME: 0:00:39 |
[VALID F0] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.04033 (0.10808) | TIME: 0:01:16 |
[VALID F0] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.16150 (0.10927) | TIME: 0:01:54 |
[VALID F0] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.06617 (0.11099) | TIME: 0:02:31 |
[VALID F0] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.19048 (0.11226) | TIME: 0:03:09 |
[VALID F0] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.06670 (0.11132) | TIME: 0:03:46 |
[VALID F0] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.06942 (0.11071) | TIME: 0:04:24 |
[VALID F0] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.07237 (0.10978) | TIME: 0:05:01 |
[VALID F0] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.10859 (0.10867) | TIME: 0:05:38 |
[VALID F0] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.14749 (0.10831) | TIME: 0:06:16 |
[VALID F0] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.14218 (0.10846) | TIME: 0:06:53 |
[VALID F0] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.05141 (0.11003) | TIME: 0:07:30 |
[VALID F0] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.09567 (0.11004) | TIME: 0:07:38 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |       0.1119 |      0.11004 |  0.47049 | 0.501 | 0.460 | 0.444 | 0.467 | 0.486 | 0.465 | 1:02:46 |


[SAVED] EPOCH: 2 | MCRMSE: 0.47049251198768616

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 3/4 | STEP: 0000/1466 | LOSS: 0.03545 (0.03545) | LR: 0.00001104 | TIME: 0:00:04 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0040/1466 | LOSS: 0.07491 (0.09753) | LR: 0.00001081 | TIME: 0:01:37 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0080/1466 | LOSS: 0.10579 (0.09901) | LR: 0.00001058 | TIME: 0:03:20 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0120/1466 | LOSS: 0.12764 (0.09272) | LR: 0.00001035 | TIME: 0:04:51 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0160/1466 | LOSS: 0.10678 (0.08918) | LR: 0.00001013 | TIME: 0:06:25 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0200/1466 | LOSS: 0.05651 (0.09007) | LR: 0.00000990 | TIME: 0:07:52 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0240/1466 | LOSS: 0.05553 (0.09120) | LR: 0.00000967 | TIME: 0:09:19 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0280/1466 | LOSS: 0.08118 (0.09173) | LR: 0.00000944 | TIME: 0:10:46 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0320/1466 | LOSS: 0.14431 (0.09120) | LR: 0.00000921 | TIME: 0:12:11 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0360/1466 | LOSS: 0.04179 (0.09086) | LR: 0.00000898 | TIME: 0:13:35 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0400/1466 | LOSS: 0.18909 (0.09064) | LR: 0.00000876 | TIME: 0:15:02 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0440/1466 | LOSS: 0.12395 (0.09159) | LR: 0.00000853 | TIME: 0:16:37 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0480/1466 | LOSS: 0.21813 (0.09124) | LR: 0.00000831 | TIME: 0:18:04 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0520/1466 | LOSS: 0.09508 (0.09171) | LR: 0.00000808 | TIME: 0:19:46 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0560/1466 | LOSS: 0.10317 (0.09224) | LR: 0.00000786 | TIME: 0:21:29 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0600/1466 | LOSS: 0.11821 (0.09252) | LR: 0.00000763 | TIME: 0:23:10 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0640/1466 | LOSS: 0.12440 (0.09187) | LR: 0.00000741 | TIME: 0:24:39 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0680/1466 | LOSS: 0.27676 (0.09243) | LR: 0.00000719 | TIME: 0:26:19 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0720/1466 | LOSS: 0.04786 (0.09160) | LR: 0.00000697 | TIME: 0:27:54 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0760/1466 | LOSS: 0.11084 (0.09107) | LR: 0.00000676 | TIME: 0:29:18 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0800/1466 | LOSS: 0.09736 (0.09102) | LR: 0.00000654 | TIME: 0:30:55 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0840/1466 | LOSS: 0.09840 (0.09090) | LR: 0.00000633 | TIME: 0:32:24 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0880/1466 | LOSS: 0.09459 (0.09053) | LR: 0.00000612 | TIME: 0:33:49 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0920/1466 | LOSS: 0.05165 (0.09013) | LR: 0.00000591 | TIME: 0:35:17 |
[TRAIN F0] EPOCH: 3/4 | STEP: 0960/1466 | LOSS: 0.14120 (0.09024) | LR: 0.00000570 | TIME: 0:36:52 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1000/1466 | LOSS: 0.10797 (0.09014) | LR: 0.00000549 | TIME: 0:38:22 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1040/1466 | LOSS: 0.15516 (0.08992) | LR: 0.00000529 | TIME: 0:39:48 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1080/1466 | LOSS: 0.10600 (0.09001) | LR: 0.00000509 | TIME: 0:41:24 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1120/1466 | LOSS: 0.09558 (0.08968) | LR: 0.00000489 | TIME: 0:42:53 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1160/1466 | LOSS: 0.07158 (0.08938) | LR: 0.00000470 | TIME: 0:44:28 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1200/1466 | LOSS: 0.13703 (0.08914) | LR: 0.00000451 | TIME: 0:46:00 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1240/1466 | LOSS: 0.09408 (0.08885) | LR: 0.00000432 | TIME: 0:47:40 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1280/1466 | LOSS: 0.09251 (0.08884) | LR: 0.00000413 | TIME: 0:49:10 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1320/1466 | LOSS: 0.07469 (0.08880) | LR: 0.00000395 | TIME: 0:50:45 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1360/1466 | LOSS: 0.06135 (0.08896) | LR: 0.00000377 | TIME: 0:52:23 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1400/1466 | LOSS: 0.06078 (0.08872) | LR: 0.00000359 | TIME: 0:53:54 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1440/1466 | LOSS: 0.10280 (0.08833) | LR: 0.00000341 | TIME: 0:55:25 |
[TRAIN F0] EPOCH: 3/4 | STEP: 1465/1466 | LOSS: 0.05952 (0.08808) | LR: 0.00000331 | TIME: 0:56:26 |

VALID_LOOP
[VALID F0] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.06206 (0.06206) | TIME: 0:00:02 |
[VALID F0] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.11559 (0.10519) | TIME: 0:00:40 |
[VALID F0] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.04870 (0.10710) | TIME: 0:01:19 |
[VALID F0] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.17757 (0.10683) | TIME: 0:01:57 |
[VALID F0] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.05453 (0.10961) | TIME: 0:02:36 |
[VALID F0] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.19184 (0.10977) | TIME: 0:03:15 |
[VALID F0] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.08232 (0.10868) | TIME: 0:03:53 |
[VALID F0] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.06279 (0.10854) | TIME: 0:04:32 |
[VALID F0] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.05712 (0.10725) | TIME: 0:05:11 |
[VALID F0] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.08748 (0.10615) | TIME: 0:05:49 |
[VALID F0] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.15521 (0.10581) | TIME: 0:06:29 |
[VALID F0] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.11530 (0.10586) | TIME: 0:07:07 |
[VALID F0] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.05255 (0.10712) | TIME: 0:07:46 |
[VALID F0] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.08255 (0.10713) | TIME: 0:07:54 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.08808 |      0.10713 |  0.46371 | 0.502 | 0.438 | 0.431 | 0.464 | 0.487 | 0.460 | 1:04:21 |


[SAVED] EPOCH: 3 | MCRMSE: 0.46371421217918396

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F0] EPOCH: 4/4 | STEP: 0000/1466 | LOSS: 0.02602 (0.02602) | LR: 0.00000330 | TIME: 0:00:02 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0040/1466 | LOSS: 0.10640 (0.07948) | LR: 0.00000314 | TIME: 0:01:27 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0080/1466 | LOSS: 0.05802 (0.07752) | LR: 0.00000297 | TIME: 0:03:03 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0120/1466 | LOSS: 0.06490 (0.07521) | LR: 0.00000281 | TIME: 0:04:36 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0160/1466 | LOSS: 0.07567 (0.07407) | LR: 0.00000265 | TIME: 0:06:01 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0200/1466 | LOSS: 0.11878 (0.07390) | LR: 0.00000250 | TIME: 0:07:39 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0240/1466 | LOSS: 0.08840 (0.07336) | LR: 0.00000235 | TIME: 0:09:01 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0280/1466 | LOSS: 0.07687 (0.07276) | LR: 0.00000221 | TIME: 0:10:25 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0320/1466 | LOSS: 0.14123 (0.07293) | LR: 0.00000207 | TIME: 0:12:00 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0360/1466 | LOSS: 0.03757 (0.07298) | LR: 0.00000193 | TIME: 0:13:39 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0400/1466 | LOSS: 0.09218 (0.07193) | LR: 0.00000180 | TIME: 0:15:09 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0440/1466 | LOSS: 0.04893 (0.07115) | LR: 0.00000167 | TIME: 0:16:50 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0480/1466 | LOSS: 0.02589 (0.07073) | LR: 0.00000154 | TIME: 0:18:19 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0520/1466 | LOSS: 0.06378 (0.07070) | LR: 0.00000142 | TIME: 0:19:52 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0560/1466 | LOSS: 0.08987 (0.07061) | LR: 0.00000131 | TIME: 0:21:17 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0600/1466 | LOSS: 0.03961 (0.07054) | LR: 0.00000120 | TIME: 0:22:46 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0640/1466 | LOSS: 0.04824 (0.07060) | LR: 0.00000109 | TIME: 0:24:12 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0680/1466 | LOSS: 0.03745 (0.07054) | LR: 0.00000099 | TIME: 0:25:36 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0720/1466 | LOSS: 0.05048 (0.07041) | LR: 0.00000089 | TIME: 0:27:15 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0760/1466 | LOSS: 0.05237 (0.07041) | LR: 0.00000080 | TIME: 0:28:38 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0800/1466 | LOSS: 0.08637 (0.07056) | LR: 0.00000071 | TIME: 0:30:19 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0840/1466 | LOSS: 0.03835 (0.07023) | LR: 0.00000063 | TIME: 0:31:54 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0880/1466 | LOSS: 0.05798 (0.07013) | LR: 0.00000055 | TIME: 0:33:17 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0920/1466 | LOSS: 0.07033 (0.07001) | LR: 0.00000048 | TIME: 0:34:50 |
[TRAIN F0] EPOCH: 4/4 | STEP: 0960/1466 | LOSS: 0.06611 (0.06984) | LR: 0.00000041 | TIME: 0:36:22 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1000/1466 | LOSS: 0.04392 (0.06987) | LR: 0.00000035 | TIME: 0:37:51 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1040/1466 | LOSS: 0.04121 (0.06979) | LR: 0.00000029 | TIME: 0:39:26 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1080/1466 | LOSS: 0.05003 (0.06943) | LR: 0.00000024 | TIME: 0:40:50 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1120/1466 | LOSS: 0.08686 (0.06952) | LR: 0.00000019 | TIME: 0:42:25 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1160/1466 | LOSS: 0.03019 (0.06947) | LR: 0.00000015 | TIME: 0:43:52 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1200/1466 | LOSS: 0.02075 (0.06965) | LR: 0.00000011 | TIME: 0:45:29 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1240/1466 | LOSS: 0.02660 (0.06947) | LR: 0.00000008 | TIME: 0:47:02 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1280/1466 | LOSS: 0.07949 (0.06943) | LR: 0.00000006 | TIME: 0:48:39 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1320/1466 | LOSS: 0.06145 (0.06948) | LR: 0.00000003 | TIME: 0:50:09 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1360/1466 | LOSS: 0.05337 (0.06950) | LR: 0.00000002 | TIME: 0:51:43 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1400/1466 | LOSS: 0.08552 (0.06941) | LR: 0.00000001 | TIME: 0:53:17 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1440/1466 | LOSS: 0.04622 (0.06939) | LR: 0.00000000 | TIME: 0:54:45 |
[TRAIN F0] EPOCH: 4/4 | STEP: 1465/1466 | LOSS: 0.04149 (0.06923) | LR: 0.00000000 | TIME: 0:55:44 |

VALID_LOOP
[VALID F0] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.06660 (0.06660) | TIME: 0:00:02 |
[VALID F0] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.11007 (0.10345) | TIME: 0:00:40 |
[VALID F0] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.04811 (0.10519) | TIME: 0:01:19 |
[VALID F0] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.16854 (0.10492) | TIME: 0:01:57 |
[VALID F0] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.05232 (0.10748) | TIME: 0:02:36 |
[VALID F0] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.19527 (0.10874) | TIME: 0:03:14 |
[VALID F0] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.08841 (0.10789) | TIME: 0:03:52 |
[VALID F0] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.06036 (0.10788) | TIME: 0:04:31 |
[VALID F0] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.05395 (0.10649) | TIME: 0:05:09 |
[VALID F0] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.09573 (0.10538) | TIME: 0:05:47 |
[VALID F0] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.16653 (0.10527) | TIME: 0:06:25 |
[VALID F0] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.11754 (0.10540) | TIME: 0:07:04 |
[VALID F0] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.04853 (0.10682) | TIME: 0:07:42 |
[VALID F0] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.08546 (0.10681) | TIME: 0:07:50 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.06923 |      0.10681 |  0.46306 | 0.504 | 0.438 | 0.433 | 0.464 | 0.478 | 0.462 | 1:03:35 |


[SAVED] EPOCH: 4 | MCRMSE: 0.4630582630634308


----------------------------------- FOLD 0 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.46306     0.50379   0.43752       0.43273        0.46419    0.47785        0.46227

################################### END OF FOlD 0 ###################################



Date: 2022-11-18 13:52:29.950558+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: microsoft/deberta-v3-large
Model_config: DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0.0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.20.1",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Pooling_strategy: concat_attn_mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5868}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 1/4 | STEP: 0000/1467 | LOSS: 1.83085 (1.83085) | LR: 0.00000005 | TIME: 0:00:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0040/1467 | LOSS: 1.25368 (2.06603) | LR: 0.00000224 | TIME: 0:01:34 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0080/1467 | LOSS: 0.36051 (1.44378) | LR: 0.00000443 | TIME: 0:03:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0120/1467 | LOSS: 0.51002 (1.04738) | LR: 0.00000661 | TIME: 0:04:31 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0160/1467 | LOSS: 0.13045 (0.83717) | LR: 0.00000880 | TIME: 0:06:03 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0200/1467 | LOSS: 0.14276 (0.70519) | LR: 0.00001098 | TIME: 0:07:45 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0240/1467 | LOSS: 0.18168 (0.61506) | LR: 0.00001317 | TIME: 0:09:02 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0280/1467 | LOSS: 0.07163 (0.55141) | LR: 0.00001536 | TIME: 0:10:30 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0320/1467 | LOSS: 0.09153 (0.50339) | LR: 0.00001754 | TIME: 0:12:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0360/1467 | LOSS: 0.14524 (0.46317) | LR: 0.00001973 | TIME: 0:13:40 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0400/1467 | LOSS: 0.28962 (0.43176) | LR: 0.00002000 | TIME: 0:15:12 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0440/1467 | LOSS: 0.09109 (0.40687) | LR: 0.00001999 | TIME: 0:16:42 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0480/1467 | LOSS: 0.09216 (0.38395) | LR: 0.00001998 | TIME: 0:18:17 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0520/1467 | LOSS: 0.13293 (0.36520) | LR: 0.00001996 | TIME: 0:19:40 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0560/1467 | LOSS: 0.06802 (0.34991) | LR: 0.00001994 | TIME: 0:21:16 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0600/1467 | LOSS: 0.13485 (0.33673) | LR: 0.00001991 | TIME: 0:22:38 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0640/1467 | LOSS: 0.08157 (0.32493) | LR: 0.00001988 | TIME: 0:24:12 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0680/1467 | LOSS: 0.13875 (0.31275) | LR: 0.00001984 | TIME: 0:25:40 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0720/1467 | LOSS: 0.18786 (0.30256) | LR: 0.00001980 | TIME: 0:27:11 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0760/1467 | LOSS: 0.04986 (0.29462) | LR: 0.00001975 | TIME: 0:28:35 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0800/1467 | LOSS: 0.22015 (0.28669) | LR: 0.00001969 | TIME: 0:30:02 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0840/1467 | LOSS: 0.07273 (0.28011) | LR: 0.00001963 | TIME: 0:31:37 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0880/1467 | LOSS: 0.09925 (0.27376) | LR: 0.00001957 | TIME: 0:33:11 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0920/1467 | LOSS: 0.19652 (0.26692) | LR: 0.00001950 | TIME: 0:34:34 |
[TRAIN F1] EPOCH: 1/4 | STEP: 0960/1467 | LOSS: 0.30135 (0.26212) | LR: 0.00001943 | TIME: 0:36:13 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1000/1467 | LOSS: 0.24993 (0.25759) | LR: 0.00001935 | TIME: 0:37:52 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1040/1467 | LOSS: 0.12083 (0.25324) | LR: 0.00001927 | TIME: 0:39:26 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1080/1467 | LOSS: 0.14152 (0.24844) | LR: 0.00001918 | TIME: 0:41:04 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1120/1467 | LOSS: 0.03864 (0.24369) | LR: 0.00001909 | TIME: 0:42:46 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1160/1467 | LOSS: 0.19662 (0.24058) | LR: 0.00001899 | TIME: 0:44:28 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1200/1467 | LOSS: 0.06290 (0.23696) | LR: 0.00001888 | TIME: 0:46:05 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1240/1467 | LOSS: 0.30057 (0.23394) | LR: 0.00001878 | TIME: 0:47:38 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1280/1467 | LOSS: 0.04494 (0.23105) | LR: 0.00001867 | TIME: 0:49:11 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1320/1467 | LOSS: 0.16435 (0.22807) | LR: 0.00001855 | TIME: 0:50:44 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1360/1467 | LOSS: 0.06454 (0.22500) | LR: 0.00001843 | TIME: 0:52:30 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1400/1467 | LOSS: 0.12743 (0.22287) | LR: 0.00001830 | TIME: 0:54:00 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1440/1467 | LOSS: 0.08669 (0.21979) | LR: 0.00001817 | TIME: 0:55:28 |
[TRAIN F1] EPOCH: 1/4 | STEP: 1466/1467 | LOSS: 0.07230 (0.21782) | LR: 0.00001809 | TIME: 0:56:29 |

VALID_LOOP
[VALID F1] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.13150 (0.13150) | TIME: 0:00:02 |
[VALID F1] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.14240 (0.11051) | TIME: 0:00:41 |
[VALID F1] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.05189 (0.11363) | TIME: 0:01:21 |
[VALID F1] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.06592 (0.10993) | TIME: 0:02:01 |
[VALID F1] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.11714 (0.10922) | TIME: 0:02:40 |
[VALID F1] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.04072 (0.11076) | TIME: 0:03:21 |
[VALID F1] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.05566 (0.11125) | TIME: 0:04:00 |
[VALID F1] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.05325 (0.11074) | TIME: 0:04:40 |
[VALID F1] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.14752 (0.11175) | TIME: 0:05:20 |
[VALID F1] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.12635 (0.11179) | TIME: 0:05:59 |
[VALID F1] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.05902 (0.11128) | TIME: 0:06:39 |
[VALID F1] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.04566 (0.11161) | TIME: 0:07:19 |
[VALID F1] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.13015 (0.11152) | TIME: 0:07:59 |
[VALID F1] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.06624 (0.11080) | TIME: 0:08:06 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.21782 |       0.1108 |  0.47148 | 0.510 | 0.470 | 0.440 | 0.460 | 0.497 | 0.451 | 1:04:36 |


[SAVED] EPOCH: 1 | MCRMSE: 0.47148314118385315

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 2/4 | STEP: 0000/1467 | LOSS: 0.04146 (0.04146) | LR: 0.00001808 | TIME: 0:00:02 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0040/1467 | LOSS: 0.12099 (0.12255) | LR: 0.00001795 | TIME: 0:01:32 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0080/1467 | LOSS: 0.17153 (0.11699) | LR: 0.00001781 | TIME: 0:03:09 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0120/1467 | LOSS: 0.31195 (0.11487) | LR: 0.00001766 | TIME: 0:04:32 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0160/1467 | LOSS: 0.10019 (0.11201) | LR: 0.00001751 | TIME: 0:05:57 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0200/1467 | LOSS: 0.11630 (0.11325) | LR: 0.00001736 | TIME: 0:07:34 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0240/1467 | LOSS: 0.11501 (0.11431) | LR: 0.00001721 | TIME: 0:08:57 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0280/1467 | LOSS: 0.10251 (0.11422) | LR: 0.00001704 | TIME: 0:10:26 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0320/1467 | LOSS: 0.09643 (0.11397) | LR: 0.00001688 | TIME: 0:11:47 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0360/1467 | LOSS: 0.11165 (0.11297) | LR: 0.00001671 | TIME: 0:13:08 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0400/1467 | LOSS: 0.08938 (0.11239) | LR: 0.00001654 | TIME: 0:14:39 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0440/1467 | LOSS: 0.05874 (0.11156) | LR: 0.00001637 | TIME: 0:16:00 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0480/1467 | LOSS: 0.10909 (0.11107) | LR: 0.00001619 | TIME: 0:17:32 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0520/1467 | LOSS: 0.08141 (0.11072) | LR: 0.00001601 | TIME: 0:19:11 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0560/1467 | LOSS: 0.22582 (0.11216) | LR: 0.00001583 | TIME: 0:20:38 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0600/1467 | LOSS: 0.13303 (0.11325) | LR: 0.00001564 | TIME: 0:22:09 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0640/1467 | LOSS: 0.04064 (0.11327) | LR: 0.00001545 | TIME: 0:23:46 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0680/1467 | LOSS: 0.09002 (0.11327) | LR: 0.00001525 | TIME: 0:25:11 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0720/1467 | LOSS: 0.17412 (0.11341) | LR: 0.00001506 | TIME: 0:26:39 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0760/1467 | LOSS: 0.08722 (0.11332) | LR: 0.00001486 | TIME: 0:28:05 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0800/1467 | LOSS: 0.10379 (0.11319) | LR: 0.00001466 | TIME: 0:29:38 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0840/1467 | LOSS: 0.18846 (0.11351) | LR: 0.00001446 | TIME: 0:31:07 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0880/1467 | LOSS: 0.14191 (0.11342) | LR: 0.00001425 | TIME: 0:32:27 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0920/1467 | LOSS: 0.10001 (0.11348) | LR: 0.00001404 | TIME: 0:33:58 |
[TRAIN F1] EPOCH: 2/4 | STEP: 0960/1467 | LOSS: 0.04226 (0.11301) | LR: 0.00001383 | TIME: 0:35:21 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1000/1467 | LOSS: 0.16560 (0.11259) | LR: 0.00001362 | TIME: 0:36:47 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1040/1467 | LOSS: 0.12392 (0.11225) | LR: 0.00001341 | TIME: 0:38:17 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1080/1467 | LOSS: 0.11997 (0.11210) | LR: 0.00001319 | TIME: 0:39:43 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1120/1467 | LOSS: 0.09076 (0.11213) | LR: 0.00001297 | TIME: 0:41:16 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1160/1467 | LOSS: 0.07894 (0.11179) | LR: 0.00001276 | TIME: 0:42:45 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1200/1467 | LOSS: 0.03768 (0.11170) | LR: 0.00001254 | TIME: 0:44:09 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1240/1467 | LOSS: 0.07495 (0.11169) | LR: 0.00001231 | TIME: 0:45:29 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1280/1467 | LOSS: 0.07617 (0.11190) | LR: 0.00001209 | TIME: 0:47:03 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1320/1467 | LOSS: 0.11546 (0.11182) | LR: 0.00001187 | TIME: 0:48:42 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1360/1467 | LOSS: 0.08284 (0.11186) | LR: 0.00001164 | TIME: 0:50:17 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1400/1467 | LOSS: 0.03374 (0.11147) | LR: 0.00001142 | TIME: 0:52:01 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1440/1467 | LOSS: 0.06533 (0.11159) | LR: 0.00001119 | TIME: 0:53:26 |
[TRAIN F1] EPOCH: 2/4 | STEP: 1466/1467 | LOSS: 0.11152 (0.11137) | LR: 0.00001104 | TIME: 0:54:23 |

VALID_LOOP
[VALID F1] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.07982 (0.07982) | TIME: 0:00:02 |
[VALID F1] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.14204 (0.10042) | TIME: 0:00:38 |
[VALID F1] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.06522 (0.10549) | TIME: 0:01:15 |
[VALID F1] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.04926 (0.10232) | TIME: 0:01:51 |
[VALID F1] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.16093 (0.10265) | TIME: 0:02:28 |
[VALID F1] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.04644 (0.10299) | TIME: 0:03:04 |
[VALID F1] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.03379 (0.10353) | TIME: 0:03:41 |
[VALID F1] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.03219 (0.10323) | TIME: 0:04:18 |
[VALID F1] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.12831 (0.10469) | TIME: 0:04:54 |
[VALID F1] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.10150 (0.10487) | TIME: 0:05:31 |
[VALID F1] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.04082 (0.10512) | TIME: 0:06:08 |
[VALID F1] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.05809 (0.10630) | TIME: 0:06:44 |
[VALID F1] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.16191 (0.10627) | TIME: 0:07:21 |
[VALID F1] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.06483 (0.10574) | TIME: 0:07:28 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11137 |      0.10574 |  0.46041 | 0.490 | 0.471 | 0.406 | 0.468 | 0.477 | 0.450 | 1:01:51 |


[SAVED] EPOCH: 2 | MCRMSE: 0.46040835976600647

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 3/4 | STEP: 0000/1467 | LOSS: 0.07890 (0.07890) | LR: 0.00001104 | TIME: 0:00:05 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0040/1467 | LOSS: 0.04680 (0.09646) | LR: 0.00001081 | TIME: 0:01:41 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0080/1467 | LOSS: 0.15154 (0.10214) | LR: 0.00001058 | TIME: 0:03:19 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0120/1467 | LOSS: 0.10592 (0.09810) | LR: 0.00001035 | TIME: 0:04:39 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0160/1467 | LOSS: 0.04554 (0.09371) | LR: 0.00001013 | TIME: 0:06:12 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0200/1467 | LOSS: 0.10830 (0.09819) | LR: 0.00000990 | TIME: 0:07:54 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0240/1467 | LOSS: 0.06807 (0.09510) | LR: 0.00000967 | TIME: 0:09:21 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0280/1467 | LOSS: 0.08110 (0.09295) | LR: 0.00000944 | TIME: 0:10:39 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0320/1467 | LOSS: 0.05001 (0.09254) | LR: 0.00000921 | TIME: 0:12:12 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0360/1467 | LOSS: 0.07969 (0.09213) | LR: 0.00000899 | TIME: 0:13:42 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0400/1467 | LOSS: 0.05666 (0.09106) | LR: 0.00000876 | TIME: 0:15:07 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0440/1467 | LOSS: 0.16947 (0.09101) | LR: 0.00000853 | TIME: 0:16:46 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0480/1467 | LOSS: 0.08090 (0.09016) | LR: 0.00000831 | TIME: 0:18:12 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0520/1467 | LOSS: 0.07262 (0.08992) | LR: 0.00000808 | TIME: 0:19:55 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0560/1467 | LOSS: 0.08322 (0.08960) | LR: 0.00000786 | TIME: 0:21:21 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0600/1467 | LOSS: 0.12796 (0.08983) | LR: 0.00000764 | TIME: 0:22:48 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0640/1467 | LOSS: 0.04829 (0.08965) | LR: 0.00000741 | TIME: 0:24:19 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0680/1467 | LOSS: 0.13389 (0.08984) | LR: 0.00000719 | TIME: 0:25:42 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0720/1467 | LOSS: 0.14734 (0.08981) | LR: 0.00000698 | TIME: 0:27:08 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0760/1467 | LOSS: 0.02770 (0.08994) | LR: 0.00000676 | TIME: 0:28:49 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0800/1467 | LOSS: 0.06471 (0.09013) | LR: 0.00000654 | TIME: 0:30:10 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0840/1467 | LOSS: 0.10454 (0.08987) | LR: 0.00000633 | TIME: 0:31:41 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0880/1467 | LOSS: 0.10998 (0.08991) | LR: 0.00000612 | TIME: 0:33:14 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0920/1467 | LOSS: 0.28437 (0.08967) | LR: 0.00000591 | TIME: 0:34:47 |
[TRAIN F1] EPOCH: 3/4 | STEP: 0960/1467 | LOSS: 0.10527 (0.08933) | LR: 0.00000570 | TIME: 0:36:14 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1000/1467 | LOSS: 0.04837 (0.08929) | LR: 0.00000550 | TIME: 0:37:48 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1040/1467 | LOSS: 0.03866 (0.08919) | LR: 0.00000529 | TIME: 0:39:18 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1080/1467 | LOSS: 0.03086 (0.08907) | LR: 0.00000509 | TIME: 0:40:55 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1120/1467 | LOSS: 0.07686 (0.08870) | LR: 0.00000490 | TIME: 0:42:27 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1160/1467 | LOSS: 0.04064 (0.08871) | LR: 0.00000470 | TIME: 0:43:51 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1200/1467 | LOSS: 0.07788 (0.08855) | LR: 0.00000451 | TIME: 0:45:19 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1240/1467 | LOSS: 0.08231 (0.08856) | LR: 0.00000432 | TIME: 0:46:46 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1280/1467 | LOSS: 0.05374 (0.08820) | LR: 0.00000413 | TIME: 0:48:08 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1320/1467 | LOSS: 0.16147 (0.08816) | LR: 0.00000395 | TIME: 0:49:42 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1360/1467 | LOSS: 0.05399 (0.08791) | LR: 0.00000377 | TIME: 0:51:09 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1400/1467 | LOSS: 0.12861 (0.08790) | LR: 0.00000359 | TIME: 0:52:35 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1440/1467 | LOSS: 0.07439 (0.08766) | LR: 0.00000342 | TIME: 0:54:04 |
[TRAIN F1] EPOCH: 3/4 | STEP: 1466/1467 | LOSS: 0.22922 (0.08771) | LR: 0.00000331 | TIME: 0:55:01 |

VALID_LOOP
[VALID F1] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.11767 (0.11767) | TIME: 0:00:01 |
[VALID F1] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.12479 (0.10992) | TIME: 0:00:39 |
[VALID F1] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.06794 (0.11305) | TIME: 0:01:17 |
[VALID F1] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.07758 (0.11097) | TIME: 0:01:55 |
[VALID F1] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.13701 (0.11029) | TIME: 0:02:33 |
[VALID F1] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.04170 (0.11084) | TIME: 0:03:11 |
[VALID F1] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.03836 (0.11073) | TIME: 0:03:49 |
[VALID F1] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.06923 (0.11063) | TIME: 0:04:27 |
[VALID F1] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.15688 (0.11031) | TIME: 0:05:05 |
[VALID F1] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.14615 (0.10998) | TIME: 0:05:43 |
[VALID F1] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.06923 (0.10954) | TIME: 0:06:21 |
[VALID F1] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.05709 (0.11021) | TIME: 0:06:59 |
[VALID F1] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.12314 (0.10997) | TIME: 0:07:37 |
[VALID F1] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.08593 (0.10923) | TIME: 0:07:44 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.08771 |      0.10923 |  0.46792 | 0.497 | 0.463 | 0.417 | 0.461 | 0.512 | 0.457 | 1:02:46 |

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F1] EPOCH: 4/4 | STEP: 0000/1467 | LOSS: 0.07752 (0.07752) | LR: 0.00000330 | TIME: 0:00:01 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0040/1467 | LOSS: 0.03474 (0.06412) | LR: 0.00000314 | TIME: 0:01:30 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0080/1467 | LOSS: 0.07936 (0.06762) | LR: 0.00000297 | TIME: 0:02:58 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0120/1467 | LOSS: 0.05135 (0.07198) | LR: 0.00000281 | TIME: 0:04:19 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0160/1467 | LOSS: 0.09788 (0.07221) | LR: 0.00000265 | TIME: 0:05:53 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0200/1467 | LOSS: 0.05162 (0.07060) | LR: 0.00000250 | TIME: 0:07:19 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0240/1467 | LOSS: 0.10672 (0.07320) | LR: 0.00000235 | TIME: 0:08:51 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0280/1467 | LOSS: 0.10569 (0.07173) | LR: 0.00000221 | TIME: 0:10:22 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0320/1467 | LOSS: 0.03076 (0.07239) | LR: 0.00000207 | TIME: 0:11:53 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0360/1467 | LOSS: 0.05638 (0.07195) | LR: 0.00000193 | TIME: 0:13:26 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0400/1467 | LOSS: 0.05823 (0.07238) | LR: 0.00000180 | TIME: 0:14:48 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0440/1467 | LOSS: 0.04377 (0.07256) | LR: 0.00000167 | TIME: 0:16:11 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0480/1467 | LOSS: 0.07203 (0.07275) | LR: 0.00000154 | TIME: 0:17:40 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0520/1467 | LOSS: 0.10562 (0.07286) | LR: 0.00000142 | TIME: 0:19:11 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0560/1467 | LOSS: 0.07138 (0.07175) | LR: 0.00000131 | TIME: 0:20:33 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0600/1467 | LOSS: 0.05922 (0.07169) | LR: 0.00000120 | TIME: 0:22:10 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0640/1467 | LOSS: 0.12001 (0.07151) | LR: 0.00000109 | TIME: 0:23:44 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0680/1467 | LOSS: 0.06236 (0.07148) | LR: 0.00000099 | TIME: 0:25:12 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0720/1467 | LOSS: 0.14994 (0.07147) | LR: 0.00000089 | TIME: 0:26:37 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0760/1467 | LOSS: 0.04663 (0.07119) | LR: 0.00000080 | TIME: 0:28:10 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0800/1467 | LOSS: 0.05922 (0.07131) | LR: 0.00000071 | TIME: 0:29:54 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0840/1467 | LOSS: 0.08606 (0.07132) | LR: 0.00000063 | TIME: 0:31:37 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0880/1467 | LOSS: 0.05874 (0.07110) | LR: 0.00000055 | TIME: 0:33:09 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0920/1467 | LOSS: 0.03630 (0.07106) | LR: 0.00000048 | TIME: 0:34:44 |
[TRAIN F1] EPOCH: 4/4 | STEP: 0960/1467 | LOSS: 0.05418 (0.07084) | LR: 0.00000041 | TIME: 0:36:10 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1000/1467 | LOSS: 0.06149 (0.07075) | LR: 0.00000035 | TIME: 0:37:41 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1040/1467 | LOSS: 0.08719 (0.07072) | LR: 0.00000029 | TIME: 0:39:22 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1080/1467 | LOSS: 0.03184 (0.07037) | LR: 0.00000024 | TIME: 0:40:49 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1120/1467 | LOSS: 0.09536 (0.07067) | LR: 0.00000019 | TIME: 0:42:07 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1160/1467 | LOSS: 0.07235 (0.07059) | LR: 0.00000015 | TIME: 0:43:37 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1200/1467 | LOSS: 0.06672 (0.07109) | LR: 0.00000012 | TIME: 0:45:12 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1240/1467 | LOSS: 0.04643 (0.07094) | LR: 0.00000008 | TIME: 0:46:51 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1280/1467 | LOSS: 0.06861 (0.07103) | LR: 0.00000006 | TIME: 0:48:33 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1320/1467 | LOSS: 0.04609 (0.07102) | LR: 0.00000003 | TIME: 0:50:03 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1360/1467 | LOSS: 0.05137 (0.07083) | LR: 0.00000002 | TIME: 0:51:27 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1400/1467 | LOSS: 0.03382 (0.07076) | LR: 0.00000001 | TIME: 0:52:55 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1440/1467 | LOSS: 0.04761 (0.07079) | LR: 0.00000000 | TIME: 0:54:22 |
[TRAIN F1] EPOCH: 4/4 | STEP: 1466/1467 | LOSS: 0.07439 (0.07062) | LR: 0.00000000 | TIME: 0:55:16 |

VALID_LOOP
[VALID F1] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.08437 (0.08437) | TIME: 0:00:01 |
[VALID F1] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.12290 (0.10106) | TIME: 0:00:39 |
[VALID F1] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.05725 (0.10599) | TIME: 0:01:16 |
[VALID F1] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.05511 (0.10272) | TIME: 0:01:53 |
[VALID F1] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.18150 (0.10229) | TIME: 0:02:31 |
[VALID F1] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.03360 (0.10284) | TIME: 0:03:08 |
[VALID F1] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.03175 (0.10256) | TIME: 0:03:45 |
[VALID F1] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.04386 (0.10251) | TIME: 0:04:22 |
[VALID F1] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.12805 (0.10329) | TIME: 0:05:00 |
[VALID F1] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.10407 (0.10328) | TIME: 0:05:37 |
[VALID F1] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.04907 (0.10348) | TIME: 0:06:14 |
[VALID F1] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.05833 (0.10475) | TIME: 0:06:52 |
[VALID F1] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.15740 (0.10475) | TIME: 0:07:29 |
[VALID F1] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.04655 (0.10412) | TIME: 0:07:36 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.07062 |      0.10412 |  0.45678 | 0.493 | 0.458 | 0.408 | 0.456 | 0.481 | 0.445 | 1:02:53 |


[SAVED] EPOCH: 4 | MCRMSE: 0.4567841589450836


----------------------------------- FOLD 1 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.45678     0.49254   0.45765       0.40754        0.45631    0.48136        0.44531

################################### END OF FOlD 1 ###################################


Date: 2022-11-18 18:20:32.353538+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: microsoft/deberta-v3-large
Model_config: DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0.0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.20.1",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Pooling_strategy: concat_attn_mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5864}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 1/4 | STEP: 0000/1466 | LOSS: 1.48396 (1.48396) | LR: 0.00000005 | TIME: 0:00:03 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0040/1466 | LOSS: 1.01872 (1.86369) | LR: 0.00000224 | TIME: 0:01:49 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0080/1466 | LOSS: 0.19541 (1.30022) | LR: 0.00000443 | TIME: 0:03:17 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0120/1466 | LOSS: 0.05167 (0.94565) | LR: 0.00000661 | TIME: 0:05:02 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0160/1466 | LOSS: 0.18135 (0.76018) | LR: 0.00000880 | TIME: 0:06:39 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0200/1466 | LOSS: 0.05969 (0.64867) | LR: 0.00001098 | TIME: 0:08:04 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0240/1466 | LOSS: 0.07651 (0.56924) | LR: 0.00001317 | TIME: 0:09:35 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0280/1466 | LOSS: 0.16514 (0.51400) | LR: 0.00001536 | TIME: 0:11:11 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0320/1466 | LOSS: 0.10274 (0.46865) | LR: 0.00001754 | TIME: 0:12:47 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0360/1466 | LOSS: 0.15725 (0.43339) | LR: 0.00001973 | TIME: 0:14:14 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0400/1466 | LOSS: 0.16725 (0.40789) | LR: 0.00002000 | TIME: 0:15:52 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0440/1466 | LOSS: 0.21323 (0.38452) | LR: 0.00001999 | TIME: 0:17:28 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0480/1466 | LOSS: 0.12627 (0.36511) | LR: 0.00001998 | TIME: 0:19:02 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0520/1466 | LOSS: 0.07668 (0.34744) | LR: 0.00001996 | TIME: 0:20:33 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0560/1466 | LOSS: 0.09545 (0.33218) | LR: 0.00001994 | TIME: 0:22:10 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0600/1466 | LOSS: 0.12679 (0.32065) | LR: 0.00001991 | TIME: 0:23:51 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0640/1466 | LOSS: 0.20897 (0.30996) | LR: 0.00001988 | TIME: 0:25:20 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0680/1466 | LOSS: 0.05798 (0.30049) | LR: 0.00001984 | TIME: 0:26:51 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0720/1466 | LOSS: 0.28754 (0.29183) | LR: 0.00001979 | TIME: 0:28:26 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0760/1466 | LOSS: 0.56856 (0.28597) | LR: 0.00001975 | TIME: 0:30:11 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0800/1466 | LOSS: 0.25456 (0.27811) | LR: 0.00001969 | TIME: 0:31:47 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0840/1466 | LOSS: 0.13815 (0.27144) | LR: 0.00001963 | TIME: 0:33:35 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0880/1466 | LOSS: 0.08816 (0.26472) | LR: 0.00001957 | TIME: 0:35:12 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0920/1466 | LOSS: 0.08267 (0.25859) | LR: 0.00001950 | TIME: 0:37:00 |
[TRAIN F2] EPOCH: 1/4 | STEP: 0960/1466 | LOSS: 0.04418 (0.25344) | LR: 0.00001943 | TIME: 0:38:41 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1000/1466 | LOSS: 0.29625 (0.24953) | LR: 0.00001935 | TIME: 0:40:29 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1040/1466 | LOSS: 0.08963 (0.24449) | LR: 0.00001927 | TIME: 0:42:06 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1080/1466 | LOSS: 0.18395 (0.23978) | LR: 0.00001918 | TIME: 0:43:52 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1120/1466 | LOSS: 0.11972 (0.23536) | LR: 0.00001908 | TIME: 0:45:35 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1160/1466 | LOSS: 0.08460 (0.23191) | LR: 0.00001899 | TIME: 0:47:05 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1200/1466 | LOSS: 0.14346 (0.22838) | LR: 0.00001888 | TIME: 0:48:36 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1240/1466 | LOSS: 0.19543 (0.22499) | LR: 0.00001878 | TIME: 0:50:07 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1280/1466 | LOSS: 0.07997 (0.22220) | LR: 0.00001866 | TIME: 0:51:52 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1320/1466 | LOSS: 0.14507 (0.21978) | LR: 0.00001855 | TIME: 0:53:29 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1360/1466 | LOSS: 0.09084 (0.21762) | LR: 0.00001843 | TIME: 0:55:13 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1400/1466 | LOSS: 0.19070 (0.21524) | LR: 0.00001830 | TIME: 0:56:39 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1440/1466 | LOSS: 0.13142 (0.21271) | LR: 0.00001817 | TIME: 0:58:13 |
[TRAIN F2] EPOCH: 1/4 | STEP: 1465/1466 | LOSS: 0.24436 (0.21167) | LR: 0.00001809 | TIME: 0:59:18 |

VALID_LOOP
[VALID F2] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.07051 (0.07051) | TIME: 0:00:02 |
[VALID F2] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.07521 (0.14772) | TIME: 0:00:42 |
[VALID F2] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.12484 (0.14187) | TIME: 0:01:22 |
[VALID F2] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.10019 (0.14193) | TIME: 0:02:03 |
[VALID F2] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.05445 (0.14312) | TIME: 0:02:44 |
[VALID F2] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.19648 (0.14397) | TIME: 0:03:25 |
[VALID F2] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.10943 (0.14660) | TIME: 0:04:05 |
[VALID F2] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.18494 (0.14724) | TIME: 0:04:46 |
[VALID F2] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.17436 (0.14786) | TIME: 0:05:26 |
[VALID F2] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.23184 (0.14774) | TIME: 0:06:07 |
[VALID F2] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.15588 (0.14858) | TIME: 0:06:48 |
[VALID F2] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.47486 (0.14923) | TIME: 0:07:27 |
[VALID F2] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.05666 (0.14901) | TIME: 0:08:06 |
[VALID F2] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.04849 (0.14884) | TIME: 0:08:14 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.21167 |      0.14884 |  0.54526 | 0.520 | 0.648 | 0.418 | 0.593 | 0.552 | 0.541 | 1:07:33 |


[SAVED] EPOCH: 1 | MCRMSE: 0.545263946056366

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 2/4 | STEP: 0000/1466 | LOSS: 0.18297 (0.18297) | LR: 0.00001809 | TIME: 0:00:03 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0040/1466 | LOSS: 0.10166 (0.12335) | LR: 0.00001795 | TIME: 0:01:34 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0080/1466 | LOSS: 0.04889 (0.12431) | LR: 0.00001781 | TIME: 0:03:00 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0120/1466 | LOSS: 0.11413 (0.12173) | LR: 0.00001766 | TIME: 0:04:26 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0160/1466 | LOSS: 0.14186 (0.12241) | LR: 0.00001751 | TIME: 0:06:12 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0200/1466 | LOSS: 0.14572 (0.12477) | LR: 0.00001736 | TIME: 0:08:02 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0240/1466 | LOSS: 0.14304 (0.12342) | LR: 0.00001721 | TIME: 0:09:40 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0280/1466 | LOSS: 0.09878 (0.12192) | LR: 0.00001704 | TIME: 0:11:10 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0320/1466 | LOSS: 0.07667 (0.12222) | LR: 0.00001688 | TIME: 0:12:35 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0360/1466 | LOSS: 0.23033 (0.12123) | LR: 0.00001671 | TIME: 0:14:16 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0400/1466 | LOSS: 0.08533 (0.11972) | LR: 0.00001654 | TIME: 0:15:51 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0440/1466 | LOSS: 0.12222 (0.11832) | LR: 0.00001637 | TIME: 0:17:24 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0480/1466 | LOSS: 0.05044 (0.11847) | LR: 0.00001619 | TIME: 0:19:02 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0520/1466 | LOSS: 0.16240 (0.11758) | LR: 0.00001601 | TIME: 0:20:42 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0560/1466 | LOSS: 0.22118 (0.11706) | LR: 0.00001582 | TIME: 0:22:07 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0600/1466 | LOSS: 0.09978 (0.11642) | LR: 0.00001564 | TIME: 0:23:39 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0640/1466 | LOSS: 0.09939 (0.11602) | LR: 0.00001545 | TIME: 0:25:01 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0680/1466 | LOSS: 0.12192 (0.11515) | LR: 0.00001525 | TIME: 0:26:39 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0720/1466 | LOSS: 0.19931 (0.11473) | LR: 0.00001506 | TIME: 0:28:05 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0760/1466 | LOSS: 0.08693 (0.11578) | LR: 0.00001486 | TIME: 0:29:55 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0800/1466 | LOSS: 0.08960 (0.11562) | LR: 0.00001466 | TIME: 0:31:28 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0840/1466 | LOSS: 0.05092 (0.11551) | LR: 0.00001445 | TIME: 0:32:51 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0880/1466 | LOSS: 0.06859 (0.11486) | LR: 0.00001425 | TIME: 0:34:22 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0920/1466 | LOSS: 0.07548 (0.11499) | LR: 0.00001404 | TIME: 0:36:02 |
[TRAIN F2] EPOCH: 2/4 | STEP: 0960/1466 | LOSS: 0.14494 (0.11470) | LR: 0.00001383 | TIME: 0:37:34 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1000/1466 | LOSS: 0.19757 (0.11466) | LR: 0.00001362 | TIME: 0:39:13 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1040/1466 | LOSS: 0.03824 (0.11459) | LR: 0.00001340 | TIME: 0:40:44 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1080/1466 | LOSS: 0.05283 (0.11492) | LR: 0.00001319 | TIME: 0:42:30 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1120/1466 | LOSS: 0.04814 (0.11444) | LR: 0.00001297 | TIME: 0:43:59 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1160/1466 | LOSS: 0.20277 (0.11415) | LR: 0.00001275 | TIME: 0:45:25 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1200/1466 | LOSS: 0.02325 (0.11422) | LR: 0.00001253 | TIME: 0:46:56 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1240/1466 | LOSS: 0.19751 (0.11417) | LR: 0.00001231 | TIME: 0:48:48 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1280/1466 | LOSS: 0.16696 (0.11457) | LR: 0.00001209 | TIME: 0:50:23 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1320/1466 | LOSS: 0.08017 (0.11423) | LR: 0.00001186 | TIME: 0:51:54 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1360/1466 | LOSS: 0.05993 (0.11417) | LR: 0.00001164 | TIME: 0:53:25 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1400/1466 | LOSS: 0.04881 (0.11377) | LR: 0.00001141 | TIME: 0:54:59 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1440/1466 | LOSS: 0.11618 (0.11396) | LR: 0.00001119 | TIME: 0:56:23 |
[TRAIN F2] EPOCH: 2/4 | STEP: 1465/1466 | LOSS: 0.07301 (0.11391) | LR: 0.00001104 | TIME: 0:57:17 |

VALID_LOOP
[VALID F2] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.03649 (0.03649) | TIME: 0:00:02 |
[VALID F2] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.18799 (0.10906) | TIME: 0:00:39 |
[VALID F2] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.04769 (0.10404) | TIME: 0:01:17 |
[VALID F2] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.07664 (0.10368) | TIME: 0:01:54 |
[VALID F2] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.12088 (0.10588) | TIME: 0:02:32 |
[VALID F2] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.06731 (0.10278) | TIME: 0:03:09 |
[VALID F2] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.07000 (0.10649) | TIME: 0:03:47 |
[VALID F2] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.03878 (0.10557) | TIME: 0:04:24 |
[VALID F2] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.11043 (0.10569) | TIME: 0:05:01 |
[VALID F2] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.13240 (0.10587) | TIME: 0:05:38 |
[VALID F2] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.08895 (0.10560) | TIME: 0:06:16 |
[VALID F2] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.15067 (0.10589) | TIME: 0:06:53 |
[VALID F2] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.12579 (0.10523) | TIME: 0:07:30 |
[VALID F2] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.14199 (0.10489) | TIME: 0:07:38 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11391 |      0.10489 |  0.45901 | 0.480 | 0.477 | 0.429 | 0.447 | 0.475 | 0.446 | 1:04:55 |


[SAVED] EPOCH: 2 | MCRMSE: 0.45900657773017883

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 3/4 | STEP: 0000/1466 | LOSS: 0.04960 (0.04960) | LR: 0.00001104 | TIME: 0:00:03 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0040/1466 | LOSS: 0.08098 (0.10148) | LR: 0.00001081 | TIME: 0:01:29 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0080/1466 | LOSS: 0.16367 (0.10054) | LR: 0.00001058 | TIME: 0:03:06 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0120/1466 | LOSS: 0.10568 (0.09791) | LR: 0.00001035 | TIME: 0:04:49 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0160/1466 | LOSS: 0.05525 (0.09531) | LR: 0.00001013 | TIME: 0:06:16 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0200/1466 | LOSS: 0.05394 (0.09345) | LR: 0.00000990 | TIME: 0:07:54 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0240/1466 | LOSS: 0.17469 (0.09277) | LR: 0.00000967 | TIME: 0:09:23 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0280/1466 | LOSS: 0.05749 (0.09272) | LR: 0.00000944 | TIME: 0:10:49 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0320/1466 | LOSS: 0.10078 (0.09252) | LR: 0.00000921 | TIME: 0:12:27 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0360/1466 | LOSS: 0.07892 (0.09202) | LR: 0.00000898 | TIME: 0:14:06 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0400/1466 | LOSS: 0.09192 (0.09205) | LR: 0.00000876 | TIME: 0:15:45 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0440/1466 | LOSS: 0.10142 (0.09163) | LR: 0.00000853 | TIME: 0:17:16 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0480/1466 | LOSS: 0.05314 (0.08980) | LR: 0.00000831 | TIME: 0:18:38 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0520/1466 | LOSS: 0.04191 (0.08958) | LR: 0.00000808 | TIME: 0:20:00 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0560/1466 | LOSS: 0.10909 (0.08930) | LR: 0.00000786 | TIME: 0:21:31 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0600/1466 | LOSS: 0.11254 (0.08970) | LR: 0.00000763 | TIME: 0:23:08 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0640/1466 | LOSS: 0.09694 (0.08976) | LR: 0.00000741 | TIME: 0:24:31 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0680/1466 | LOSS: 0.05728 (0.08951) | LR: 0.00000719 | TIME: 0:25:56 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0720/1466 | LOSS: 0.06345 (0.08949) | LR: 0.00000697 | TIME: 0:27:38 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0760/1466 | LOSS: 0.10019 (0.08980) | LR: 0.00000676 | TIME: 0:29:08 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0800/1466 | LOSS: 0.07162 (0.09010) | LR: 0.00000654 | TIME: 0:30:53 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0840/1466 | LOSS: 0.08573 (0.08964) | LR: 0.00000633 | TIME: 0:32:21 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0880/1466 | LOSS: 0.12438 (0.08971) | LR: 0.00000612 | TIME: 0:34:05 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0920/1466 | LOSS: 0.01971 (0.08935) | LR: 0.00000591 | TIME: 0:35:34 |
[TRAIN F2] EPOCH: 3/4 | STEP: 0960/1466 | LOSS: 0.04114 (0.08909) | LR: 0.00000570 | TIME: 0:37:09 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1000/1466 | LOSS: 0.03295 (0.08905) | LR: 0.00000549 | TIME: 0:38:41 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1040/1466 | LOSS: 0.04745 (0.08913) | LR: 0.00000529 | TIME: 0:40:29 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1080/1466 | LOSS: 0.06325 (0.08876) | LR: 0.00000509 | TIME: 0:42:01 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1120/1466 | LOSS: 0.03474 (0.08870) | LR: 0.00000489 | TIME: 0:43:40 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1160/1466 | LOSS: 0.06492 (0.08830) | LR: 0.00000470 | TIME: 0:45:16 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1200/1466 | LOSS: 0.09846 (0.08813) | LR: 0.00000451 | TIME: 0:46:55 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1240/1466 | LOSS: 0.04396 (0.08793) | LR: 0.00000432 | TIME: 0:48:23 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1280/1466 | LOSS: 0.04647 (0.08825) | LR: 0.00000413 | TIME: 0:50:05 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1320/1466 | LOSS: 0.13006 (0.08799) | LR: 0.00000395 | TIME: 0:51:42 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1360/1466 | LOSS: 0.07734 (0.08788) | LR: 0.00000377 | TIME: 0:53:25 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1400/1466 | LOSS: 0.07268 (0.08757) | LR: 0.00000359 | TIME: 0:54:57 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1440/1466 | LOSS: 0.18594 (0.08770) | LR: 0.00000341 | TIME: 0:56:40 |
[TRAIN F2] EPOCH: 3/4 | STEP: 1465/1466 | LOSS: 0.10251 (0.08760) | LR: 0.00000331 | TIME: 0:57:47 |

VALID_LOOP
[VALID F2] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.03634 (0.03634) | TIME: 0:00:01 |
[VALID F2] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.13025 (0.10293) | TIME: 0:00:40 |
[VALID F2] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.04828 (0.09721) | TIME: 0:01:19 |
[VALID F2] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.06108 (0.09694) | TIME: 0:01:58 |
[VALID F2] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.10868 (0.09945) | TIME: 0:02:36 |
[VALID F2] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.09024 (0.09724) | TIME: 0:03:16 |
[VALID F2] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.05956 (0.10050) | TIME: 0:03:55 |
[VALID F2] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.03697 (0.09953) | TIME: 0:04:34 |
[VALID F2] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.12381 (0.09951) | TIME: 0:05:13 |
[VALID F2] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.17151 (0.09973) | TIME: 0:05:52 |
[VALID F2] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.07567 (0.09960) | TIME: 0:06:31 |
[VALID F2] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.19554 (0.10029) | TIME: 0:07:10 |
[VALID F2] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.07814 (0.09998) | TIME: 0:07:49 |
[VALID F2] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.10016 (0.09961) | TIME: 0:07:57 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |       0.0876 |      0.09961 |  0.44686 | 0.465 | 0.452 | 0.410 | 0.455 | 0.464 | 0.435 | 1:05:45 |


[SAVED] EPOCH: 3 | MCRMSE: 0.44685837626457214

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F2] EPOCH: 4/4 | STEP: 0000/1466 | LOSS: 0.04587 (0.04587) | LR: 0.00000330 | TIME: 0:00:02 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0040/1466 | LOSS: 0.06706 (0.08440) | LR: 0.00000314 | TIME: 0:01:50 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0080/1466 | LOSS: 0.09321 (0.08138) | LR: 0.00000297 | TIME: 0:03:23 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0120/1466 | LOSS: 0.08618 (0.07831) | LR: 0.00000281 | TIME: 0:04:59 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0160/1466 | LOSS: 0.07217 (0.07717) | LR: 0.00000265 | TIME: 0:06:36 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0200/1466 | LOSS: 0.05830 (0.07525) | LR: 0.00000250 | TIME: 0:08:12 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0240/1466 | LOSS: 0.09502 (0.07441) | LR: 0.00000235 | TIME: 0:09:50 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0280/1466 | LOSS: 0.05210 (0.07324) | LR: 0.00000221 | TIME: 0:11:16 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0320/1466 | LOSS: 0.04283 (0.07181) | LR: 0.00000207 | TIME: 0:12:49 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0360/1466 | LOSS: 0.09140 (0.07166) | LR: 0.00000193 | TIME: 0:14:18 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0400/1466 | LOSS: 0.04544 (0.07171) | LR: 0.00000180 | TIME: 0:16:03 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0440/1466 | LOSS: 0.09138 (0.07166) | LR: 0.00000167 | TIME: 0:17:31 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0480/1466 | LOSS: 0.08491 (0.07117) | LR: 0.00000154 | TIME: 0:18:46 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0520/1466 | LOSS: 0.06826 (0.07097) | LR: 0.00000142 | TIME: 0:20:16 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0560/1466 | LOSS: 0.19503 (0.07118) | LR: 0.00000131 | TIME: 0:21:51 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0600/1466 | LOSS: 0.08469 (0.07088) | LR: 0.00000120 | TIME: 0:23:24 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0640/1466 | LOSS: 0.10043 (0.07066) | LR: 0.00000109 | TIME: 0:25:03 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0680/1466 | LOSS: 0.05704 (0.07067) | LR: 0.00000099 | TIME: 0:26:33 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0720/1466 | LOSS: 0.05274 (0.07060) | LR: 0.00000089 | TIME: 0:28:11 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0760/1466 | LOSS: 0.06310 (0.07034) | LR: 0.00000080 | TIME: 0:29:39 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0800/1466 | LOSS: 0.08563 (0.06999) | LR: 0.00000071 | TIME: 0:31:13 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0840/1466 | LOSS: 0.06439 (0.07013) | LR: 0.00000063 | TIME: 0:32:51 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0880/1466 | LOSS: 0.04610 (0.07021) | LR: 0.00000055 | TIME: 0:34:46 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0920/1466 | LOSS: 0.03552 (0.07015) | LR: 0.00000048 | TIME: 0:36:21 |
[TRAIN F2] EPOCH: 4/4 | STEP: 0960/1466 | LOSS: 0.07035 (0.07011) | LR: 0.00000041 | TIME: 0:37:51 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1000/1466 | LOSS: 0.13513 (0.07009) | LR: 0.00000035 | TIME: 0:39:20 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1040/1466 | LOSS: 0.05765 (0.06980) | LR: 0.00000029 | TIME: 0:40:45 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1080/1466 | LOSS: 0.09754 (0.06996) | LR: 0.00000024 | TIME: 0:42:16 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1120/1466 | LOSS: 0.07089 (0.07004) | LR: 0.00000019 | TIME: 0:44:04 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1160/1466 | LOSS: 0.04998 (0.06989) | LR: 0.00000015 | TIME: 0:45:29 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1200/1466 | LOSS: 0.03041 (0.07007) | LR: 0.00000011 | TIME: 0:47:04 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1240/1466 | LOSS: 0.11058 (0.07011) | LR: 0.00000008 | TIME: 0:48:28 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1280/1466 | LOSS: 0.04133 (0.07002) | LR: 0.00000006 | TIME: 0:50:03 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1320/1466 | LOSS: 0.09632 (0.07045) | LR: 0.00000003 | TIME: 0:51:24 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1360/1466 | LOSS: 0.06254 (0.07064) | LR: 0.00000002 | TIME: 0:52:57 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1400/1466 | LOSS: 0.07915 (0.07049) | LR: 0.00000001 | TIME: 0:54:32 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1440/1466 | LOSS: 0.07970 (0.07055) | LR: 0.00000000 | TIME: 0:56:06 |
[TRAIN F2] EPOCH: 4/4 | STEP: 1465/1466 | LOSS: 0.10062 (0.07045) | LR: 0.00000000 | TIME: 0:56:58 |

VALID_LOOP
[VALID F2] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.03769 (0.03769) | TIME: 0:00:01 |
[VALID F2] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.12650 (0.10185) | TIME: 0:00:39 |
[VALID F2] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.04850 (0.09687) | TIME: 0:01:16 |
[VALID F2] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.07156 (0.09630) | TIME: 0:01:54 |
[VALID F2] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.10444 (0.09862) | TIME: 0:02:32 |
[VALID F2] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.09083 (0.09647) | TIME: 0:03:09 |
[VALID F2] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.05992 (0.09967) | TIME: 0:03:47 |
[VALID F2] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.04139 (0.09867) | TIME: 0:04:24 |
[VALID F2] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.12202 (0.09884) | TIME: 0:05:02 |
[VALID F2] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.16822 (0.09906) | TIME: 0:05:39 |
[VALID F2] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.08985 (0.09898) | TIME: 0:06:17 |
[VALID F2] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.19879 (0.09956) | TIME: 0:06:55 |
[VALID F2] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.07844 (0.09929) | TIME: 0:07:32 |
[VALID F2] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.09891 (0.09891) | TIME: 0:07:40 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.07045 |      0.09891 |  0.44531 | 0.464 | 0.448 | 0.411 | 0.454 | 0.464 | 0.430 | 1:04:38 |


[SAVED] EPOCH: 4 | MCRMSE: 0.4453061819076538


----------------------------------- FOLD 2 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
 0.44531     0.46389   0.44767       0.41118        0.45442    0.46447        0.43021

################################### END OF FOlD 2 ###################################


Date: 2022-11-18 22:59:03.110903+07:00 (GMT+7)
Mode: EXPERIMENTING_MODE
Train_on: cuda, (AMP: True, GradScaler: True)
Model: microsoft/deberta-v3-large
Model_config: DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0.0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.20.1",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Pooling_strategy: concat_attn_mean_pooling
Initailzation: None
AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1
SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112
Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])
Loss_fn: SmoothL1Loss()
Optimizer: AdamW
LR: (Backbone: 1e-05, LowerLayer: 2e-05)
LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 366, 'num_training_steps': 5864}
Grad_clip_norm: False (max_norm: 10)
Number_of_batches: 2 (Gradient_accumulate: 1)
max_len: 1024

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 1/4 | STEP: 0000/1466 | LOSS: 2.48102 (2.48102) | LR: 0.00000005 | TIME: 0:00:02 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0040/1466 | LOSS: 1.72826 (1.97007) | LR: 0.00000224 | TIME: 0:01:33 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0080/1466 | LOSS: 0.18071 (1.44630) | LR: 0.00000443 | TIME: 0:02:55 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0120/1466 | LOSS: 0.12028 (1.03479) | LR: 0.00000661 | TIME: 0:04:13 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0160/1466 | LOSS: 0.18130 (0.82716) | LR: 0.00000880 | TIME: 0:05:58 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0200/1466 | LOSS: 0.18068 (0.69868) | LR: 0.00001098 | TIME: 0:07:43 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0240/1466 | LOSS: 0.14657 (0.60975) | LR: 0.00001317 | TIME: 0:09:11 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0280/1466 | LOSS: 0.17681 (0.54802) | LR: 0.00001536 | TIME: 0:10:46 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0320/1466 | LOSS: 0.14410 (0.50029) | LR: 0.00001754 | TIME: 0:12:08 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0360/1466 | LOSS: 0.07991 (0.46153) | LR: 0.00001973 | TIME: 0:13:37 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0400/1466 | LOSS: 0.14843 (0.43213) | LR: 0.00002000 | TIME: 0:15:01 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0440/1466 | LOSS: 0.10038 (0.40566) | LR: 0.00001999 | TIME: 0:16:40 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0480/1466 | LOSS: 0.15609 (0.38513) | LR: 0.00001998 | TIME: 0:18:28 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0520/1466 | LOSS: 0.48180 (0.36810) | LR: 0.00001996 | TIME: 0:19:55 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0560/1466 | LOSS: 0.17916 (0.35192) | LR: 0.00001994 | TIME: 0:21:14 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0600/1466 | LOSS: 0.33570 (0.33865) | LR: 0.00001991 | TIME: 0:22:30 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0640/1466 | LOSS: 0.10806 (0.32616) | LR: 0.00001988 | TIME: 0:24:06 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0680/1466 | LOSS: 0.12836 (0.31557) | LR: 0.00001984 | TIME: 0:25:36 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0720/1466 | LOSS: 0.10995 (0.30574) | LR: 0.00001979 | TIME: 0:27:14 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0760/1466 | LOSS: 0.07634 (0.29617) | LR: 0.00001975 | TIME: 0:28:41 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0800/1466 | LOSS: 0.06872 (0.28780) | LR: 0.00001969 | TIME: 0:30:21 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0840/1466 | LOSS: 0.07558 (0.28070) | LR: 0.00001963 | TIME: 0:31:51 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0880/1466 | LOSS: 0.11890 (0.27494) | LR: 0.00001957 | TIME: 0:33:26 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0920/1466 | LOSS: 0.03757 (0.26858) | LR: 0.00001950 | TIME: 0:34:56 |
[TRAIN F3] EPOCH: 1/4 | STEP: 0960/1466 | LOSS: 0.10882 (0.26284) | LR: 0.00001943 | TIME: 0:36:21 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1000/1466 | LOSS: 0.05343 (0.25714) | LR: 0.00001935 | TIME: 0:37:49 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1040/1466 | LOSS: 0.21531 (0.25274) | LR: 0.00001927 | TIME: 0:39:31 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1080/1466 | LOSS: 0.10216 (0.24827) | LR: 0.00001918 | TIME: 0:41:05 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1120/1466 | LOSS: 0.12796 (0.24408) | LR: 0.00001908 | TIME: 0:42:34 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1160/1466 | LOSS: 0.12866 (0.24021) | LR: 0.00001899 | TIME: 0:44:07 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1200/1466 | LOSS: 0.09318 (0.23690) | LR: 0.00001888 | TIME: 0:45:37 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1240/1466 | LOSS: 0.24551 (0.23372) | LR: 0.00001878 | TIME: 0:47:03 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1280/1466 | LOSS: 0.13486 (0.23082) | LR: 0.00001866 | TIME: 0:48:41 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1320/1466 | LOSS: 0.06899 (0.22749) | LR: 0.00001855 | TIME: 0:50:16 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1360/1466 | LOSS: 0.18122 (0.22542) | LR: 0.00001843 | TIME: 0:51:54 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1400/1466 | LOSS: 0.11167 (0.22309) | LR: 0.00001830 | TIME: 0:53:27 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1440/1466 | LOSS: 0.11546 (0.22084) | LR: 0.00001817 | TIME: 0:55:00 |
[TRAIN F3] EPOCH: 1/4 | STEP: 1465/1466 | LOSS: 0.12792 (0.21957) | LR: 0.00001809 | TIME: 0:55:56 |

VALID_LOOP
[VALID F3] EPOCH: 1/4 | STEP: 000/489 | LOSS: 0.22555 (0.22555) | TIME: 0:00:02 |
[VALID F3] EPOCH: 1/4 | STEP: 040/489 | LOSS: 0.04954 (0.10843) | TIME: 0:00:41 |
[VALID F3] EPOCH: 1/4 | STEP: 080/489 | LOSS: 0.17326 (0.11014) | TIME: 0:01:21 |
[VALID F3] EPOCH: 1/4 | STEP: 120/489 | LOSS: 0.14884 (0.10889) | TIME: 0:02:00 |
[VALID F3] EPOCH: 1/4 | STEP: 160/489 | LOSS: 0.08600 (0.10922) | TIME: 0:02:39 |
[VALID F3] EPOCH: 1/4 | STEP: 200/489 | LOSS: 0.12637 (0.10709) | TIME: 0:03:18 |
[VALID F3] EPOCH: 1/4 | STEP: 240/489 | LOSS: 0.13043 (0.10503) | TIME: 0:03:57 |
[VALID F3] EPOCH: 1/4 | STEP: 280/489 | LOSS: 0.05967 (0.10799) | TIME: 0:04:37 |
[VALID F3] EPOCH: 1/4 | STEP: 320/489 | LOSS: 0.11104 (0.10913) | TIME: 0:05:16 |
[VALID F3] EPOCH: 1/4 | STEP: 360/489 | LOSS: 0.10045 (0.10808) | TIME: 0:05:55 |
[VALID F3] EPOCH: 1/4 | STEP: 400/489 | LOSS: 0.11197 (0.10903) | TIME: 0:06:33 |
[VALID F3] EPOCH: 1/4 | STEP: 440/489 | LOSS: 0.05769 (0.11017) | TIME: 0:07:12 |
[VALID F3] EPOCH: 1/4 | STEP: 480/489 | LOSS: 0.06023 (0.11020) | TIME: 0:07:50 |
[VALID F3] EPOCH: 1/4 | STEP: 488/489 | LOSS: 0.05329 (0.11019) | TIME: 0:07:58 |

--------------------
EPOCH: 1/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 1/4     |      0.21957 |      0.11019 |  0.47027 | 0.493 | 0.514 | 0.437 | 0.454 | 0.476 | 0.448 | 1:03:54 |


[SAVED] EPOCH: 1 | MCRMSE: 0.47026732563972473

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 2/4 | STEP: 0000/1466 | LOSS: 0.07544 (0.07544) | LR: 0.00001809 | TIME: 0:00:02 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0040/1466 | LOSS: 0.10369 (0.11884) | LR: 0.00001795 | TIME: 0:01:22 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0080/1466 | LOSS: 0.11390 (0.12021) | LR: 0.00001781 | TIME: 0:03:02 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0120/1466 | LOSS: 0.07307 (0.11994) | LR: 0.00001766 | TIME: 0:04:33 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0160/1466 | LOSS: 0.09304 (0.11838) | LR: 0.00001751 | TIME: 0:05:56 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0200/1466 | LOSS: 0.19588 (0.11975) | LR: 0.00001736 | TIME: 0:07:23 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0240/1466 | LOSS: 0.14827 (0.11741) | LR: 0.00001721 | TIME: 0:08:51 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0280/1466 | LOSS: 0.26771 (0.11671) | LR: 0.00001704 | TIME: 0:10:13 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0320/1466 | LOSS: 0.06633 (0.11987) | LR: 0.00001688 | TIME: 0:11:36 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0360/1466 | LOSS: 0.06254 (0.11895) | LR: 0.00001671 | TIME: 0:13:09 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0400/1466 | LOSS: 0.12614 (0.11820) | LR: 0.00001654 | TIME: 0:14:29 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0440/1466 | LOSS: 0.10241 (0.11791) | LR: 0.00001637 | TIME: 0:16:02 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0480/1466 | LOSS: 0.08770 (0.11636) | LR: 0.00001619 | TIME: 0:17:31 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0520/1466 | LOSS: 0.10177 (0.11521) | LR: 0.00001601 | TIME: 0:19:01 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0560/1466 | LOSS: 0.06272 (0.11362) | LR: 0.00001582 | TIME: 0:20:20 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0600/1466 | LOSS: 0.12103 (0.11271) | LR: 0.00001564 | TIME: 0:21:50 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0640/1466 | LOSS: 0.06205 (0.11285) | LR: 0.00001545 | TIME: 0:23:13 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0680/1466 | LOSS: 0.09368 (0.11305) | LR: 0.00001525 | TIME: 0:24:36 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0720/1466 | LOSS: 0.10103 (0.11361) | LR: 0.00001506 | TIME: 0:26:00 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0760/1466 | LOSS: 0.06715 (0.11374) | LR: 0.00001486 | TIME: 0:27:26 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0800/1466 | LOSS: 0.14800 (0.11398) | LR: 0.00001466 | TIME: 0:29:10 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0840/1466 | LOSS: 0.11528 (0.11401) | LR: 0.00001445 | TIME: 0:30:39 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0880/1466 | LOSS: 0.13483 (0.11386) | LR: 0.00001425 | TIME: 0:31:55 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0920/1466 | LOSS: 0.10454 (0.11367) | LR: 0.00001404 | TIME: 0:33:14 |
[TRAIN F3] EPOCH: 2/4 | STEP: 0960/1466 | LOSS: 0.06143 (0.11336) | LR: 0.00001383 | TIME: 0:34:49 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1000/1466 | LOSS: 0.04973 (0.11388) | LR: 0.00001362 | TIME: 0:36:19 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1040/1466 | LOSS: 0.04755 (0.11339) | LR: 0.00001340 | TIME: 0:37:45 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1080/1466 | LOSS: 0.14837 (0.11284) | LR: 0.00001319 | TIME: 0:39:22 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1120/1466 | LOSS: 0.10872 (0.11267) | LR: 0.00001297 | TIME: 0:40:48 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1160/1466 | LOSS: 0.10987 (0.11301) | LR: 0.00001275 | TIME: 0:42:18 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1200/1466 | LOSS: 0.10884 (0.11360) | LR: 0.00001253 | TIME: 0:43:40 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1240/1466 | LOSS: 0.08568 (0.11297) | LR: 0.00001231 | TIME: 0:45:02 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1280/1466 | LOSS: 0.13211 (0.11281) | LR: 0.00001209 | TIME: 0:46:33 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1320/1466 | LOSS: 0.05079 (0.11249) | LR: 0.00001186 | TIME: 0:48:07 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1360/1466 | LOSS: 0.12679 (0.11224) | LR: 0.00001164 | TIME: 0:49:32 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1400/1466 | LOSS: 0.06145 (0.11216) | LR: 0.00001141 | TIME: 0:51:10 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1440/1466 | LOSS: 0.09287 (0.11234) | LR: 0.00001119 | TIME: 0:52:42 |
[TRAIN F3] EPOCH: 2/4 | STEP: 1465/1466 | LOSS: 0.05777 (0.11226) | LR: 0.00001104 | TIME: 0:53:42 |

VALID_LOOP
[VALID F3] EPOCH: 2/4 | STEP: 000/489 | LOSS: 0.31496 (0.31496) | TIME: 0:00:01 |
[VALID F3] EPOCH: 2/4 | STEP: 040/489 | LOSS: 0.07888 (0.10979) | TIME: 0:00:38 |
[VALID F3] EPOCH: 2/4 | STEP: 080/489 | LOSS: 0.19129 (0.11022) | TIME: 0:01:14 |
[VALID F3] EPOCH: 2/4 | STEP: 120/489 | LOSS: 0.13059 (0.10604) | TIME: 0:01:51 |
[VALID F3] EPOCH: 2/4 | STEP: 160/489 | LOSS: 0.05415 (0.10664) | TIME: 0:02:28 |
[VALID F3] EPOCH: 2/4 | STEP: 200/489 | LOSS: 0.10540 (0.10523) | TIME: 0:03:04 |
[VALID F3] EPOCH: 2/4 | STEP: 240/489 | LOSS: 0.09101 (0.10341) | TIME: 0:03:41 |
[VALID F3] EPOCH: 2/4 | STEP: 280/489 | LOSS: 0.04593 (0.10613) | TIME: 0:04:17 |
[VALID F3] EPOCH: 2/4 | STEP: 320/489 | LOSS: 0.10682 (0.10673) | TIME: 0:04:54 |
[VALID F3] EPOCH: 2/4 | STEP: 360/489 | LOSS: 0.10207 (0.10549) | TIME: 0:05:30 |
[VALID F3] EPOCH: 2/4 | STEP: 400/489 | LOSS: 0.06948 (0.10592) | TIME: 0:06:07 |
[VALID F3] EPOCH: 2/4 | STEP: 440/489 | LOSS: 0.06110 (0.10688) | TIME: 0:06:43 |
[VALID F3] EPOCH: 2/4 | STEP: 480/489 | LOSS: 0.07210 (0.10649) | TIME: 0:07:20 |
[VALID F3] EPOCH: 2/4 | STEP: 488/489 | LOSS: 0.04020 (0.10626) | TIME: 0:07:27 |

--------------------
EPOCH: 2/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 2/4     |      0.11226 |      0.10626 |  0.46184 | 0.485 | 0.462 | 0.445 | 0.464 | 0.476 | 0.438 | 1:01:09 |


[SAVED] EPOCH: 2 | MCRMSE: 0.46183618903160095

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 3/4 | STEP: 0000/1466 | LOSS: 0.04880 (0.04880) | LR: 0.00001104 | TIME: 0:00:03 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0040/1466 | LOSS: 0.05968 (0.10407) | LR: 0.00001081 | TIME: 0:01:33 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0080/1466 | LOSS: 0.08588 (0.09748) | LR: 0.00001058 | TIME: 0:03:03 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0120/1466 | LOSS: 0.07145 (0.09070) | LR: 0.00001035 | TIME: 0:04:24 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0160/1466 | LOSS: 0.07341 (0.09216) | LR: 0.00001013 | TIME: 0:05:53 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0200/1466 | LOSS: 0.05710 (0.09048) | LR: 0.00000990 | TIME: 0:07:16 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0240/1466 | LOSS: 0.05643 (0.09120) | LR: 0.00000967 | TIME: 0:08:44 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0280/1466 | LOSS: 0.08351 (0.09234) | LR: 0.00000944 | TIME: 0:10:17 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0320/1466 | LOSS: 0.05687 (0.09210) | LR: 0.00000921 | TIME: 0:11:49 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0360/1466 | LOSS: 0.07785 (0.09068) | LR: 0.00000898 | TIME: 0:13:13 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0400/1466 | LOSS: 0.10886 (0.09144) | LR: 0.00000876 | TIME: 0:14:50 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0440/1466 | LOSS: 0.16007 (0.09234) | LR: 0.00000853 | TIME: 0:16:21 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0480/1466 | LOSS: 0.06394 (0.09313) | LR: 0.00000831 | TIME: 0:17:46 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0520/1466 | LOSS: 0.07690 (0.09354) | LR: 0.00000808 | TIME: 0:19:21 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0560/1466 | LOSS: 0.21583 (0.09311) | LR: 0.00000786 | TIME: 0:21:00 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0600/1466 | LOSS: 0.17375 (0.09238) | LR: 0.00000763 | TIME: 0:22:24 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0640/1466 | LOSS: 0.12725 (0.09132) | LR: 0.00000741 | TIME: 0:23:53 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0680/1466 | LOSS: 0.08453 (0.09097) | LR: 0.00000719 | TIME: 0:25:23 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0720/1466 | LOSS: 0.04208 (0.09104) | LR: 0.00000697 | TIME: 0:26:47 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0760/1466 | LOSS: 0.11476 (0.09097) | LR: 0.00000676 | TIME: 0:28:25 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0800/1466 | LOSS: 0.10134 (0.09050) | LR: 0.00000654 | TIME: 0:29:56 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0840/1466 | LOSS: 0.05243 (0.09037) | LR: 0.00000633 | TIME: 0:31:35 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0880/1466 | LOSS: 0.05836 (0.09047) | LR: 0.00000612 | TIME: 0:33:04 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0920/1466 | LOSS: 0.09959 (0.08999) | LR: 0.00000591 | TIME: 0:34:43 |
[TRAIN F3] EPOCH: 3/4 | STEP: 0960/1466 | LOSS: 0.11719 (0.08967) | LR: 0.00000570 | TIME: 0:36:08 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1000/1466 | LOSS: 0.09181 (0.08992) | LR: 0.00000549 | TIME: 0:37:43 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1040/1466 | LOSS: 0.05294 (0.08969) | LR: 0.00000529 | TIME: 0:39:09 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1080/1466 | LOSS: 0.07222 (0.08957) | LR: 0.00000509 | TIME: 0:40:33 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1120/1466 | LOSS: 0.08975 (0.08947) | LR: 0.00000489 | TIME: 0:41:59 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1160/1466 | LOSS: 0.12576 (0.08931) | LR: 0.00000470 | TIME: 0:43:23 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1200/1466 | LOSS: 0.08120 (0.08885) | LR: 0.00000451 | TIME: 0:44:54 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1240/1466 | LOSS: 0.11153 (0.08848) | LR: 0.00000432 | TIME: 0:46:34 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1280/1466 | LOSS: 0.09451 (0.08851) | LR: 0.00000413 | TIME: 0:48:09 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1320/1466 | LOSS: 0.07505 (0.08815) | LR: 0.00000395 | TIME: 0:49:42 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1360/1466 | LOSS: 0.22284 (0.08830) | LR: 0.00000377 | TIME: 0:51:11 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1400/1466 | LOSS: 0.04331 (0.08793) | LR: 0.00000359 | TIME: 0:52:47 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1440/1466 | LOSS: 0.02006 (0.08767) | LR: 0.00000341 | TIME: 0:54:10 |
[TRAIN F3] EPOCH: 3/4 | STEP: 1465/1466 | LOSS: 0.19699 (0.08758) | LR: 0.00000331 | TIME: 0:54:58 |

VALID_LOOP
[VALID F3] EPOCH: 3/4 | STEP: 000/489 | LOSS: 0.29676 (0.29676) | TIME: 0:00:01 |
[VALID F3] EPOCH: 3/4 | STEP: 040/489 | LOSS: 0.06212 (0.10017) | TIME: 0:00:39 |
[VALID F3] EPOCH: 3/4 | STEP: 080/489 | LOSS: 0.15645 (0.10302) | TIME: 0:01:17 |
[VALID F3] EPOCH: 3/4 | STEP: 120/489 | LOSS: 0.09004 (0.10021) | TIME: 0:01:54 |
[VALID F3] EPOCH: 3/4 | STEP: 160/489 | LOSS: 0.05786 (0.10149) | TIME: 0:02:32 |
[VALID F3] EPOCH: 3/4 | STEP: 200/489 | LOSS: 0.12558 (0.09981) | TIME: 0:03:10 |
[VALID F3] EPOCH: 3/4 | STEP: 240/489 | LOSS: 0.09736 (0.09727) | TIME: 0:03:48 |
[VALID F3] EPOCH: 3/4 | STEP: 280/489 | LOSS: 0.06423 (0.10027) | TIME: 0:04:25 |
[VALID F3] EPOCH: 3/4 | STEP: 320/489 | LOSS: 0.11370 (0.10152) | TIME: 0:05:03 |
[VALID F3] EPOCH: 3/4 | STEP: 360/489 | LOSS: 0.08586 (0.10067) | TIME: 0:05:41 |
[VALID F3] EPOCH: 3/4 | STEP: 400/489 | LOSS: 0.07939 (0.10091) | TIME: 0:06:19 |
[VALID F3] EPOCH: 3/4 | STEP: 440/489 | LOSS: 0.04743 (0.10154) | TIME: 0:06:57 |
[VALID F3] EPOCH: 3/4 | STEP: 480/489 | LOSS: 0.05292 (0.10115) | TIME: 0:07:35 |
[VALID F3] EPOCH: 3/4 | STEP: 488/489 | LOSS: 0.03285 (0.10107) | TIME: 0:07:43 |

--------------------
EPOCH: 3/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 3/4     |      0.08758 |      0.10107 |  0.45032 | 0.477 | 0.443 | 0.420 | 0.453 | 0.473 | 0.436 | 1:02:41 |


[SAVED] EPOCH: 3 | MCRMSE: 0.4503219425678253

TRAIN_LOOP
AWP_ACTIVATED
[TRAIN F3] EPOCH: 4/4 | STEP: 0000/1466 | LOSS: 0.15414 (0.15414) | LR: 0.00000330 | TIME: 0:00:02 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0040/1466 | LOSS: 0.04322 (0.07590) | LR: 0.00000314 | TIME: 0:01:22 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0080/1466 | LOSS: 0.08742 (0.07251) | LR: 0.00000297 | TIME: 0:02:50 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0120/1466 | LOSS: 0.07262 (0.07346) | LR: 0.00000281 | TIME: 0:04:24 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0160/1466 | LOSS: 0.07114 (0.07299) | LR: 0.00000265 | TIME: 0:05:56 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0200/1466 | LOSS: 0.20603 (0.07424) | LR: 0.00000250 | TIME: 0:07:28 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0240/1466 | LOSS: 0.09099 (0.07109) | LR: 0.00000235 | TIME: 0:08:53 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0280/1466 | LOSS: 0.03233 (0.07219) | LR: 0.00000221 | TIME: 0:10:17 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0320/1466 | LOSS: 0.04907 (0.07086) | LR: 0.00000207 | TIME: 0:11:46 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0360/1466 | LOSS: 0.03759 (0.07095) | LR: 0.00000193 | TIME: 0:13:11 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0400/1466 | LOSS: 0.06876 (0.07094) | LR: 0.00000180 | TIME: 0:14:31 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0440/1466 | LOSS: 0.03809 (0.07084) | LR: 0.00000167 | TIME: 0:15:55 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0480/1466 | LOSS: 0.02605 (0.07048) | LR: 0.00000154 | TIME: 0:17:19 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0520/1466 | LOSS: 0.04905 (0.07030) | LR: 0.00000142 | TIME: 0:18:40 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0560/1466 | LOSS: 0.12647 (0.07022) | LR: 0.00000131 | TIME: 0:20:21 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0600/1466 | LOSS: 0.04963 (0.07014) | LR: 0.00000120 | TIME: 0:21:53 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0640/1466 | LOSS: 0.24174 (0.07009) | LR: 0.00000109 | TIME: 0:23:25 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0680/1466 | LOSS: 0.06431 (0.07035) | LR: 0.00000099 | TIME: 0:24:51 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0720/1466 | LOSS: 0.07393 (0.07048) | LR: 0.00000089 | TIME: 0:26:12 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0760/1466 | LOSS: 0.05125 (0.07027) | LR: 0.00000080 | TIME: 0:27:37 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0800/1466 | LOSS: 0.04373 (0.07044) | LR: 0.00000071 | TIME: 0:29:03 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0840/1466 | LOSS: 0.05233 (0.07082) | LR: 0.00000063 | TIME: 0:30:30 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0880/1466 | LOSS: 0.06301 (0.07059) | LR: 0.00000055 | TIME: 0:31:51 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0920/1466 | LOSS: 0.06244 (0.07059) | LR: 0.00000048 | TIME: 0:33:23 |
[TRAIN F3] EPOCH: 4/4 | STEP: 0960/1466 | LOSS: 0.05581 (0.07044) | LR: 0.00000041 | TIME: 0:34:43 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1000/1466 | LOSS: 0.02762 (0.07061) | LR: 0.00000035 | TIME: 0:36:03 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1040/1466 | LOSS: 0.10213 (0.07069) | LR: 0.00000029 | TIME: 0:37:20 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1080/1466 | LOSS: 0.07250 (0.07092) | LR: 0.00000024 | TIME: 0:38:44 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1120/1466 | LOSS: 0.04778 (0.07090) | LR: 0.00000019 | TIME: 0:40:30 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1160/1466 | LOSS: 0.09348 (0.07086) | LR: 0.00000015 | TIME: 0:42:00 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1200/1466 | LOSS: 0.09114 (0.07062) | LR: 0.00000011 | TIME: 0:43:24 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1240/1466 | LOSS: 0.06283 (0.07042) | LR: 0.00000008 | TIME: 0:45:10 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1280/1466 | LOSS: 0.04787 (0.07043) | LR: 0.00000006 | TIME: 0:46:51 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1320/1466 | LOSS: 0.06904 (0.07036) | LR: 0.00000003 | TIME: 0:48:27 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1360/1466 | LOSS: 0.02626 (0.07057) | LR: 0.00000002 | TIME: 0:49:57 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1400/1466 | LOSS: 0.06086 (0.07052) | LR: 0.00000001 | TIME: 0:51:22 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1440/1466 | LOSS: 0.08229 (0.07046) | LR: 0.00000000 | TIME: 0:52:45 |
[TRAIN F3] EPOCH: 4/4 | STEP: 1465/1466 | LOSS: 0.02257 (0.07048) | LR: 0.00000000 | TIME: 0:53:45 |

VALID_LOOP
[VALID F3] EPOCH: 4/4 | STEP: 000/489 | LOSS: 0.30197 (0.30197) | TIME: 0:00:01 |
[VALID F3] EPOCH: 4/4 | STEP: 040/489 | LOSS: 0.05353 (0.09934) | TIME: 0:00:38 |
[VALID F3] EPOCH: 4/4 | STEP: 080/489 | LOSS: 0.16154 (0.10311) | TIME: 0:01:14 |
[VALID F3] EPOCH: 4/4 | STEP: 120/489 | LOSS: 0.07871 (0.10063) | TIME: 0:01:51 |
[VALID F3] EPOCH: 4/4 | STEP: 160/489 | LOSS: 0.06307 (0.10239) | TIME: 0:02:27 |
[VALID F3] EPOCH: 4/4 | STEP: 200/489 | LOSS: 0.13541 (0.10056) | TIME: 0:03:04 |
[VALID F3] EPOCH: 4/4 | STEP: 240/489 | LOSS: 0.09337 (0.09758) | TIME: 0:03:40 |
[VALID F3] EPOCH: 4/4 | STEP: 280/489 | LOSS: 0.06751 (0.10058) | TIME: 0:04:16 |
[VALID F3] EPOCH: 4/4 | STEP: 320/489 | LOSS: 0.11366 (0.10181) | TIME: 0:04:53 |
[VALID F3] EPOCH: 4/4 | STEP: 360/489 | LOSS: 0.08187 (0.10096) | TIME: 0:05:29 |
[VALID F3] EPOCH: 4/4 | STEP: 400/489 | LOSS: 0.07631 (0.10111) | TIME: 0:06:06 |
[VALID F3] EPOCH: 4/4 | STEP: 440/489 | LOSS: 0.04881 (0.10157) | TIME: 0:06:42 |
[VALID F3] EPOCH: 4/4 | STEP: 480/489 | LOSS: 0.05310 (0.10108) | TIME: 0:07:19 |
[VALID F3] EPOCH: 4/4 | STEP: 488/489 | LOSS: 0.03494 (0.10104) | TIME: 0:07:26 |

--------------------
EPOCH: 4/4 SUMMARY
--------------------
| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |
|---------|--------------|--------------|----------|-----------------------------------------------|---------|
| 4/4     |      0.07048 |      0.10104 |   0.4502 | 0.477 | 0.444 | 0.418 | 0.450 | 0.475 | 0.437 | 1:01:12 |


[SAVED] EPOCH: 4 | MCRMSE: 0.45020148158073425


----------------------------------- FOLD 3 RESULT -----------------------------------
  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions
--------  ----------  --------  ------------  -------------  ---------  -------------
  0.4502     0.47664   0.44406        0.4184        0.45014    0.47483        0.43714

################################### END OF FOlD 3 ###################################


