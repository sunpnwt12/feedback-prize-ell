{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZeDAOtLCTr8",
        "outputId": "c5ad5555-a998-4ae7-b7ed-0ff099b4d844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 29 04:32:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh8o1rD2CcA5",
        "outputId": "1317c17c-fc50-4bc1-e988-2474ee9916ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.11.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (1637.0 MB)\n",
            "\u001b[K     |████████████████▎               | 834.1 MB 1.3 MB/s eta 0:10:10tcmalloc: large alloc 1147494400 bytes == 0x64cc4000 @  0x7f398edb2615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████▋           | 1055.7 MB 1.3 MB/s eta 0:07:18tcmalloc: large alloc 1434370048 bytes == 0x24ec000 @  0x7f398edb2615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |██████████████████████████▏     | 1336.2 MB 1.3 MB/s eta 0:04:00tcmalloc: large alloc 1792966656 bytes == 0x57cd8000 @  0x7f398edb2615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████████████████| 1636.9 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 1636958208 bytes == 0xc2ac0000 @  0x7f398edb11e7 0x4b2590 0x4b261c 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6\n",
            "tcmalloc: large alloc 2046197760 bytes == 0x1243e0000 @  0x7f398edb2615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x4bad99 0x4d3249\n",
            "\u001b[K     |████████████████████████████████| 1637.0 MB 6.3 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.12.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.11.0\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0+cu113) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (2022.9.24)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n",
            "\u001b[K     |████████████████████████████████| 529 kB 26.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 31.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 64.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 39.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install -q torchmetrics\n",
        "!pip install -q transformers==4.20.1\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q kaggle --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOFn9ZgwCeKE"
      },
      "outputs": [],
      "source": [
        "prepare_data = True\n",
        "import os\n",
        "if os.path.exists('/content/data'):\n",
        "    prepare_data = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "06mmzCLSCfdr",
        "outputId": "aa6c7aa7-7c4d-42b2-d902-91961876d069"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edffb908-4714-4e4e-aeac-0f22684a80a1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-edffb908-4714-4e4e-aeac-0f22684a80a1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 65 bytes\n",
            "Downloading feedback-prize-english-language-learning.zip to /content/data\n",
            " 71% 2.00M/2.80M [00:01<00:00, 2.25MB/s]\n",
            "100% 2.80M/2.80M [00:01<00:00, 2.57MB/s]\n",
            "Archive:  /content/data/feedback-prize-english-language-learning.zip\n",
            "  inflating: /content/data/sample_submission.csv  \n",
            "  inflating: /content/data/test.csv  \n",
            "  inflating: /content/data/train.csv  \n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if prepare_data:    \n",
        "    from google.colab import files, drive\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "            name=fn, length=len(uploaded[fn])))\n",
        "    \n",
        "    # Then move kaggle.json into the folder where the API expects to find it.\n",
        "    !mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    !mkdir data && cd data && kaggle competitions download -c feedback-prize-english-language-learning\n",
        "    !unzip /content/data/feedback-prize-english-language-learning.zip -d /content/data/\n",
        "\n",
        "    # !mkdir data/pretrained && cd data/pretrained && kaggle datasets download -d sunpnwt12/fb3-pretrained-s42\n",
        "    # !unzip /content/data/pretrained/fb3-pretrained-s42.zip -d /content/data/pretrained/\n",
        "\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TIIoPUNCTr_",
        "outputId": "b96f03df-0a39-485b-d288-7279f7fdf3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python version: 3.7.15 (default, Oct 12 2022, 19:14:55) \n",
            "[GCC 7.5.0]\n",
            "iterstart version: 0.1.6\n",
            "torch version: 1.11.0+cu113\n",
            "transfromers version: 4.20.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "import gc; gc.enable()\n",
        "import random\n",
        "import warnings\n",
        "import yaml\n",
        "from itertools import chain\n",
        "from pathlib import Path\n",
        "from tabulate import tabulate\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(f'python version: {sys.version}') \n",
        "\n",
        "os.system('pip install -q iterative-stratification==0.1.7')\n",
        "import iterstrat\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "print(f'iterstart version: {iterstrat.__version__}')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "\n",
        "print(f'torch version: {torch.__version__}')\n",
        "\n",
        "from torchmetrics.functional import mean_squared_error\n",
        "\n",
        "# os.system('pip install --root-user-action=ignore --force-reinstall transformers==4.22.1')\n",
        "import transformers\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig, DataCollatorWithPadding\n",
        "print(f'transfromers version: {transformers.__version__}')\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6gx9T4kCTsA"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui5K2GNVCTsD"
      },
      "outputs": [],
      "source": [
        "class BASICCONF:\n",
        "    seed = 42\n",
        "    \n",
        "    data_path = '/content/data'\n",
        "    \n",
        "    target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
        "    num_labels = 6\n",
        "    num_folds = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrPNKiEmCTsE"
      },
      "source": [
        "# Seeding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuSsOvr5CTsF"
      },
      "outputs": [],
      "source": [
        "#https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\n",
        "def seed_everything(seed: int):    \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(BASICCONF.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68GCXTsnCTsG"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik9Ilb7MCTsG"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = f'{BASICCONF.data_path}/train.csv'\n",
        "TEST_PATH = f'{BASICCONF.data_path}/test.csv'\n",
        "SAMP_SUB = f'{BASICCONF.data_path}/sample_submission.csv'\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "samp_sup = pd.read_csv(SAMP_SUB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHfCEbB-CTsH"
      },
      "source": [
        "## split CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxIVrficCTsI",
        "outputId": "391f582d-3f3e-4de7-bcc7-47bc65aa1119"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fold\n",
              "0    978\n",
              "1    977\n",
              "2    978\n",
              "3    978\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def split_cv(conf, df_):\n",
        "    df = df_.copy(deep=True)\n",
        "    mskf = MultilabelStratifiedKFold(n_splits=conf.num_folds, shuffle=True, random_state=conf.seed)\n",
        "    y = df[conf.target_cols]\n",
        "\n",
        "    for n, (train_index, valid_index) in enumerate(mskf.split(df, y)):\n",
        "        df.loc[ｖalid_index, 'fold'] = int(n)\n",
        "    \n",
        "    df['fold'] = df['fold'].astype(int)\n",
        "        \n",
        "    return df\n",
        "        \n",
        "# train_df = train_df.drop(train_df[train_df['text_id'] == 'F69C85F4C3CA'].index).reset_index(drop=True)\n",
        "df = split_cv(BASICCONF, train_df)\n",
        "df.groupby('fold').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O0Kn0ClCTsJ"
      },
      "outputs": [],
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "# all_text = df['full_text']\n",
        "# def ft_array_dist(full_texts, tokenizer):\n",
        "#     lengths = []\n",
        "#     for text in full_texts.fillna('').values:\n",
        "#         length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "#         lengths.append(length)\n",
        "#     lengths = np.array(lengths)\n",
        "#     return lengths\n",
        "\n",
        "# all_text_l = ft_array_dist(all_text, tokenizer)\n",
        "# plt.hist(all_text_l, 40)\n",
        "# ft_fold = df[df['fold'] != 1]['full_text']\n",
        "# l_fold = ft_array_dist(ft_fold, tokenizer)\n",
        "# plt.hist(l_fold, 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efo6V_kKCTsK"
      },
      "outputs": [],
      "source": [
        "class FB3Dataset(Dataset):\n",
        "    def __init__(self, conf, df, tokenizer, fold):\n",
        "        self.labels = df[conf.target_cols].reset_index(drop=True)\n",
        "        self.full_texts = df['full_text'].reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        if conf.dynamic_max_len:\n",
        "            self.max_len = self._get_max_len()\n",
        "        else:\n",
        "            self.max_len = conf.static_max_len_list[fold]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.full_texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        token = self._get_token(idx)\n",
        "        label = self._get_label(idx)\n",
        "        \n",
        "        return token, label\n",
        "    \n",
        "    def _get_label(self, idx):\n",
        "        return torch.tensor(self.labels.loc[idx].values, dtype=torch.float)\n",
        "    \n",
        "    def _get_token(self, idx):\n",
        "        tokenized = self.tokenizer(\n",
        "                        self.full_texts.loc[idx],\n",
        "                        add_special_tokens=True,\n",
        "                        max_length=self.max_len,\n",
        "                        pad_to_max_length=True,\n",
        "                        truncation=True,\n",
        "                        return_tensors=None,\n",
        "                )\n",
        "        return {k: torch.tensor(v, dtype=torch.long) for k, v in tokenized.items()} # stack tensor\n",
        "    \n",
        "    # get longest max_len\n",
        "    # https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train/notebook\n",
        "    def _get_max_len(self):\n",
        "        lengths = []\n",
        "        for text in self.full_texts.fillna('').values:\n",
        "            length = len(self.tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "            lengths.append(length)\n",
        "        return max(lengths) + 2 # cls & sep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VssM1Pe5CTsL"
      },
      "source": [
        "\n",
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n-lIHkyCTsM"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/maunish/clrp-pytorch-roberta-finetune/notebook\n",
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, in_features, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.middle_features = hidden_dim\n",
        "        self.W = nn.Linear(in_features, hidden_dim)\n",
        "        self.V = nn.Linear(hidden_dim, 1)\n",
        "        self.out_features = hidden_dim\n",
        "\n",
        "    def forward(self, features):\n",
        "        att = torch.tanh(self.W(features))\n",
        "        score = self.V(att)\n",
        "        attention_weights = torch.softmax(score, dim=1)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "# https://www.kaggle.com/competitions/feedback-prize-english-language-learning/discussion/361678\n",
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(in_dim, in_dim),\n",
        "            nn.LayerNorm(in_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(in_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        w = self.attention(x).float()\n",
        "        w[mask==0]=float('-inf')\n",
        "        w = torch.softmax(w,1)\n",
        "        x = torch.sum(w * x, dim=1)\n",
        "        return x    \n",
        "    \n",
        "# https://www.kaggle.com/code/rhtsingh/utilizing-transformer-representations-efficiently\n",
        "class HiddenAttentionPooling(nn.Module):\n",
        "    def __init__(self, num_layers, hidden_size, hiddendim_fc):\n",
        "        super().__init__()\n",
        "        self.num_hidden_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hiddendim_fc = hiddendim_fc\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        q_t = torch.normal(mean=0.0, std=0.02, size=(1, self.hidden_size))\n",
        "        self.q = nn.Parameter(q_t).float()\n",
        "        w_ht = torch.normal(mean=0.0, std=0.02, size=(self.hidden_size, self.hiddendim_fc))\n",
        "        self.w_h = nn.Parameter(w_ht).float()\n",
        "\n",
        "    def forward(self, all_hidden_states):\n",
        "        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n",
        "                                     for layer_i in range(1, self.num_hidden_layers+1)], dim=-1)\n",
        "        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n",
        "        out = self.attention(hidden_states)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "    def attention(self, h):\n",
        "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
        "        v = F.softmax(v, -1)\n",
        "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
        "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
        "        return v\n",
        "\n",
        "class ConcatPooling(nn.Module):\n",
        "    def __init__(self, pooling_last=4):\n",
        "        super().__init__()\n",
        "        self.pooling_last = pooling_last\n",
        "        \n",
        "    def forward(self, all_hidden_states):\n",
        "        concat_pooling = torch.cat(tuple(all_hidden_states[-l] for l in range(1, self.pooling_last + 1)), -1)\n",
        "#         concat_pooling = concat_pooling.mean(dim=1) # average instead of select only one\n",
        "        concat_pooling = concat_pooling[:, 0] # select the first one\n",
        "        return concat_pooling\n",
        "\n",
        "# https://www.kaggle.com/competitions/google-quest-challenge/discussion/129840\n",
        "class WeightedLayerPooling(nn.Module):\n",
        "    def __init__(self, num_layers=12, init_std=0.02):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        weights_init = torch.zeros(self.num_layers).float()\n",
        "        weights_init.data[:-1] = -3\n",
        "        self.layer_weights = torch.nn.Parameter(weights_init)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, all_hidden_states):\n",
        "        all_layer_encoders = torch.stack(\n",
        "            [self.dropout(layer) for layer in all_hidden_states[-self.num_layers:]], dim=0\n",
        "        )\n",
        "        averaged_layers = (torch.softmax(self.layer_weights, dim=0).unsqueeze(1).unsqueeze(1).unsqueeze(1) * all_layer_encoders).sum(0)\n",
        "        return averaged_layers\n",
        "        \n",
        "class MeanPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def forward(self, last_hidden_state, attention_mask):\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        mean_embeddings = sum_embeddings / sum_mask\n",
        "        return mean_embeddings\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, conf, fold_num, config_path=None):\n",
        "        super().__init__()\n",
        "        if not config_path:\n",
        "            self.model_conf = AutoConfig.from_pretrained(conf.model_name, output_hidden_states=True)\n",
        "            self.model_conf = self._set_dropout(self.model_conf)\n",
        "            self.backbone = AutoModel.from_pretrained(conf.model_name, config=self.model_conf)\n",
        "        else:\n",
        "            self.model_conf = torch.load(config_path)\n",
        "            self.backbone = AutoModel.from_config(self.model_conf)\n",
        "        if conf.gradient_checkpointing:\n",
        "            self.backbone.gradient_checkpointing_enable()\n",
        "        \n",
        "        if not config_path:\n",
        "            for layer in self.backbone.encoder.layer[-conf.reinit_last_layers:]:\n",
        "                for module in layer.modules():\n",
        "                    self._init_weights(module)\n",
        "                    \n",
        "        self.pooling_strategy = conf.pooling_strategy_list[fold_num]\n",
        "        if self.pooling_strategy == 'mean_pooling':\n",
        "            self.pooler = MeanPooling()\n",
        "            \n",
        "        elif self.pooling_strategy == 'concat_pooling':\n",
        "            self.pooler = ConcatPooling(conf.concat_pooling_last)\n",
        "            \n",
        "        elif self.pooling_strategy == 'attn_pooling': \n",
        "            self.attn_pooler = AttentionPooling(self.model_conf.hidden_size) \n",
        "            for attn_module in self.attn_pooler.modules():\n",
        "                self._init_weights(attn_module)\n",
        "            \n",
        "        elif self.pooling_strategy == 'wlp_attn_pooling':\n",
        "            self.wlp_pooler = WeightedLayerPooling(self.model_conf.num_hidden_layers, self.model_conf.initializer_range)\n",
        "            self.attn_pooler = AttentionPooling(self.model_conf.hidden_size)\n",
        "            for attn_module in self.attn_pooler.modules():\n",
        "                self._init_weights(attn_module)\n",
        "                \n",
        "        elif self.pooling_strategy == 'concat_h_attn_mean_pooling':\n",
        "            self.hattn_pooler = HiddenAttentionPooling(self.model_conf.num_hidden_layers, self.model_conf.hidden_size, self.model_conf.hidden_size)\n",
        "            self.mean_pooler = MeanPooling()\n",
        "\n",
        "        elif self.pooling_strategy == 'concat_attn_mean_pooling':\n",
        "            self.attn_pooler = AttentionPooling(self.model_conf.hidden_size)\n",
        "            for attn_module in self.attn_pooler.modules():\n",
        "                self._init_weights(attn_module)\n",
        "            self.mean_pooler = MeanPooling()\n",
        "            \n",
        "        else:\n",
        "            raise Exception('Invalid pooling strategy')\n",
        "\n",
        "        if self.pooling_strategy in ['mean_pooling', 'attn_pooling', 'wlp_attn_pooling']:\n",
        "            hidden_size = self.model_conf.hidden_size\n",
        "        elif self.pooling_strategy in ['concat_pooling']:\n",
        "            hidden_size = self.model_conf.hidenn_size * conf.concat_pooling_last\n",
        "        elif self.pooling_strategy in ['concat_h_attn_mean_pooling', 'concat_attn_mean_pooling']:\n",
        "            hidden_size = self.model_conf.hidden_size * 2\n",
        "        else:\n",
        "            raise Exception('Cannot create fc layer.')\n",
        "            \n",
        "        self.multi_dropout = conf.multi_dropout\n",
        "        if self.multi_dropout:\n",
        "            self.dropout1 = nn.Dropout(conf.multi_dropout_p[0])\n",
        "            self.dropout2 = nn.Dropout(conf.multi_dropout_p[1])\n",
        "            self.dropout3 = nn.Dropout(conf.multi_dropout_p[2])\n",
        "            self.dropout4 = nn.Dropout(conf.multi_dropout_p[3])\n",
        "            self.dropout5 = nn.Dropout(conf.multi_dropout_p[4])\n",
        "        else:\n",
        "            self.dropout0 = nn.Dropout(0.1)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, conf.num_labels)\n",
        "        if conf.reinit_method is not None:\n",
        "            self._init_weights2_([self.fc], conf.reinit_method)\n",
        "        else:\n",
        "            self._init_weights(self.fc)\n",
        "\n",
        "        self.use_ln = conf.use_ln\n",
        "        if self.use_ln:\n",
        "            self.ln = nn.LayerNorm(hidden_size)\n",
        "            self._init_weights(self.ln)\n",
        "        \n",
        "    def _set_dropout(self, conf, ratio=0.):\n",
        "        conf.attention_probs_dropout_prob = ratio\n",
        "        conf.hidden_dropout = ratio \n",
        "        conf.hidden_dropout_prob = ratio\n",
        "        conf.pooler_dropout = ratio\n",
        "        return conf\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "    \n",
        "    def _init_weights2_(self, module_lst, method):\n",
        "        for module in module_lst:\n",
        "            for param in module.parameters():\n",
        "                if param.dim() > 1:\n",
        "                    if method == 'kaiming_normal':\n",
        "                        nn.init.kaiming_normal_(param)\n",
        "                    elif method == 'xavier_normal':\n",
        "                        nn.init.xavier_normal_(param)\n",
        "                    elif method == 'orthoganol':\n",
        "                        nn.init.orthogonal_(param)\n",
        "                    else:\n",
        "                        raise Exception('The method is invalid')\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        backbone_outputs = self.backbone(**inputs)\n",
        "        if self.pooling_strategy == 'mean_pooling':\n",
        "            last_hidden_states = backbone_outputs['last_hidden_state']\n",
        "            pooler_outputs = self.pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            \n",
        "        elif self.pooling_strategy == 'concat_pooling':\n",
        "            all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
        "            pooler_outputs = self.pooler(all_hidden_states)\n",
        "            \n",
        "        elif self.pooling_strategy == 'attn_pooling':\n",
        "            last_hidden_states = backbone_outputs['last_hidden_state']\n",
        "            pooler_outputs = self.attn_pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            \n",
        "        elif self.pooling_strategy == 'wlp_attn_pooling':\n",
        "            all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
        "            wlp_pooler = self.wlp_pooler(all_hidden_states)\n",
        "            pooler_outputs = self.attn_pooler(wlp_pooler, inputs['attention_mask'])\n",
        "            \n",
        "        elif self.pooling_strategy == 'concat_h_attn_mean_pooling':\n",
        "            last_hidden_states = backbone_outputs['last_hidden_state']\n",
        "            all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
        "            hattn_outputs = self.hattn_pooler(all_hidden_states)\n",
        "            mean_outputs = self.mean_pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            pooler_outputs = torch.cat((hattn_outputs, mean_outputs), -1)\n",
        "            \n",
        "        elif self.pooling_strategy == 'concat_attn_mean_pooling':\n",
        "            last_hidden_states = backbone_outputs['last_hidden_state']\n",
        "            attn_outputs = self.attn_pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            mean_outputs = self.mean_pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            pooler_outputs = torch.cat((attn_outputs, mean_outputs), -1)\n",
        "            \n",
        "        if self.use_ln:\n",
        "            pooler_outputs = self.ln(pooler_outputs)\n",
        "            \n",
        "        if self.multi_dropout:\n",
        "            x1 = self.fc(self.dropout1(pooler_outputs))\n",
        "            x2 = self.fc(self.dropout2(pooler_outputs))\n",
        "            x3 = self.fc(self.dropout3(pooler_outputs))\n",
        "            x4 = self.fc(self.dropout4(pooler_outputs))\n",
        "            x5 = self.fc(self.dropout5(pooler_outputs))\n",
        "            \n",
        "            outputs = (x1 + x2 + x3 + x4 + x5) / 5\n",
        "\n",
        "        else:\n",
        "            outputs = self.fc(self.dropout0(pooler_outputs))\n",
        "            \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh7RMJlKCTsO"
      },
      "source": [
        "## Adversial Learning Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZhqelQdCTsP"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/wht1996/feedback-nn-train/notebook\n",
        "class AWP:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        adv_param=\"weight\",\n",
        "        adv_lr=1,\n",
        "        adv_eps=0.2,\n",
        "        adv_step=1,\n",
        "        scaler=None,\n",
        "        apex=False,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.adv_param = adv_param\n",
        "        self.adv_lr = adv_lr\n",
        "        self.adv_eps = adv_eps\n",
        "        self.adv_step = adv_step\n",
        "        self.backup = {}\n",
        "        self.backup_eps = {}\n",
        "        self.scaler = scaler\n",
        "        self.apex = apex\n",
        "\n",
        "    def attack_backward(self, inputs, labels):\n",
        "        self._save() \n",
        "        for i in range(self.adv_step):\n",
        "            self._attack_step() \n",
        "            with torch.cuda.amp.autocast(enabled=self.apex):\n",
        "                adv_outputs = self.model(inputs)\n",
        "                adv_loss = self.criterion(adv_outputs, labels)\n",
        "                adv_loss = adv_loss.mean()\n",
        "            self.optimizer.zero_grad()\n",
        "            self.scaler.scale(adv_loss).backward()\n",
        "            \n",
        "        self._restore()\n",
        "\n",
        "    def _attack_step(self):\n",
        "        e = 1e-6\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
        "                norm1 = torch.norm(param.grad)\n",
        "                norm2 = torch.norm(param.data.detach())\n",
        "                if norm1 != 0 and not torch.isnan(norm1):\n",
        "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
        "                    param.data.add_(r_at)\n",
        "                    param.data = torch.min(\n",
        "                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n",
        "                    )\n",
        "                # param.data.clamp_(*self.backup_eps[name])\n",
        "\n",
        "    def _save(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
        "                if name not in self.backup:\n",
        "                    self.backup[name] = param.data.clone()\n",
        "                    grad_eps = self.adv_eps * param.abs().detach()\n",
        "                    self.backup_eps[name] = (\n",
        "                        self.backup[name] - grad_eps,\n",
        "                        self.backup[name] + grad_eps,\n",
        "                    )\n",
        "\n",
        "    def _restore(self,):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if name in self.backup:\n",
        "                param.data = self.backup[name]\n",
        "        self.backup = {}\n",
        "        self.backup_eps = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxcWd2FmCTsQ"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCFchPTMCTsQ"
      },
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.__name__ = self.__class__.__name__\n",
        "    \n",
        "    def forward(self, y_pred, y_true):\n",
        "        return torch.sqrt(self.mse(y_pred, y_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2KbG04pCTsR"
      },
      "source": [
        "# Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz8xhKVmCTsR"
      },
      "outputs": [],
      "source": [
        "# https://realpython.com/python-timer/\n",
        "class TimerError(Exception):\n",
        "    \"\"\"A custom exception used to report errors in use of Timer class\"\"\"\n",
        "\n",
        "class Timer:\n",
        "    def __init__(self):\n",
        "        self._start_time = None\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start a new timer\"\"\"\n",
        "        if self._start_time is not None:\n",
        "            raise TimerError(f\"Timer is running. Use .stop() to stop it\")\n",
        "\n",
        "        self._start_time = time.perf_counter()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer, and report the elapsed time\"\"\"\n",
        "        if self._start_time is None:\n",
        "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
        "            \n",
        "        self._start_time = None\n",
        "    \n",
        "    def get_time(self):\n",
        "        if self._start_time is None:\n",
        "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
        "            \n",
        "        return time.perf_counter() - self._start_time\n",
        "    \n",
        "    @staticmethod\n",
        "    def formatting(second):\n",
        "        return str(datetime.timedelta(seconds=round(second)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G8XxI0oCTsS"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train/notebook\n",
        "class Averager:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "        \n",
        "    def get_average(self):\n",
        "        return self.avg\n",
        "    \n",
        "    def get_value(self):\n",
        "        return self.val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE5LhwplCTsS"
      },
      "outputs": [],
      "source": [
        "class ModelWeightAverager:\n",
        "    def __init__(self, conf, fold):\n",
        "        self.conf = conf\n",
        "        self.fold = fold\n",
        "        self.state_dict_list = []\n",
        "    \n",
        "    def add_state_dict(self, state_dict):\n",
        "        self.state_dict_list.append(state_dict)\n",
        "        \n",
        "    def average_state_dict(self):\n",
        "        master_sd = CustomModel(self.conf, self.fold).state_dict()\n",
        "        for key in master_sd:\n",
        "            master_sd[key] = 0\n",
        "            for state_dict in self.state_dict_list:\n",
        "                master_sd[key] += state_dict[key]\n",
        "            master_sd[key] = master_sd[key] / len(self.state_dict_list)\n",
        "        \n",
        "        torch.save({\n",
        "            'model_state_dict': master_sd,\n",
        "        },\n",
        "            Path(self.conf.save_path, f'best-epoch-fold{self.fold}-swa.pt'))\n",
        "        \n",
        "        print(f'SAVED FOLD{self.fold}_M_SWA)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK7ft6GxCTsS"
      },
      "outputs": [],
      "source": [
        "# optimize padding size\n",
        "# https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train/notebook\n",
        "def collator(inputs):\n",
        "    mask_len = int(inputs['attention_mask'].sum(axis=1).max())\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = inputs[k][:, :mask_len]\n",
        "    return inputs\n",
        "\n",
        "def get_dataloader(conf, df, tokenizer, fold_num):\n",
        "    \n",
        "    train_dataset = FB3Dataset(conf, df[df['fold'] != fold_num], tokenizer, fold_num)\n",
        "    valid_dataset = FB3Dataset(conf, df[df['fold'] == fold_num], tokenizer, fold_num)\n",
        "    \n",
        "    total_train_samples = len(train_dataset)\n",
        "    \n",
        "#     data_collator = DataCollatorWithPadding(tokenizer, padding='longest', return_tensors=None)\n",
        "    \n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=conf.num_batch,\n",
        "#         collate_fn=data_collator,\n",
        "        num_workers=4,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    \n",
        "    valid_dataloader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=conf.num_batch,\n",
        "#         collate_fn=data_collator,\n",
        "        num_workers=4,\n",
        "        shuffle=False,\n",
        "        pin_memory=True,\n",
        "        drop_last=False\n",
        "    )\n",
        "    \n",
        "    return train_dataloader, valid_dataloader, total_train_samples\n",
        "\n",
        "def get_model(conf, fold_num):\n",
        "    model = CustomModel(conf, fold_num)\n",
        "    model_config_file = Path(conf.save_path, Path(conf.model_name).name + '_config.pt')\n",
        "    \n",
        "    # save model config file\n",
        "    if not model_config_file.is_file():\n",
        "        torch.save(model.model_conf, model_config_file)\n",
        "        \n",
        "    return model\n",
        "\n",
        "def get_tokenizer(conf):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(conf.model_name)\n",
        "    tokenizer_file = Path(conf.save_path, 'tokenizers/')\n",
        "    \n",
        "    if not tokenizer_file.is_file():\n",
        "        tokenizer.save_pretrained(tokenizer_file) # save tokenizer vocab\n",
        "        \n",
        "    return tokenizer\n",
        "\n",
        "def get_optimizer(conf):\n",
        "    optimizer_dict = {\n",
        "        'adamw': optim.AdamW,\n",
        "    }\n",
        "    return optimizer_dict[conf.optimizer]\n",
        "\n",
        "def get_optimizer_grouped_params(model, bb_lr, ll_lr, weight_decay=0.01, layerwise_learning_rate_decay=0.9):\n",
        "    # turn off weight decay in some layer\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if 'backbone' not in n],\n",
        "            \"weight_decay\": 0.0,\n",
        "            \"lr\": ll_lr,\n",
        "        },\n",
        "    ]\n",
        "    # layer-wise learning rate decay\n",
        "    layers = [model.backbone.embeddings] + list(model.backbone.encoder.layer)\n",
        "    layers.reverse()\n",
        "    decay_lr = bb_lr\n",
        "    for layer in layers:\n",
        "        decay_lr *= layerwise_learning_rate_decay\n",
        "        optimizer_grouped_parameters += [\n",
        "            {\n",
        "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": weight_decay,\n",
        "                \"lr\": decay_lr,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "                \"lr\": decay_lr,\n",
        "            },\n",
        "        ]\n",
        "    return optimizer_grouped_parameters\n",
        "\n",
        "def get_scheduler(conf, total_samples):\n",
        "    scheduler_dict = {\n",
        "        'cosine_warmup': {\n",
        "            'scheduler': transformers.get_cosine_schedule_with_warmup,\n",
        "            'params': {\n",
        "                'num_warmup_steps': int((total_samples // conf.num_batch) * conf.warmup_epoch),\n",
        "                'num_training_steps': (total_samples // conf.num_batch) * conf.num_epochs,\n",
        "            }\n",
        "        },\n",
        "        'linear_warmup': {\n",
        "            'scheduler': transformers.get_linear_schedule_with_warmup,\n",
        "            'params': {\n",
        "                'num_warmup_steps': int((total_samples // conf.num_batch) * conf.warmup_epoch),\n",
        "                'num_training_steps': (total_samples // conf.num_batch) * conf.num_epochs,\n",
        "            }\n",
        "        },\n",
        "        'cosine_restart_warmup': {\n",
        "            'scheduler': transformers.get_cosine_with_hard_restarts_schedule_with_warmup,\n",
        "            'params': {\n",
        "                'num_warmup_steps':  int((total_samples // conf.num_batch) * conf.warmup_epoch),\n",
        "                'num_training_steps': (total_samples // conf.num_batch) * conf.num_epochs,\n",
        "                'num_cycles': 2,\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "    \n",
        "    return scheduler_dict[conf.scheduler]['scheduler'], scheduler_dict[conf.scheduler]['params']\n",
        "\n",
        "def scores_with_MCRMSE(y_predicteds, y_targets):\n",
        "    cols_score = []\n",
        "    col_wise = y_targets.shape[1]\n",
        "    for col in range(col_wise):\n",
        "        y_predicted = torch.as_tensor(y_predicteds[:, col])\n",
        "        y_target = torch.as_tensor(y_targets[:, col])\n",
        "        rmse = mean_squared_error(y_predicted, y_target, squared=False) # returns RMSE value if set to False\n",
        "        cols_score.append(rmse)\n",
        "    score_mean = torch.mean(torch.as_tensor(cols_score))\n",
        "    return score_mean, cols_score\n",
        "\n",
        "def calculate_fold_mean(conf, df):\n",
        "    bsr_list = []\n",
        "    for i in range(conf.num_folds):\n",
        "        fold = df[df['fold'] == i]\n",
        "        best_score_row = fold.loc[fold['mcrmse'] == fold['mcrmse'].min()]\n",
        "        bsr_list.append(best_score_row)\n",
        "        \n",
        "    cv_df = pd.concat(bsr_list)\n",
        "    cv_mean = cv_df.mean(axis=0)\n",
        "    cv_mean['fold'] = cv_mean['epoch'] = int(99)\n",
        "    cv_mean = cv_mean.to_frame().T\n",
        "    cv_df = pd.concat([cv_df, cv_mean], axis=0)\n",
        "    return cv_df.reset_index(drop=True)\n",
        "\n",
        "def get_oof_df(target_cols, predictions, targets):\n",
        "    oof_df = pd.DataFrame()\n",
        "    oof_df[target_cols] = targets.cpu().numpy()\n",
        "    oof_df[[f'pred_{col}' for col in target_cols]] = predictions.cpu().numpy()\n",
        "    return oof_df\n",
        "\n",
        "def calculate_oof_cv(target_cols, oof_df):\n",
        "    predictions = oof_df[[f'pred_{col}' for col in target_cols]].values\n",
        "    targets = oof_df[target_cols].values\n",
        "    score_mean, cols_score = scores_with_MCRMSE(predictions, targets)\n",
        "    return score_mean, cols_score\n",
        "\n",
        "def export_config(basic, train):\n",
        "    config_dict = {**basic.__dict__, **train.__dict__}\n",
        "    remove_keys_list = ['__module__', '__dict__', '__weakref__', '__doc__']\n",
        "    \n",
        "    for key in remove_keys_list:\n",
        "        config_dict.pop(key)\n",
        "    \n",
        "    with open(Path(train.save_path, 'config.yml'), 'w') as file:\n",
        "        yaml.dump(config_dict, file)\n",
        "        \n",
        "def load_model(conf, device, fold_num, config_path, pretrained_model_path):\n",
        "    model = CustomModel(conf, fold_num, config_path=config_path)\n",
        "    state_dict = torch.load(pretrained_model_path, map_location=device)['model_state_dict']\n",
        "    model.load_state_dict(state_dict)\n",
        "    print(f'Loaded \"{pretrained_model_path}\"')\n",
        "    return model\n",
        "\n",
        "def get_model_path_dict(source, fold_num_list):\n",
        "    model_path_dict = {\n",
        "        'yaml': f'{source}/config.yml',\n",
        "        'config': [cf for cf in Path(source).glob('*_config.pt')][0].as_posix(),\n",
        "        'tokenizer': f'{source}/tokenizers/',\n",
        "        # 'models': [[f_n, f'{source}/best-epoch-fold{f_n}.pt'] for f_n in fold_num_list],\n",
        "        'models': {f_n: f'{source}/best-epoch-fold{f_n}.pt' for f_n in fold_num_list},\n",
        "        'tables': {\n",
        "            'train_result': f'{source}/train_result.csv',\n",
        "            'best_result': f'{source}/best_result.csv',\n",
        "            'cv_result': f'{source}/cv_result.csv',\n",
        "        },\n",
        "        'log': f'{source}/log.txt'\n",
        "    }\n",
        "    return model_path_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtEiCi7vCTsT"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0o5LnzKCTsU"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, conf, device, fold, model, optimizer, optimizer_grouped_params, scheduler, scheduler_params):\n",
        "        self.device = device\n",
        "        self.current_fold = fold\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer(optimizer_grouped_params, lr=conf.ll_lr, eps=conf.optim_eps)\n",
        "        self.scheduler = scheduler(self.optimizer, **scheduler_params)\n",
        "        \n",
        "        self.dry_run = conf.dry_run\n",
        "        self.exp = conf.exp\n",
        "\n",
        "        self.model_name = conf.model_name\n",
        "        self.target_cols = conf.target_cols\n",
        "        self.use_apex = conf.use_apex\n",
        "        self.use_awp = conf.use_awp\n",
        "        self.use_swa = conf.use_swa\n",
        "        self.multi_dropout = conf.multi_dropout\n",
        "        self.grad_clip = conf.grad_clip\n",
        "        self.grad_max_norm = conf.grad_max_norm\n",
        "        \n",
        "        self.num_batch = conf.num_batch\n",
        "        self.num_epochs = conf.num_epochs\n",
        "        self.current_epoch = None\n",
        "        self.batch_scheduler = conf.batch_scheduler\n",
        "        self.verbose_step = conf.verbose_step\n",
        "        self.accumulate_step = conf.accumulate_step\n",
        "\n",
        "        self.save_path = conf.save_path\n",
        "        \n",
        "        self.scaler = GradScaler(enabled=self.use_apex)\n",
        "        self.criterion = nn.SmoothL1Loss(beta=conf.loss_beta) # [RMSELoss, SmoothL1Loss]\n",
        "        \n",
        "        self.awp_start_epoch = conf.awp_start_epoch\n",
        "        if self.use_awp:\n",
        "            self.awp = AWP(\n",
        "                model=self.model,\n",
        "                criterion=self.criterion,\n",
        "                optimizer=self.optimizer,\n",
        "                adv_lr=conf.adv_lr,\n",
        "                adv_eps=conf.adv_eps,\n",
        "                scaler=self.scaler,\n",
        "                apex=self.use_apex,\n",
        "            )\n",
        "            \n",
        "        self.swa_start_step_ratio = conf.swa_start_step_ratio\n",
        "        if self.use_swa:\n",
        "            self.swa_model = AveragedModel(self.model)\n",
        "            self.swa_scheduler = SWALR(\n",
        "                self.optimizer,\n",
        "                swa_lr=conf.swa_lr,\n",
        "                anneal_strategy=conf.swa_anneal_strat,\n",
        "            )\n",
        "\n",
        "        self.best_train_loss = torch.tensor(10000) # placeholder\n",
        "        self.best_valid_loss = torch.tensor(10000) # placeholder\n",
        "        self.best_score = torch.tensor(10000) # placeholder\n",
        "        self.best_score_col = [torch.tensor(10000) for i in range(6)] # placeholder\n",
        "        \n",
        "        self.record_cols = [\n",
        "            'fold',\n",
        "            'epoch',\n",
        "            'train_loss',\n",
        "            'valid_loss',\n",
        "            'mcrmse',\n",
        "            'cohesion',\n",
        "            'syntax',\n",
        "            'vocabulary',\n",
        "            'phraseology',\n",
        "            'grammar',\n",
        "            'conventions',\n",
        "        ]\n",
        "        self.record_df = pd.DataFrame(columns=self.record_cols)\n",
        "        \n",
        "        if self.dry_run: \n",
        "            self.log('=============')\n",
        "            self.log('== DRY_RUN ==')\n",
        "            self.log('=============')\n",
        "            \n",
        "\n",
        "        mode = 'EXPERIMENTING_MODE' if self.exp else 'CV_MODE'\n",
        "        current_max_len = 'dynamic_padding' if conf.dynamic_max_len else conf.static_max_len_list[self.current_fold]\n",
        "        current_pooling_strategy = conf.pooling_strategy_list[self.current_fold]\n",
        "        \n",
        "        self.log(f'Date: {datetime.datetime.now(pytz.timezone(\"Asia/Ho_Chi_Minh\") )} (GMT+7)')\n",
        "        self.log(f'Mode: {mode}')\n",
        "        self.log(f'Train_on: {self.device}, (AMP: {self.use_apex}, GradScaler: {self.scaler.is_enabled()})')\n",
        "        self.log(f'Model: {self.model_name}')\n",
        "        self.log(f'Model_config: {self.model.model_conf}')\n",
        "        self.log(f'Pooling_strategy: {current_pooling_strategy}')\n",
        "        self.log(f'Initailzation: {conf.reinit_method}')\n",
        "        self.log(f'AWP: {self.use_awp} (adv_lr: {conf.adv_lr}, adv_eps: {conf.adv_eps}) at epoch {self.awp_start_epoch}')\n",
        "        self.log(f'SWA: {self.use_swa} (swa_lr: {conf.swa_lr}, anneal_strat: {conf.swa_anneal_strat}) at last {conf.swa_start_step_ratio}')\n",
        "        self.log(f'Multi_sample_dropout: {self.multi_dropout} (p: {conf.multi_dropout_p})')\n",
        "        self.log(f'Loss_fn: {str(self.criterion)}')\n",
        "        self.log(f'Optimizer: {optimizer.__name__}')\n",
        "        self.log(f'LR: (Backbone: {conf.bb_lr}, LowerLayer: {conf.ll_lr})')\n",
        "        self.log(f'LR_Scheduler: {scheduler.__name__} {scheduler_params}')\n",
        "        self.log(f'Grad_clip_norm: {self.grad_clip} (max_norm: {self.grad_max_norm})')\n",
        "        self.log(f'Number_of_batches: {self.num_batch} (Gradient_accumulate: {self.accumulate_step})')\n",
        "        self.log(f'max_len: {current_max_len}')\n",
        "        self.log('')\n",
        "        \n",
        "    def fit(self, train_loader, valid_loader):\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.current_epoch = epoch + 1\n",
        "            \n",
        "            timer = Timer()\n",
        "            timer.start()\n",
        "            \n",
        "            self.log('TRAIN_LOOP')\n",
        "            train_loss = self._train_fn(train_loader)\n",
        "            self.log('')\n",
        "            \n",
        "            self.log('VALID_LOOP')\n",
        "            valid_loss, score_mean, cols_score, valid_predictions, valid_targets = self._valid_fn(valid_loader)\n",
        "            self.log('')\n",
        "            \n",
        "            epoch_summary_dict = {\n",
        "                'EPOCH': [f'{self.current_epoch}/{self.num_epochs}'],\n",
        "                'TRAIN_LOSS': [f'{train_loss:.5f}'],\n",
        "                'VALID_LOSS': [f'{valid_loss:.5f}'],\n",
        "                'MCRMSE': [f'{score_mean:.5f}'],\n",
        "                'COLS': [' | '.join([f'{col:.3f}' for col in cols_score])],\n",
        "                'TIME': [Timer.formatting(timer.get_time())],\n",
        "            }\n",
        "            epoch_summary_table = tabulate(epoch_summary_dict, headers='keys', tablefmt=\"github\")\n",
        "            \n",
        "            \n",
        "            self.log('--------------------')\n",
        "            self.log(f'EPOCH: {self.current_epoch}/{self.num_epochs} SUMMARY')\n",
        "            self.log('--------------------')\n",
        "            self.log(epoch_summary_table)\n",
        "            self.log('')\n",
        "            \n",
        "            timer.stop()\n",
        "            \n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            self._compare_and_save(score_mean, cols_score, train_loss, valid_loss, valid_predictions, valid_targets)\n",
        "                \n",
        "            self.record([\n",
        "                self.current_fold,\n",
        "                self.current_epoch,\n",
        "                train_loss.detach().cpu().numpy(),\n",
        "                valid_loss.detach().cpu().numpy(),\n",
        "                score_mean.cpu().numpy(),\n",
        "                *[col.cpu().numpy() for col in cols_score],\n",
        "            ])\n",
        "            \n",
        "            if self.dry_run: break\n",
        "            # end of the loop\n",
        "        \n",
        "        if self.use_swa:\n",
        "            torch.optim.swa_utils.update_bn(train_loader, self.swa_model)\n",
        "\n",
        "        fold_summary_dict = {\n",
        "            'MCRMSE': [f'{self.best_score:.5f}'],\n",
        "            'cohesion': [f'{self.best_score_col[0]:.5f}'],\n",
        "            'syntax': [f'{self.best_score_col[1]:.5f}'],\n",
        "            'vocabulary': [f'{self.best_score_col[2]:.5f}'],\n",
        "            'phraseology': [f'{self.best_score_col[3]:.5f}'],\n",
        "            'grammar': [f'{self.best_score_col[4]:.5f}'],\n",
        "            'conventions': [f'{self.best_score_col[5]:.5f}'],\n",
        "        }\n",
        "        \n",
        "        fold_summary_table = tabulate(fold_summary_dict, headers='keys', tablefmt='simple_grid')\n",
        "        \n",
        "        self.log('')\n",
        "        self.log(('-' * 35) + f' FOLD {self.current_fold} RESULT ' + ('-' * 35))\n",
        "        self.log(fold_summary_table)\n",
        "        self.log('')\n",
        "        self.log(('#' * 35) + f' END OF FOlD {self.current_fold} ' + ('#' * 35))\n",
        "        self.log('')\n",
        "        self.log('')\n",
        "        \n",
        "        return self.record_df, self.oof_df\n",
        "        \n",
        "    def _train_fn(self, train_loader):\n",
        "        self.model.train()\n",
        "        total_loss = Averager()\n",
        "        current_lr = self.scheduler.get_lr()[0] # placeholder\n",
        "        timer = Timer()\n",
        "        timer.start()\n",
        "        if self.use_awp and self.awp_start_epoch <= self.current_epoch: self.log('AWP_ACTIVATED')\n",
        "        \n",
        "        for step, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            inputs = collator(inputs)\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "            labels = labels.to(self.device)\n",
        "            batchsize = len(labels)\n",
        "            \n",
        "            with autocast(enabled=self.use_apex):\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "            if self.accumulate_step > 1:\n",
        "                loss = loss / self.accumulate_step\n",
        "            total_loss.update(loss, batchsize)\n",
        "            \n",
        "            self.scaler.scale(loss).backward()\n",
        "            \n",
        "            if (step + 1) % self.accumulate_step == 0:\n",
        "                if self.use_awp and self.awp_start_epoch <= self.current_epoch:\n",
        "                    self.awp.attack_backward(inputs, labels)\n",
        "                \n",
        "                if self.use_swa:\n",
        "                    swa_start_step = int((self.num_epochs * len(train_loader)) * (1 - self.swa_start_step_ratio))\n",
        "                    current_training_step = int(((self.current_epoch - 1) * len(train_loader)) + step)\n",
        "                    if current_training_step == swa_start_step:\n",
        "                        self.log('SWA_ACTIVATED')\n",
        "                    if current_training_step >= swa_start_step:\n",
        "                        self.swa_model.update_parameters(self.model)\n",
        "                        self.swa_scheduler.step()\n",
        "                        current_lr = self.swa_scheduler.get_last_lr()[0]\n",
        "                    else:\n",
        "                        if self.batch_scheduler:\n",
        "                            self.scheduler.step()\n",
        "                            current_lr = self.scheduler.get_lr()[0]\n",
        "                            \n",
        "                if self.grad_clip:\n",
        "                    self.scaler.unscale_(self.optimizer)\n",
        "                    grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                        parameters=self.model.parameters(),\n",
        "                        max_norm=self.grad_max_norm,\n",
        "                    )\n",
        "\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                self.optimizer.zero_grad()\n",
        "            \n",
        "            if not self.use_swa:\n",
        "                if self.batch_scheduler:\n",
        "                    self.scheduler.step()\n",
        "                    current_lr = self.scheduler.get_lr()[0]\n",
        "            \n",
        "            if step % self.verbose_step == 0 or step == (len(train_loader) - 1):\n",
        "                self.log(\n",
        "                    f'[TRAIN F{self.current_fold}] ' + \\\n",
        "                    f'EPOCH: {self.current_epoch}/{self.num_epochs} | ' + \\\n",
        "                    f'STEP: {str(step).zfill(len(str(len(train_loader))))}/{len(train_loader)} | ' + \\\n",
        "                    f'LOSS: {total_loss.get_value():.5f} ({total_loss.get_average():.5f}) | ' + \\\n",
        "                    f'LR: {current_lr:.8f} | ' + \\\n",
        "                    f'TIME: {Timer.formatting(timer.get_time())} |'\n",
        "                )\n",
        "\n",
        "            if self.dry_run: break\n",
        "            # end of the loop\n",
        "            \n",
        "        timer.stop()\n",
        "\n",
        "        return total_loss.get_average()\n",
        "            \n",
        "    \n",
        "    def _valid_fn(self, valid_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = Averager()\n",
        "        timer = Timer()\n",
        "        timer.start()\n",
        "        outputs_list = [] # for stacking outputs\n",
        "        targets_list = [] # for stacking labels\n",
        "        \n",
        "        for step, (inputs, labels) in enumerate(valid_loader):\n",
        "            \n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "            labels = labels.to(self.device)\n",
        "            batchsize = len(labels)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                \n",
        "            total_loss.update(loss, batchsize)\n",
        "            outputs_list.append(outputs)\n",
        "            targets_list.append(labels)\n",
        "            \n",
        "            if step % self.verbose_step == 0 or step == (len(valid_loader) - 1):\n",
        "                self.log(\n",
        "                    f'[VALID F{self.current_fold}] ' + \\\n",
        "                    f'EPOCH: {self.current_epoch}/{self.num_epochs} | ' + \\\n",
        "                    f'STEP: {str(step).zfill(len(str(len(valid_loader))))}/{len(valid_loader)} | ' + \\\n",
        "                    f'LOSS: {total_loss.get_value():.5f} ({total_loss.get_average():.5f}) | ' + \\\n",
        "                    f'TIME: {Timer.formatting(timer.get_time())} |'\n",
        "                )\n",
        "\n",
        "            if self.dry_run: break\n",
        "            # end of the loop\n",
        "\n",
        "        predictions = torch.cat(outputs_list)\n",
        "        targets = torch.cat(targets_list)\n",
        "\n",
        "        score_mean, cols_score = scores_with_MCRMSE(predictions, targets)\n",
        "        \n",
        "        timer.stop()\n",
        "        \n",
        "        return total_loss.get_average(), score_mean, cols_score, predictions, targets\n",
        "    \n",
        "    def _compare_and_save(self, score, col_score, train_loss, valid_loss, valid_predictions, valid_targets):\n",
        "        if score < self.best_score:\n",
        "            self.best_score = score\n",
        "            self.best_score_col = col_score\n",
        "            self.best_train_loss = train_loss\n",
        "            self.best_valid_loss = valid_loss\n",
        "            \n",
        "            file_name = f'best-epoch-fold{self.current_fold}.pt'\n",
        "            self._save(self.save_path, file_name, last_checkpoint=False)\n",
        "            \n",
        "            self.oof_df = get_oof_df(self.target_cols, valid_predictions, valid_targets)\n",
        "        \n",
        "            self.log('')\n",
        "            self.log(f'[SAVED] EPOCH: {self.current_epoch} | MCRMSE: {self.best_score}')\n",
        "            self.log('')\n",
        "    \n",
        "    def _save(self, save_path, file_name, last_checkpoint=False):\n",
        "        self.model.eval()\n",
        "        if last_checkpoint:\n",
        "            torch.save({\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                'scaler': self.scaler.state_dict(),\n",
        "                'best_train_loss': self.best_train_loss,\n",
        "                'best_valid_loss': self.best_valid_loss,\n",
        "                'best_score': self.best_score,\n",
        "                'epoch': self.current_epoch,\n",
        "            }, Path(save_path, file_name))\n",
        "        else:\n",
        "            torch.save({\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'best_train_loss': self.best_train_loss,\n",
        "                'best_valid_loss': self.best_valid_loss,\n",
        "                'best_score': self.best_score,\n",
        "                'epoch': self.current_epoch,\n",
        "            }, Path(save_path, file_name))\n",
        "            \n",
        "    def log(self, message):\n",
        "        print(message)\n",
        "        if not self.dry_run:\n",
        "            with open(Path(self.save_path, 'log.txt'), mode='a+', encoding='utf-8') as log:\n",
        "                log.write(f'{message}\\n')\n",
        "\n",
        "    def record(self, record_row):\n",
        "        new_record_dict = {k: [v] for k, v in zip(self.record_cols, record_row)}\n",
        "        new_record = pd.DataFrame.from_dict(new_record_dict)\n",
        "        self.record_df = pd.concat([self.record_df, new_record], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vCG6PzFCTsV"
      },
      "outputs": [],
      "source": [
        "def run_training(train_df, conf, source, dry_run=True, exp=True):\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    \n",
        "    conf.dry_run = dry_run # for debugging\n",
        "    conf.exp = exp # for experimenting train only the first fold\n",
        "    \n",
        "    model_path_dict = get_model_path_dict(source, conf.train_fold_list)\n",
        "    \n",
        "    tokenizer = get_tokenizer(conf)\n",
        "    train_result_df = pd.DataFrame()\n",
        "    oof_df = pd.DataFrame()\n",
        "    \n",
        "    for fold in conf.train_fold_list:\n",
        "        \n",
        "        seed_everything(conf.seed)\n",
        "#         model = get_model(conf, fold)\n",
        "        model = load_model(conf, device, fold, model_path_dict['config'], model_path_dict['models'][fold])\n",
        "        model = model.to(device)\n",
        "        optimizer = get_optimizer(conf)\n",
        "        optimizer_grouped_params = get_optimizer_grouped_params(model, conf.bb_lr, conf.ll_lr, conf.weight_decay, conf.llrd)\n",
        "        train_loader, valid_loader, total_train_samples = get_dataloader(conf, train_df, tokenizer, fold)\n",
        "        scheduler, scheduler_params = get_scheduler(conf, total_train_samples)\n",
        "\n",
        "        trainer = Trainer(conf, device, fold, model, optimizer, optimizer_grouped_params, scheduler, scheduler_params)\n",
        "        fold_result, fold_oof_df = trainer.fit(train_loader, valid_loader)\n",
        "        train_result_df = pd.concat([train_result_df, fold_result], axis=0)\n",
        "        oof_df = pd.concat((oof_df, fold_oof_df), axis=0)\n",
        "        \n",
        "        if conf.dry_run or conf.exp : break\n",
        "    \n",
        "    cv_result_df = calculate_fold_mean(conf, train_result_df)\n",
        "    oof_score_mean, oof_cols_score = calculate_oof_cv(conf.target_cols, oof_df)\n",
        "    cv_df = pd.DataFrame([[oof_score_mean.numpy(), *[col.numpy() for col in oof_cols_score]]], columns=['mcrmse', *conf.target_cols])\n",
        "    \n",
        "    print('Overall Training Result')\n",
        "    display(train_result_df)\n",
        "    print('Best Result')\n",
        "    display(cv_result_df)\n",
        "    print('CV Result')\n",
        "    display(cv_df)\n",
        "    \n",
        "    train_result_df.reset_index(drop=True).to_csv(Path(conf.save_path, 'train_result.csv'), index=False)\n",
        "    cv_result_df.reset_index(drop=True).to_csv(Path(conf.save_path, 'best_result.csv'), index=False)\n",
        "    cv_df.reset_index(drop=True).to_csv(Path(conf.save_path, 'cv_result.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiG7Gy5WCTsW"
      },
      "outputs": [],
      "source": [
        "class TRAINCONF(BASICCONF):\n",
        "    \n",
        "    # general config\n",
        "    exp_num = '64s42'\n",
        "    save_path = f'/content/drive/MyDrive/Colab Notebooks/kaggle/fb3/results/exp{exp_num}'\n",
        "\n",
        "    # run config\n",
        "    dry_run = True # for debugging\n",
        "    exp = True # for experimenting\n",
        "    train_fold_list = [0, 1, 2, 3]\n",
        "    \n",
        "    # dataset config\n",
        "    dynamic_max_len = False\n",
        "    static_max_len_list = [768, 768, 768, 768] # if dynaimic_padding is False: then use static_max_len_list instead\n",
        "    # [1428, 1428, 1428, 1428] default max_len for 4 fold\n",
        "    \n",
        "    # model config\n",
        "    model_name = 'microsoft/deberta-v3-base' # [xsmall, small, base, large, xlarge]\n",
        "    reinit_last_layers = 1 # from the bottom (no need to set negative value).\n",
        "    reinit_method = None # [kaiming_normal, xavier_normal, orthoganol, None] # if None: initialize by  normal dist\n",
        "    gradient_checkpointing = True\n",
        "    \n",
        "    use_awp = True\n",
        "    awp_start_epoch = 1\n",
        "    adv_lr = 2e-5\n",
        "    adv_eps = 1e-3\n",
        "    \n",
        "    use_swa = False\n",
        "    swa_start_step_ratio = 0.112 #tart from last n% of the training step # 0.112(1300)\n",
        "    swa_lr = 1e-6\n",
        "    swa_anneal_strat = 'cos' # ['cos', 'linear']\n",
        "    \n",
        "    pooling_strategy_list = [\n",
        "        'concat_attn_mean_pooling',\n",
        "        'concat_attn_mean_pooling',\n",
        "        'concat_attn_mean_pooling',\n",
        "        'concat_attn_mean_pooling',\n",
        "    ]\n",
        "    \n",
        "    # [\n",
        "    #     mean_pooling,\n",
        "    #     concat_pooling,\n",
        "    #     attn_pooling,\n",
        "    #     wlp_attn_pooling,\n",
        "    #     concat_h_attn_mean_pooling,\n",
        "    #     concat_attn_mean_pooling,\n",
        "    # ]\n",
        "    \n",
        "    wlp_pooling_start = 0 # for weighted layer pooling (n from the top)\n",
        "    concat_pooling_last = 4 # for concatenate pooling (n from the bottom)\n",
        "    \n",
        "    use_ln = False\n",
        "\n",
        "    multi_dropout = True\n",
        "    multi_dropout_p = [0.3, 0.3, 0.3, 0.3, 0.3]\n",
        "    \n",
        "    # trainer config\n",
        "    use_apex = torch.cuda.is_available()\n",
        "    verbose_step = 40\n",
        "    num_epochs = 3\n",
        "    num_batch = 8\n",
        "    accumulate_step = 1\n",
        "    \n",
        "    # optimizer config\n",
        "    optimizer = 'adamw'\n",
        "    bb_lr = 2e-5 # backbone lr\n",
        "    ll_lr = 3e-5 # lowerlayer lr\n",
        "    \n",
        "    weight_decay = 0.01\n",
        "    llrd = 0.9\n",
        "    optim_eps = 1e-6\n",
        "    \n",
        "    batch_scheduler = True\n",
        "    scheduler = 'cosine_warmup' # [cosine_warmup, linear_warmup, consine_restart_warmup]\n",
        "    warmup_epoch = 0.25 # first n of the first epoch\n",
        "    \n",
        "    grad_clip = False\n",
        "    grad_max_norm = 10\n",
        "    \n",
        "    # loss_fn config\n",
        "    loss_beta = 1.0\n",
        "    \n",
        "    is_pl = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkT0XAf7Cmes"
      },
      "outputs": [],
      "source": [
        "def check_or_create(path):\n",
        "    path = Path(path)\n",
        "    if not path.is_dir():\n",
        "        path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK-AQOdNCTsX"
      },
      "source": [
        "# RUN TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "146dd0fccc6941419d8b2da19daa4323",
            "f3166ef42ad44814a7fc77f2d8af9925",
            "756e5e80e7254a58b939cbe23162dcfe",
            "53d93aed28f24007af782d512946dc2c",
            "5901e69c52bc448a89b44537a59855c8",
            "32b381f14f21439595c7975513def3fe",
            "51f00b0198734ffb88dd89acebc1e239",
            "f6b016bee7e1464ba7e6467415678fe5",
            "2b6f0812f0114363a883ee59ea9cd60b",
            "425fc451937e4a7785f056a68c3d37d6",
            "de50c56510054e2095d7e79e4953201a",
            "6f63e04aaad64c3cbd12ebd8f93810e5",
            "fd1721d6e54d4120ac1e58d183f0dbb4",
            "84505acd57554146b18a41733473e239",
            "646bb21da25a4629be6ca32508b1b5d9",
            "0e433393e1b7467da23501612c79d2b5",
            "daea69c40e5a4bfe8d23e4cd7975cde7",
            "97c1b9f4d9164b84847c4471f4fcbcc0",
            "9e10bd0aca0f40028a3b39c8d0c423bd",
            "d935460964a64bd6909775496858e236",
            "a83fbd0c508c481ba2ceea8d6cb2493d",
            "68e3c9e4b63048ef8c894fce5c24d10c",
            "05825a7c09434e1e9efb99e3adcbd2ba",
            "6e80cbd611ed4017a56398eddd75ee07",
            "8a17ea99b5a14080a7c7467c40892cc3",
            "091bd6031bd44b05a46afcbf63dd5d4b",
            "2dd332a2a63b47fd8fcd6a75b753b49e",
            "ee89c6b5839442e9b24ce990976cea1a",
            "6b4885a446d045efbe7160375d5387dc",
            "b825058509cf41ee935a58f8f817d1c8",
            "bf07f1e06901472bafb3be31c3bb4e85",
            "ac1824c0f11640e98d86152f3881cf85",
            "45c5a3292798419fbcaa41c7b85c15c4"
          ]
        },
        "id": "NmHrO3y1CTsX",
        "outputId": "3e857828-64de-4f32-c34b-ebccddba7468"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "146dd0fccc6941419d8b2da19daa4323"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f63e04aaad64c3cbd12ebd8f93810e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05825a7c09434e1e9efb99e3adcbd2ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded \"/content/drive/MyDrive/fb3/results/exp64s42pretrained/best-epoch-fold0.pt\"\n",
            "Date: 2022-11-29 11:38:16.427204+07:00 (GMT+7)\n",
            "Mode: CV_MODE\n",
            "Train_on: cuda, (AMP: True, GradScaler: True)\n",
            "Model: microsoft/deberta-v3-base\n",
            "Model_config: DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0.0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Pooling_strategy: concat_attn_mean_pooling\n",
            "Initailzation: None\n",
            "AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1\n",
            "SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112\n",
            "Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])\n",
            "Loss_fn: SmoothL1Loss()\n",
            "Optimizer: AdamW\n",
            "LR: (Backbone: 2e-05, LowerLayer: 3e-05)\n",
            "LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 91, 'num_training_steps': 1098}\n",
            "Grad_clip_norm: False (max_norm: 10)\n",
            "Number_of_batches: 8 (Gradient_accumulate: 1)\n",
            "max_len: 768\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 000/366 | LOSS: 0.11137 (0.11137) | LR: 0.00000033 | TIME: 0:00:03 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 040/366 | LOSS: 0.10605 (0.12073) | LR: 0.00001352 | TIME: 0:01:59 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 080/366 | LOSS: 0.15994 (0.12316) | LR: 0.00002670 | TIME: 0:03:47 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 120/366 | LOSS: 0.09330 (0.12336) | LR: 0.00002993 | TIME: 0:05:42 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 160/366 | LOSS: 0.12870 (0.12303) | LR: 0.00002964 | TIME: 0:07:33 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 200/366 | LOSS: 0.13690 (0.12325) | LR: 0.00002913 | TIME: 0:09:33 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 240/366 | LOSS: 0.13344 (0.12331) | LR: 0.00002839 | TIME: 0:11:20 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 280/366 | LOSS: 0.14934 (0.12249) | LR: 0.00002744 | TIME: 0:13:11 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 320/366 | LOSS: 0.14400 (0.12212) | LR: 0.00002630 | TIME: 0:15:03 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 360/366 | LOSS: 0.14469 (0.12299) | LR: 0.00002499 | TIME: 0:16:59 |\n",
            "[TRAIN F0] EPOCH: 1/3 | STEP: 365/366 | LOSS: 0.20954 (0.12332) | LR: 0.00002481 | TIME: 0:17:13 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F0] EPOCH: 1/3 | STEP: 000/123 | LOSS: 0.06754 (0.06754) | TIME: 0:00:01 |\n",
            "[VALID F0] EPOCH: 1/3 | STEP: 040/123 | LOSS: 0.07288 (0.10475) | TIME: 0:00:32 |\n",
            "[VALID F0] EPOCH: 1/3 | STEP: 080/123 | LOSS: 0.10590 (0.10671) | TIME: 0:01:02 |\n",
            "[VALID F0] EPOCH: 1/3 | STEP: 120/123 | LOSS: 0.13508 (0.10913) | TIME: 0:01:32 |\n",
            "[VALID F0] EPOCH: 1/3 | STEP: 122/123 | LOSS: 0.13053 (0.10905) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 1/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 1/3     |      0.12332 |      0.10905 |  0.46724 | 0.509 | 0.465 | 0.420 | 0.464 | 0.495 | 0.451 | 0:18:46 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 1 | MCRMSE: 0.4672437608242035\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 000/366 | LOSS: 0.08192 (0.08192) | LR: 0.00002477 | TIME: 0:00:04 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 040/366 | LOSS: 0.09472 (0.10706) | LR: 0.00002328 | TIME: 0:01:52 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 080/366 | LOSS: 0.04493 (0.10518) | LR: 0.00002166 | TIME: 0:03:43 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 120/366 | LOSS: 0.09281 (0.10741) | LR: 0.00001994 | TIME: 0:05:35 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 160/366 | LOSS: 0.09817 (0.10838) | LR: 0.00001814 | TIME: 0:07:34 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 200/366 | LOSS: 0.10937 (0.10768) | LR: 0.00001629 | TIME: 0:09:27 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 240/366 | LOSS: 0.11922 (0.10746) | LR: 0.00001442 | TIME: 0:11:25 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 280/366 | LOSS: 0.10978 (0.10713) | LR: 0.00001255 | TIME: 0:13:18 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 320/366 | LOSS: 0.11796 (0.10682) | LR: 0.00001073 | TIME: 0:15:09 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 360/366 | LOSS: 0.13291 (0.10750) | LR: 0.00000897 | TIME: 0:17:03 |\n",
            "[TRAIN F0] EPOCH: 2/3 | STEP: 365/366 | LOSS: 0.14114 (0.10763) | LR: 0.00000876 | TIME: 0:17:17 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F0] EPOCH: 2/3 | STEP: 000/123 | LOSS: 0.05025 (0.05025) | TIME: 0:00:01 |\n",
            "[VALID F0] EPOCH: 2/3 | STEP: 040/123 | LOSS: 0.07228 (0.09671) | TIME: 0:00:32 |\n",
            "[VALID F0] EPOCH: 2/3 | STEP: 080/123 | LOSS: 0.09580 (0.09853) | TIME: 0:01:02 |\n",
            "[VALID F0] EPOCH: 2/3 | STEP: 120/123 | LOSS: 0.10687 (0.10070) | TIME: 0:01:32 |\n",
            "[VALID F0] EPOCH: 2/3 | STEP: 122/123 | LOSS: 0.11441 (0.10052) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 2/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 2/3     |      0.10763 |      0.10052 |  0.44865 | 0.484 | 0.444 | 0.411 | 0.452 | 0.466 | 0.436 | 0:18:51 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 2 | MCRMSE: 0.44865044951438904\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 000/366 | LOSS: 0.15675 (0.15675) | LR: 0.00000872 | TIME: 0:00:04 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 040/366 | LOSS: 0.09801 (0.09652) | LR: 0.00000707 | TIME: 0:01:55 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 080/366 | LOSS: 0.08466 (0.09856) | LR: 0.00000555 | TIME: 0:03:43 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 120/366 | LOSS: 0.06539 (0.09933) | LR: 0.00000417 | TIME: 0:05:36 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 160/366 | LOSS: 0.11331 (0.10006) | LR: 0.00000296 | TIME: 0:07:30 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 200/366 | LOSS: 0.05752 (0.09859) | LR: 0.00000194 | TIME: 0:09:22 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 240/366 | LOSS: 0.11405 (0.09793) | LR: 0.00000113 | TIME: 0:11:15 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 280/366 | LOSS: 0.08242 (0.09607) | LR: 0.00000052 | TIME: 0:13:01 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 320/366 | LOSS: 0.06561 (0.09518) | LR: 0.00000015 | TIME: 0:14:56 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 360/366 | LOSS: 0.14352 (0.09494) | LR: 0.00000000 | TIME: 0:16:48 |\n",
            "[TRAIN F0] EPOCH: 3/3 | STEP: 365/366 | LOSS: 0.12005 (0.09508) | LR: 0.00000000 | TIME: 0:17:02 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F0] EPOCH: 3/3 | STEP: 000/123 | LOSS: 0.05359 (0.05359) | TIME: 0:00:01 |\n",
            "[VALID F0] EPOCH: 3/3 | STEP: 040/123 | LOSS: 0.07566 (0.09696) | TIME: 0:00:31 |\n",
            "[VALID F0] EPOCH: 3/3 | STEP: 080/123 | LOSS: 0.09316 (0.09798) | TIME: 0:01:01 |\n",
            "[VALID F0] EPOCH: 3/3 | STEP: 120/123 | LOSS: 0.10338 (0.10007) | TIME: 0:01:32 |\n",
            "[VALID F0] EPOCH: 3/3 | STEP: 122/123 | LOSS: 0.10990 (0.09985) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 3/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 3/3     |      0.09508 |      0.09985 |  0.44719 | 0.478 | 0.443 | 0.411 | 0.450 | 0.466 | 0.436 | 0:18:35 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 3 | MCRMSE: 0.44719335436820984\n",
            "\n",
            "\n",
            "----------------------------------- FOLD 0 RESULT -----------------------------------\n",
            "  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions\n",
            "--------  ----------  --------  ------------  -------------  ---------  -------------\n",
            " 0.44719      0.4778   0.44276       0.41093        0.44973    0.46611        0.43584\n",
            "\n",
            "################################### END OF FOlD 0 ###################################\n",
            "\n",
            "\n",
            "Loaded \"/content/drive/MyDrive/fb3/results/exp64s42pretrained/best-epoch-fold1.pt\"\n",
            "Date: 2022-11-29 12:34:52.674115+07:00 (GMT+7)\n",
            "Mode: CV_MODE\n",
            "Train_on: cuda, (AMP: True, GradScaler: True)\n",
            "Model: microsoft/deberta-v3-base\n",
            "Model_config: DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0.0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Pooling_strategy: concat_attn_mean_pooling\n",
            "Initailzation: None\n",
            "AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1\n",
            "SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112\n",
            "Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])\n",
            "Loss_fn: SmoothL1Loss()\n",
            "Optimizer: AdamW\n",
            "LR: (Backbone: 2e-05, LowerLayer: 3e-05)\n",
            "LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 91, 'num_training_steps': 1098}\n",
            "Grad_clip_norm: False (max_norm: 10)\n",
            "Number_of_batches: 8 (Gradient_accumulate: 1)\n",
            "max_len: 768\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 000/366 | LOSS: 0.07914 (0.07914) | LR: 0.00000033 | TIME: 0:00:03 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 040/366 | LOSS: 0.13301 (0.12557) | LR: 0.00001352 | TIME: 0:01:55 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 080/366 | LOSS: 0.09093 (0.12610) | LR: 0.00002670 | TIME: 0:03:44 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 120/366 | LOSS: 0.11420 (0.12809) | LR: 0.00002993 | TIME: 0:05:41 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 160/366 | LOSS: 0.08535 (0.12623) | LR: 0.00002964 | TIME: 0:07:32 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 200/366 | LOSS: 0.15904 (0.12666) | LR: 0.00002913 | TIME: 0:09:25 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 240/366 | LOSS: 0.13501 (0.12644) | LR: 0.00002839 | TIME: 0:11:19 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 280/366 | LOSS: 0.09117 (0.12522) | LR: 0.00002744 | TIME: 0:13:13 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 320/366 | LOSS: 0.15789 (0.12373) | LR: 0.00002630 | TIME: 0:15:06 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 360/366 | LOSS: 0.09199 (0.12292) | LR: 0.00002499 | TIME: 0:16:55 |\n",
            "[TRAIN F1] EPOCH: 1/3 | STEP: 365/366 | LOSS: 0.12656 (0.12262) | LR: 0.00002481 | TIME: 0:17:09 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F1] EPOCH: 1/3 | STEP: 000/123 | LOSS: 0.06322 (0.06322) | TIME: 0:00:01 |\n",
            "[VALID F1] EPOCH: 1/3 | STEP: 040/123 | LOSS: 0.09504 (0.12125) | TIME: 0:00:32 |\n",
            "[VALID F1] EPOCH: 1/3 | STEP: 080/123 | LOSS: 0.11444 (0.11718) | TIME: 0:01:02 |\n",
            "[VALID F1] EPOCH: 1/3 | STEP: 120/123 | LOSS: 0.09816 (0.11352) | TIME: 0:01:32 |\n",
            "[VALID F1] EPOCH: 1/3 | STEP: 122/123 | LOSS: 0.06581 (0.11329) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 1/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 1/3     |      0.12262 |      0.11329 |  0.47717 | 0.509 | 0.467 | 0.439 | 0.462 | 0.479 | 0.506 | 0:18:43 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 1 | MCRMSE: 0.47716501355171204\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 000/366 | LOSS: 0.10036 (0.10036) | LR: 0.00002477 | TIME: 0:00:03 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 040/366 | LOSS: 0.08096 (0.10947) | LR: 0.00002328 | TIME: 0:01:57 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 080/366 | LOSS: 0.08755 (0.10835) | LR: 0.00002166 | TIME: 0:03:45 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 120/366 | LOSS: 0.11681 (0.11112) | LR: 0.00001994 | TIME: 0:05:40 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 160/366 | LOSS: 0.09555 (0.11210) | LR: 0.00001814 | TIME: 0:07:35 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 200/366 | LOSS: 0.09954 (0.11080) | LR: 0.00001629 | TIME: 0:09:27 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 240/366 | LOSS: 0.09041 (0.10916) | LR: 0.00001442 | TIME: 0:11:17 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 280/366 | LOSS: 0.11291 (0.10771) | LR: 0.00001255 | TIME: 0:13:11 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 320/366 | LOSS: 0.09140 (0.10864) | LR: 0.00001073 | TIME: 0:15:09 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 360/366 | LOSS: 0.12232 (0.10813) | LR: 0.00000897 | TIME: 0:17:05 |\n",
            "[TRAIN F1] EPOCH: 2/3 | STEP: 365/366 | LOSS: 0.15479 (0.10840) | LR: 0.00000876 | TIME: 0:17:20 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F1] EPOCH: 2/3 | STEP: 000/123 | LOSS: 0.08339 (0.08339) | TIME: 0:00:01 |\n",
            "[VALID F1] EPOCH: 2/3 | STEP: 040/123 | LOSS: 0.07619 (0.10868) | TIME: 0:00:32 |\n",
            "[VALID F1] EPOCH: 2/3 | STEP: 080/123 | LOSS: 0.09082 (0.10652) | TIME: 0:01:02 |\n",
            "[VALID F1] EPOCH: 2/3 | STEP: 120/123 | LOSS: 0.08719 (0.10553) | TIME: 0:01:32 |\n",
            "[VALID F1] EPOCH: 2/3 | STEP: 122/123 | LOSS: 0.04693 (0.10540) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 2/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 2/3     |       0.1084 |       0.1054 |  0.45984 | 0.504 | 0.444 | 0.420 | 0.454 | 0.474 | 0.462 | 0:18:53 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 2 | MCRMSE: 0.459837943315506\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 000/366 | LOSS: 0.09696 (0.09696) | LR: 0.00000872 | TIME: 0:00:04 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 040/366 | LOSS: 0.06197 (0.09370) | LR: 0.00000707 | TIME: 0:01:55 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 080/366 | LOSS: 0.10773 (0.09410) | LR: 0.00000555 | TIME: 0:03:47 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 120/366 | LOSS: 0.16902 (0.09464) | LR: 0.00000417 | TIME: 0:05:42 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 160/366 | LOSS: 0.10258 (0.09659) | LR: 0.00000296 | TIME: 0:07:32 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 200/366 | LOSS: 0.12349 (0.09631) | LR: 0.00000194 | TIME: 0:09:25 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 240/366 | LOSS: 0.11125 (0.09580) | LR: 0.00000113 | TIME: 0:11:21 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 280/366 | LOSS: 0.07248 (0.09545) | LR: 0.00000052 | TIME: 0:13:09 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 320/366 | LOSS: 0.10796 (0.09609) | LR: 0.00000015 | TIME: 0:15:02 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 360/366 | LOSS: 0.10042 (0.09564) | LR: 0.00000000 | TIME: 0:16:57 |\n",
            "[TRAIN F1] EPOCH: 3/3 | STEP: 365/366 | LOSS: 0.07728 (0.09571) | LR: 0.00000000 | TIME: 0:17:11 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F1] EPOCH: 3/3 | STEP: 000/123 | LOSS: 0.08083 (0.08083) | TIME: 0:00:01 |\n",
            "[VALID F1] EPOCH: 3/3 | STEP: 040/123 | LOSS: 0.07772 (0.10653) | TIME: 0:00:32 |\n",
            "[VALID F1] EPOCH: 3/3 | STEP: 080/123 | LOSS: 0.09343 (0.10440) | TIME: 0:01:02 |\n",
            "[VALID F1] EPOCH: 3/3 | STEP: 120/123 | LOSS: 0.08836 (0.10349) | TIME: 0:01:32 |\n",
            "[VALID F1] EPOCH: 3/3 | STEP: 122/123 | LOSS: 0.05285 (0.10335) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 3/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 3/3     |      0.09571 |      0.10335 |  0.45529 | 0.492 | 0.445 | 0.419 | 0.452 | 0.471 | 0.454 | 0:18:45 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 3 | MCRMSE: 0.45528730750083923\n",
            "\n",
            "\n",
            "----------------------------------- FOLD 1 RESULT -----------------------------------\n",
            "  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions\n",
            "--------  ----------  --------  ------------  -------------  ---------  -------------\n",
            " 0.45529     0.49193   0.44475       0.41901        0.45177    0.47073        0.45354\n",
            "\n",
            "################################### END OF FOlD 1 ###################################\n",
            "\n",
            "\n",
            "Loaded \"/content/drive/MyDrive/fb3/results/exp64s42pretrained/best-epoch-fold2.pt\"\n",
            "Date: 2022-11-29 13:31:35.114767+07:00 (GMT+7)\n",
            "Mode: CV_MODE\n",
            "Train_on: cuda, (AMP: True, GradScaler: True)\n",
            "Model: microsoft/deberta-v3-base\n",
            "Model_config: DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0.0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Pooling_strategy: concat_attn_mean_pooling\n",
            "Initailzation: None\n",
            "AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1\n",
            "SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112\n",
            "Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])\n",
            "Loss_fn: SmoothL1Loss()\n",
            "Optimizer: AdamW\n",
            "LR: (Backbone: 2e-05, LowerLayer: 3e-05)\n",
            "LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 91, 'num_training_steps': 1098}\n",
            "Grad_clip_norm: False (max_norm: 10)\n",
            "Number_of_batches: 8 (Gradient_accumulate: 1)\n",
            "max_len: 768\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 000/366 | LOSS: 0.11030 (0.11030) | LR: 0.00000033 | TIME: 0:00:04 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 040/366 | LOSS: 0.10774 (0.12418) | LR: 0.00001352 | TIME: 0:02:01 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 080/366 | LOSS: 0.12585 (0.12420) | LR: 0.00002670 | TIME: 0:03:53 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 120/366 | LOSS: 0.10768 (0.12284) | LR: 0.00002993 | TIME: 0:05:55 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 160/366 | LOSS: 0.11503 (0.12500) | LR: 0.00002964 | TIME: 0:07:46 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 200/366 | LOSS: 0.11131 (0.12529) | LR: 0.00002913 | TIME: 0:09:40 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 240/366 | LOSS: 0.09894 (0.12428) | LR: 0.00002839 | TIME: 0:11:36 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 280/366 | LOSS: 0.15011 (0.12261) | LR: 0.00002744 | TIME: 0:13:28 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 320/366 | LOSS: 0.14454 (0.12170) | LR: 0.00002630 | TIME: 0:15:25 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 360/366 | LOSS: 0.17283 (0.12340) | LR: 0.00002499 | TIME: 0:17:16 |\n",
            "[TRAIN F2] EPOCH: 1/3 | STEP: 365/366 | LOSS: 0.28364 (0.12387) | LR: 0.00002481 | TIME: 0:17:31 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F2] EPOCH: 1/3 | STEP: 000/123 | LOSS: 0.17096 (0.17096) | TIME: 0:00:01 |\n",
            "[VALID F2] EPOCH: 1/3 | STEP: 040/123 | LOSS: 0.15065 (0.13477) | TIME: 0:00:31 |\n",
            "[VALID F2] EPOCH: 1/3 | STEP: 080/123 | LOSS: 0.12906 (0.13780) | TIME: 0:01:01 |\n",
            "[VALID F2] EPOCH: 1/3 | STEP: 120/123 | LOSS: 0.13824 (0.13816) | TIME: 0:01:32 |\n",
            "[VALID F2] EPOCH: 1/3 | STEP: 122/123 | LOSS: 0.30018 (0.13809) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 1/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 1/3     |      0.12387 |      0.13809 |  0.52813 | 0.551 | 0.550 | 0.467 | 0.539 | 0.499 | 0.564 | 0:19:04 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 1 | MCRMSE: 0.5281289219856262\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 000/366 | LOSS: 0.15883 (0.15883) | LR: 0.00002477 | TIME: 0:00:04 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 040/366 | LOSS: 0.16831 (0.11346) | LR: 0.00002328 | TIME: 0:02:00 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 080/366 | LOSS: 0.07672 (0.11276) | LR: 0.00002166 | TIME: 0:03:50 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 120/366 | LOSS: 0.07066 (0.11159) | LR: 0.00001994 | TIME: 0:05:48 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 160/366 | LOSS: 0.09700 (0.11040) | LR: 0.00001814 | TIME: 0:07:43 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 200/366 | LOSS: 0.11714 (0.10929) | LR: 0.00001629 | TIME: 0:09:32 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 240/366 | LOSS: 0.08483 (0.10925) | LR: 0.00001442 | TIME: 0:11:22 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 280/366 | LOSS: 0.12100 (0.10845) | LR: 0.00001255 | TIME: 0:13:16 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 320/366 | LOSS: 0.07579 (0.10789) | LR: 0.00001073 | TIME: 0:15:14 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 360/366 | LOSS: 0.09905 (0.10692) | LR: 0.00000897 | TIME: 0:17:09 |\n",
            "[TRAIN F2] EPOCH: 2/3 | STEP: 365/366 | LOSS: 0.11466 (0.10671) | LR: 0.00000876 | TIME: 0:17:23 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F2] EPOCH: 2/3 | STEP: 000/123 | LOSS: 0.13548 (0.13548) | TIME: 0:00:01 |\n",
            "[VALID F2] EPOCH: 2/3 | STEP: 040/123 | LOSS: 0.07930 (0.10484) | TIME: 0:00:31 |\n",
            "[VALID F2] EPOCH: 2/3 | STEP: 080/123 | LOSS: 0.09060 (0.10452) | TIME: 0:01:01 |\n",
            "[VALID F2] EPOCH: 2/3 | STEP: 120/123 | LOSS: 0.10855 (0.10550) | TIME: 0:01:32 |\n",
            "[VALID F2] EPOCH: 2/3 | STEP: 122/123 | LOSS: 0.12787 (0.10528) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 2/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 2/3     |      0.10671 |      0.10528 |  0.46025 | 0.486 | 0.452 | 0.427 | 0.468 | 0.473 | 0.455 | 0:18:56 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 2 | MCRMSE: 0.46024754643440247\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 000/366 | LOSS: 0.11722 (0.11722) | LR: 0.00000872 | TIME: 0:00:02 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 040/366 | LOSS: 0.11292 (0.09731) | LR: 0.00000707 | TIME: 0:01:57 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 080/366 | LOSS: 0.08000 (0.09392) | LR: 0.00000555 | TIME: 0:03:52 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 120/366 | LOSS: 0.07729 (0.09302) | LR: 0.00000417 | TIME: 0:05:50 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 160/366 | LOSS: 0.12444 (0.09395) | LR: 0.00000296 | TIME: 0:07:43 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 200/366 | LOSS: 0.09400 (0.09380) | LR: 0.00000194 | TIME: 0:09:33 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 240/366 | LOSS: 0.10176 (0.09432) | LR: 0.00000113 | TIME: 0:11:23 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 280/366 | LOSS: 0.04820 (0.09364) | LR: 0.00000052 | TIME: 0:13:20 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 320/366 | LOSS: 0.08979 (0.09370) | LR: 0.00000015 | TIME: 0:15:15 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 360/366 | LOSS: 0.06183 (0.09298) | LR: 0.00000000 | TIME: 0:17:04 |\n",
            "[TRAIN F2] EPOCH: 3/3 | STEP: 365/366 | LOSS: 0.08437 (0.09283) | LR: 0.00000000 | TIME: 0:17:20 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F2] EPOCH: 3/3 | STEP: 000/123 | LOSS: 0.13344 (0.13344) | TIME: 0:00:01 |\n",
            "[VALID F2] EPOCH: 3/3 | STEP: 040/123 | LOSS: 0.07948 (0.10360) | TIME: 0:00:31 |\n",
            "[VALID F2] EPOCH: 3/3 | STEP: 080/123 | LOSS: 0.09504 (0.10343) | TIME: 0:01:01 |\n",
            "[VALID F2] EPOCH: 3/3 | STEP: 120/123 | LOSS: 0.10747 (0.10472) | TIME: 0:01:32 |\n",
            "[VALID F2] EPOCH: 3/3 | STEP: 122/123 | LOSS: 0.12514 (0.10447) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 3/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 3/3     |      0.09283 |      0.10447 |  0.45823 | 0.484 | 0.451 | 0.415 | 0.467 | 0.475 | 0.457 | 0:18:53 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 3 | MCRMSE: 0.4582250416278839\n",
            "\n",
            "\n",
            "----------------------------------- FOLD 2 RESULT -----------------------------------\n",
            "  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions\n",
            "--------  ----------  --------  ------------  -------------  ---------  -------------\n",
            " 0.45823     0.48443   0.45146       0.41533        0.46652     0.4751        0.45652\n",
            "\n",
            "################################### END OF FOlD 2 ###################################\n",
            "\n",
            "\n",
            "Loaded \"/content/drive/MyDrive/fb3/results/exp64s42pretrained/best-epoch-fold3.pt\"\n",
            "Date: 2022-11-29 14:28:50.714041+07:00 (GMT+7)\n",
            "Mode: CV_MODE\n",
            "Train_on: cuda, (AMP: True, GradScaler: True)\n",
            "Model: microsoft/deberta-v3-base\n",
            "Model_config: DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0.0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Pooling_strategy: concat_attn_mean_pooling\n",
            "Initailzation: None\n",
            "AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1\n",
            "SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112\n",
            "Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])\n",
            "Loss_fn: SmoothL1Loss()\n",
            "Optimizer: AdamW\n",
            "LR: (Backbone: 2e-05, LowerLayer: 3e-05)\n",
            "LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 91, 'num_training_steps': 1098}\n",
            "Grad_clip_norm: False (max_norm: 10)\n",
            "Number_of_batches: 8 (Gradient_accumulate: 1)\n",
            "max_len: 768\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 000/366 | LOSS: 0.11726 (0.11726) | LR: 0.00000033 | TIME: 0:00:04 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 040/366 | LOSS: 0.07805 (0.11707) | LR: 0.00001352 | TIME: 0:01:57 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 080/366 | LOSS: 0.08787 (0.12848) | LR: 0.00002670 | TIME: 0:03:49 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 120/366 | LOSS: 0.19191 (0.12724) | LR: 0.00002993 | TIME: 0:05:43 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 160/366 | LOSS: 0.11830 (0.12493) | LR: 0.00002964 | TIME: 0:07:38 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 200/366 | LOSS: 0.12470 (0.12670) | LR: 0.00002913 | TIME: 0:09:27 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 240/366 | LOSS: 0.13910 (0.12571) | LR: 0.00002839 | TIME: 0:11:22 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 280/366 | LOSS: 0.13585 (0.12560) | LR: 0.00002744 | TIME: 0:13:15 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 320/366 | LOSS: 0.14637 (0.12529) | LR: 0.00002630 | TIME: 0:15:10 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 360/366 | LOSS: 0.05680 (0.12446) | LR: 0.00002499 | TIME: 0:17:04 |\n",
            "[TRAIN F3] EPOCH: 1/3 | STEP: 365/366 | LOSS: 0.10304 (0.12423) | LR: 0.00002481 | TIME: 0:17:18 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F3] EPOCH: 1/3 | STEP: 000/123 | LOSS: 0.11672 (0.11672) | TIME: 0:00:01 |\n",
            "[VALID F3] EPOCH: 1/3 | STEP: 040/123 | LOSS: 0.09880 (0.10374) | TIME: 0:00:32 |\n",
            "[VALID F3] EPOCH: 1/3 | STEP: 080/123 | LOSS: 0.12234 (0.10711) | TIME: 0:01:02 |\n",
            "[VALID F3] EPOCH: 1/3 | STEP: 120/123 | LOSS: 0.09389 (0.10860) | TIME: 0:01:32 |\n",
            "[VALID F3] EPOCH: 1/3 | STEP: 122/123 | LOSS: 0.06181 (0.10835) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 1/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 1/3     |      0.12423 |      0.10835 |  0.46654 | 0.498 | 0.448 | 0.472 | 0.444 | 0.486 | 0.451 | 0:18:52 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 1 | MCRMSE: 0.46653950214385986\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 000/366 | LOSS: 0.07290 (0.07290) | LR: 0.00002477 | TIME: 0:00:03 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 040/366 | LOSS: 0.07936 (0.10123) | LR: 0.00002328 | TIME: 0:01:47 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 080/366 | LOSS: 0.12977 (0.10863) | LR: 0.00002166 | TIME: 0:03:43 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 120/366 | LOSS: 0.16165 (0.10859) | LR: 0.00001994 | TIME: 0:05:36 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 160/366 | LOSS: 0.10225 (0.11025) | LR: 0.00001814 | TIME: 0:07:26 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 200/366 | LOSS: 0.12558 (0.11093) | LR: 0.00001629 | TIME: 0:09:23 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 240/366 | LOSS: 0.11601 (0.11065) | LR: 0.00001442 | TIME: 0:11:17 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 280/366 | LOSS: 0.08069 (0.11092) | LR: 0.00001255 | TIME: 0:13:08 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 320/366 | LOSS: 0.16032 (0.11005) | LR: 0.00001073 | TIME: 0:15:01 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 360/366 | LOSS: 0.11942 (0.10978) | LR: 0.00000897 | TIME: 0:16:55 |\n",
            "[TRAIN F3] EPOCH: 2/3 | STEP: 365/366 | LOSS: 0.08111 (0.10971) | LR: 0.00000876 | TIME: 0:17:08 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F3] EPOCH: 2/3 | STEP: 000/123 | LOSS: 0.10531 (0.10531) | TIME: 0:00:01 |\n",
            "[VALID F3] EPOCH: 2/3 | STEP: 040/123 | LOSS: 0.09127 (0.09895) | TIME: 0:00:31 |\n",
            "[VALID F3] EPOCH: 2/3 | STEP: 080/123 | LOSS: 0.12704 (0.10190) | TIME: 0:01:02 |\n",
            "[VALID F3] EPOCH: 2/3 | STEP: 120/123 | LOSS: 0.08356 (0.10321) | TIME: 0:01:32 |\n",
            "[VALID F3] EPOCH: 2/3 | STEP: 122/123 | LOSS: 0.06836 (0.10300) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 2/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 2/3     |      0.10971 |        0.103 |  0.45463 | 0.486 | 0.456 | 0.415 | 0.466 | 0.468 | 0.437 | 0:18:41 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 2 | MCRMSE: 0.4546292722225189\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 000/366 | LOSS: 0.22812 (0.22812) | LR: 0.00000872 | TIME: 0:00:04 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 040/366 | LOSS: 0.10153 (0.10265) | LR: 0.00000707 | TIME: 0:01:56 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 080/366 | LOSS: 0.12954 (0.10097) | LR: 0.00000555 | TIME: 0:03:46 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 120/366 | LOSS: 0.10464 (0.09891) | LR: 0.00000417 | TIME: 0:05:36 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 160/366 | LOSS: 0.04994 (0.09769) | LR: 0.00000296 | TIME: 0:07:26 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 200/366 | LOSS: 0.07305 (0.09771) | LR: 0.00000194 | TIME: 0:09:19 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 240/366 | LOSS: 0.08074 (0.09745) | LR: 0.00000113 | TIME: 0:11:11 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 280/366 | LOSS: 0.08442 (0.09667) | LR: 0.00000052 | TIME: 0:13:02 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 320/366 | LOSS: 0.10276 (0.09619) | LR: 0.00000015 | TIME: 0:14:56 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 360/366 | LOSS: 0.09427 (0.09589) | LR: 0.00000000 | TIME: 0:16:48 |\n",
            "[TRAIN F3] EPOCH: 3/3 | STEP: 365/366 | LOSS: 0.12040 (0.09597) | LR: 0.00000000 | TIME: 0:17:03 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F3] EPOCH: 3/3 | STEP: 000/123 | LOSS: 0.10798 (0.10798) | TIME: 0:00:01 |\n",
            "[VALID F3] EPOCH: 3/3 | STEP: 040/123 | LOSS: 0.07984 (0.09581) | TIME: 0:00:31 |\n",
            "[VALID F3] EPOCH: 3/3 | STEP: 080/123 | LOSS: 0.10456 (0.09813) | TIME: 0:01:02 |\n",
            "[VALID F3] EPOCH: 3/3 | STEP: 120/123 | LOSS: 0.08862 (0.09927) | TIME: 0:01:32 |\n",
            "[VALID F3] EPOCH: 3/3 | STEP: 122/123 | LOSS: 0.05171 (0.09899) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 3/3 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 3/3     |      0.09597 |      0.09899 |  0.44552 | 0.484 | 0.442 | 0.412 | 0.435 | 0.464 | 0.436 | 0:18:36 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 3 | MCRMSE: 0.44552016258239746\n",
            "\n",
            "\n",
            "----------------------------------- FOLD 3 RESULT -----------------------------------\n",
            "  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions\n",
            "--------  ----------  --------  ------------  -------------  ---------  -------------\n",
            " 0.44552      0.4845   0.44183       0.41155        0.43479    0.46399        0.43647\n",
            "\n",
            "################################### END OF FOlD 3 ###################################\n",
            "\n",
            "\n",
            "Overall Training Result\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  fold epoch   train_loss   valid_loss      mcrmse    cohesion      syntax  \\\n",
              "0    0     1   0.12332021   0.10905462  0.46724376  0.50886524  0.46532404   \n",
              "0    0     2  0.107630126   0.10052387  0.44865045  0.48421624   0.4437206   \n",
              "0    0     3   0.09507596   0.09984761  0.44719335  0.47779575  0.44275668   \n",
              "0    1     1  0.122619994   0.11329121    0.477165  0.50862813  0.46742293   \n",
              "0    1     2  0.108404435   0.10539866  0.45983794   0.5044008  0.44408068   \n",
              "0    1     3  0.095705174   0.10335419   0.4552873   0.4919293   0.4447469   \n",
              "0    2     1  0.123868786   0.13808502   0.5281289   0.5505252  0.55008304   \n",
              "0    2     2  0.106705874  0.105279736  0.46024755  0.48575047  0.45227924   \n",
              "0    2     3    0.0928264  0.104471005  0.45822504   0.4844257  0.45146272   \n",
              "0    3     1   0.12423442   0.10834746   0.4665395  0.49802577  0.44774786   \n",
              "0    3     2   0.10971142   0.10299584  0.45462927   0.4855762   0.4559296   \n",
              "0    3     3  0.095965974   0.09898608  0.44552016  0.48449677   0.4418264   \n",
              "\n",
              "   vocabulary phraseology     grammar conventions  \n",
              "0  0.41962346  0.46432376  0.49469644  0.45062947  \n",
              "0  0.41070703  0.45163482  0.46566516  0.43595874  \n",
              "0    0.410933  0.44972745  0.46610594  0.43584114  \n",
              "0  0.43917632   0.4623592   0.4790872   0.5063163  \n",
              "0  0.42039776   0.4543147  0.47423908  0.46159467  \n",
              "0  0.41900846  0.45177072  0.47072923  0.45353904  \n",
              "0  0.46684575   0.5390564    0.498646  0.56361705  \n",
              "0  0.42708105   0.4681139  0.47347537   0.4547854  \n",
              "0  0.41533154   0.4665174   0.4750954  0.45651743  \n",
              "0  0.47221377  0.44432893  0.48621595  0.45070466  \n",
              "0  0.41486743   0.4659012   0.4683917   0.4371094  \n",
              "0  0.41154832   0.4347888  0.46398917  0.43647164  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d79fbcd6-f405-41db-bc96-bb2e594123ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>mcrmse</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.12332021</td>\n",
              "      <td>0.10905462</td>\n",
              "      <td>0.46724376</td>\n",
              "      <td>0.50886524</td>\n",
              "      <td>0.46532404</td>\n",
              "      <td>0.41962346</td>\n",
              "      <td>0.46432376</td>\n",
              "      <td>0.49469644</td>\n",
              "      <td>0.45062947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.107630126</td>\n",
              "      <td>0.10052387</td>\n",
              "      <td>0.44865045</td>\n",
              "      <td>0.48421624</td>\n",
              "      <td>0.4437206</td>\n",
              "      <td>0.41070703</td>\n",
              "      <td>0.45163482</td>\n",
              "      <td>0.46566516</td>\n",
              "      <td>0.43595874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.09507596</td>\n",
              "      <td>0.09984761</td>\n",
              "      <td>0.44719335</td>\n",
              "      <td>0.47779575</td>\n",
              "      <td>0.44275668</td>\n",
              "      <td>0.410933</td>\n",
              "      <td>0.44972745</td>\n",
              "      <td>0.46610594</td>\n",
              "      <td>0.43584114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.122619994</td>\n",
              "      <td>0.11329121</td>\n",
              "      <td>0.477165</td>\n",
              "      <td>0.50862813</td>\n",
              "      <td>0.46742293</td>\n",
              "      <td>0.43917632</td>\n",
              "      <td>0.4623592</td>\n",
              "      <td>0.4790872</td>\n",
              "      <td>0.5063163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.108404435</td>\n",
              "      <td>0.10539866</td>\n",
              "      <td>0.45983794</td>\n",
              "      <td>0.5044008</td>\n",
              "      <td>0.44408068</td>\n",
              "      <td>0.42039776</td>\n",
              "      <td>0.4543147</td>\n",
              "      <td>0.47423908</td>\n",
              "      <td>0.46159467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.095705174</td>\n",
              "      <td>0.10335419</td>\n",
              "      <td>0.4552873</td>\n",
              "      <td>0.4919293</td>\n",
              "      <td>0.4447469</td>\n",
              "      <td>0.41900846</td>\n",
              "      <td>0.45177072</td>\n",
              "      <td>0.47072923</td>\n",
              "      <td>0.45353904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.123868786</td>\n",
              "      <td>0.13808502</td>\n",
              "      <td>0.5281289</td>\n",
              "      <td>0.5505252</td>\n",
              "      <td>0.55008304</td>\n",
              "      <td>0.46684575</td>\n",
              "      <td>0.5390564</td>\n",
              "      <td>0.498646</td>\n",
              "      <td>0.56361705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.106705874</td>\n",
              "      <td>0.105279736</td>\n",
              "      <td>0.46024755</td>\n",
              "      <td>0.48575047</td>\n",
              "      <td>0.45227924</td>\n",
              "      <td>0.42708105</td>\n",
              "      <td>0.4681139</td>\n",
              "      <td>0.47347537</td>\n",
              "      <td>0.4547854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0928264</td>\n",
              "      <td>0.104471005</td>\n",
              "      <td>0.45822504</td>\n",
              "      <td>0.4844257</td>\n",
              "      <td>0.45146272</td>\n",
              "      <td>0.41533154</td>\n",
              "      <td>0.4665174</td>\n",
              "      <td>0.4750954</td>\n",
              "      <td>0.45651743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.12423442</td>\n",
              "      <td>0.10834746</td>\n",
              "      <td>0.4665395</td>\n",
              "      <td>0.49802577</td>\n",
              "      <td>0.44774786</td>\n",
              "      <td>0.47221377</td>\n",
              "      <td>0.44432893</td>\n",
              "      <td>0.48621595</td>\n",
              "      <td>0.45070466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10971142</td>\n",
              "      <td>0.10299584</td>\n",
              "      <td>0.45462927</td>\n",
              "      <td>0.4855762</td>\n",
              "      <td>0.4559296</td>\n",
              "      <td>0.41486743</td>\n",
              "      <td>0.4659012</td>\n",
              "      <td>0.4683917</td>\n",
              "      <td>0.4371094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.095965974</td>\n",
              "      <td>0.09898608</td>\n",
              "      <td>0.44552016</td>\n",
              "      <td>0.48449677</td>\n",
              "      <td>0.4418264</td>\n",
              "      <td>0.41154832</td>\n",
              "      <td>0.4347888</td>\n",
              "      <td>0.46398917</td>\n",
              "      <td>0.43647164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d79fbcd6-f405-41db-bc96-bb2e594123ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d79fbcd6-f405-41db-bc96-bb2e594123ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d79fbcd6-f405-41db-bc96-bb2e594123ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Result\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   fold epoch   train_loss   valid_loss      mcrmse    cohesion      syntax  \\\n",
              "0     0     3   0.09507596   0.09984761  0.44719335  0.47779575  0.44275668   \n",
              "1     1     3  0.095705174   0.10335419   0.4552873   0.4919293   0.4447469   \n",
              "2     2     3    0.0928264  0.104471005  0.45822504   0.4844257  0.45146272   \n",
              "3     3     3  0.095965974   0.09898608  0.44552016  0.48449677   0.4418264   \n",
              "4  99.0  99.0     0.094893     0.101665    0.451556    0.484662    0.445198   \n",
              "\n",
              "   vocabulary phraseology     grammar conventions  \n",
              "0    0.410933  0.44972745  0.46610594  0.43584114  \n",
              "1  0.41900846  0.45177072  0.47072923  0.45353904  \n",
              "2  0.41533154   0.4665174   0.4750954  0.45651743  \n",
              "3  0.41154832   0.4347888  0.46398917  0.43647164  \n",
              "4    0.414205    0.450701     0.46898    0.445592  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-014f1cca-df04-4acd-8f1e-477671bcbc16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>mcrmse</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.09507596</td>\n",
              "      <td>0.09984761</td>\n",
              "      <td>0.44719335</td>\n",
              "      <td>0.47779575</td>\n",
              "      <td>0.44275668</td>\n",
              "      <td>0.410933</td>\n",
              "      <td>0.44972745</td>\n",
              "      <td>0.46610594</td>\n",
              "      <td>0.43584114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.095705174</td>\n",
              "      <td>0.10335419</td>\n",
              "      <td>0.4552873</td>\n",
              "      <td>0.4919293</td>\n",
              "      <td>0.4447469</td>\n",
              "      <td>0.41900846</td>\n",
              "      <td>0.45177072</td>\n",
              "      <td>0.47072923</td>\n",
              "      <td>0.45353904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0928264</td>\n",
              "      <td>0.104471005</td>\n",
              "      <td>0.45822504</td>\n",
              "      <td>0.4844257</td>\n",
              "      <td>0.45146272</td>\n",
              "      <td>0.41533154</td>\n",
              "      <td>0.4665174</td>\n",
              "      <td>0.4750954</td>\n",
              "      <td>0.45651743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.095965974</td>\n",
              "      <td>0.09898608</td>\n",
              "      <td>0.44552016</td>\n",
              "      <td>0.48449677</td>\n",
              "      <td>0.4418264</td>\n",
              "      <td>0.41154832</td>\n",
              "      <td>0.4347888</td>\n",
              "      <td>0.46398917</td>\n",
              "      <td>0.43647164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.094893</td>\n",
              "      <td>0.101665</td>\n",
              "      <td>0.451556</td>\n",
              "      <td>0.484662</td>\n",
              "      <td>0.445198</td>\n",
              "      <td>0.414205</td>\n",
              "      <td>0.450701</td>\n",
              "      <td>0.46898</td>\n",
              "      <td>0.445592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-014f1cca-df04-4acd-8f1e-477671bcbc16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-014f1cca-df04-4acd-8f1e-477671bcbc16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-014f1cca-df04-4acd-8f1e-477671bcbc16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Result\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       mcrmse   cohesion      syntax  vocabulary phraseology     grammar  \\\n",
              "0  0.45160806  0.4846858  0.44521427  0.41421682    0.450841  0.46899912   \n",
              "\n",
              "  conventions  \n",
              "0  0.44569147  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea09a115-09ae-4695-a512-96f980b97087\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mcrmse</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.45160806</td>\n",
              "      <td>0.4846858</td>\n",
              "      <td>0.44521427</td>\n",
              "      <td>0.41421682</td>\n",
              "      <td>0.450841</td>\n",
              "      <td>0.46899912</td>\n",
              "      <td>0.44569147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea09a115-09ae-4695-a512-96f980b97087')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea09a115-09ae-4695-a512-96f980b97087 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea09a115-09ae-4695-a512-96f980b97087');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "check_or_create(TRAINCONF.save_path)\n",
        "export_config(basic=BASICCONF, train=TRAINCONF)\n",
        "# source is path to where your pretrain models is placed\n",
        "source = '/content/drive/MyDrive/fb3/results/exp64s42pretrained'\n",
        "run_training(df, TRAINCONF, source, dry_run=False, exp=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs8w-6TCCTsX"
      },
      "source": [
        "# Jump to Results 🔼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbTsPgUQCTsX"
      },
      "outputs": [],
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "# model = AutoModel.from_pretrained('microsoft/deberta-v3-base', output_hidden_states=True)\n",
        "# train_loader, valid_loader, total_train_samples = get_dataloader(conf, df, tokenizer, 8, 2)\n",
        "\n",
        "# loader = iter(train_loader)\n",
        "# first = next(loader)\n",
        "# outputs = model(**first[0])\n",
        "\n",
        "# import pdb; pdb.set_trace()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "146dd0fccc6941419d8b2da19daa4323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3166ef42ad44814a7fc77f2d8af9925",
              "IPY_MODEL_756e5e80e7254a58b939cbe23162dcfe",
              "IPY_MODEL_53d93aed28f24007af782d512946dc2c"
            ],
            "layout": "IPY_MODEL_5901e69c52bc448a89b44537a59855c8"
          }
        },
        "f3166ef42ad44814a7fc77f2d8af9925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b381f14f21439595c7975513def3fe",
            "placeholder": "​",
            "style": "IPY_MODEL_51f00b0198734ffb88dd89acebc1e239",
            "value": "Downloading: 100%"
          }
        },
        "756e5e80e7254a58b939cbe23162dcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6b016bee7e1464ba7e6467415678fe5",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b6f0812f0114363a883ee59ea9cd60b",
            "value": 52
          }
        },
        "53d93aed28f24007af782d512946dc2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425fc451937e4a7785f056a68c3d37d6",
            "placeholder": "​",
            "style": "IPY_MODEL_de50c56510054e2095d7e79e4953201a",
            "value": " 52.0/52.0 [00:00&lt;00:00, 1.21kB/s]"
          }
        },
        "5901e69c52bc448a89b44537a59855c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b381f14f21439595c7975513def3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f00b0198734ffb88dd89acebc1e239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6b016bee7e1464ba7e6467415678fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b6f0812f0114363a883ee59ea9cd60b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "425fc451937e4a7785f056a68c3d37d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de50c56510054e2095d7e79e4953201a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f63e04aaad64c3cbd12ebd8f93810e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd1721d6e54d4120ac1e58d183f0dbb4",
              "IPY_MODEL_84505acd57554146b18a41733473e239",
              "IPY_MODEL_646bb21da25a4629be6ca32508b1b5d9"
            ],
            "layout": "IPY_MODEL_0e433393e1b7467da23501612c79d2b5"
          }
        },
        "fd1721d6e54d4120ac1e58d183f0dbb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daea69c40e5a4bfe8d23e4cd7975cde7",
            "placeholder": "​",
            "style": "IPY_MODEL_97c1b9f4d9164b84847c4471f4fcbcc0",
            "value": "Downloading: 100%"
          }
        },
        "84505acd57554146b18a41733473e239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e10bd0aca0f40028a3b39c8d0c423bd",
            "max": 579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d935460964a64bd6909775496858e236",
            "value": 579
          }
        },
        "646bb21da25a4629be6ca32508b1b5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a83fbd0c508c481ba2ceea8d6cb2493d",
            "placeholder": "​",
            "style": "IPY_MODEL_68e3c9e4b63048ef8c894fce5c24d10c",
            "value": " 579/579 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "0e433393e1b7467da23501612c79d2b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daea69c40e5a4bfe8d23e4cd7975cde7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c1b9f4d9164b84847c4471f4fcbcc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e10bd0aca0f40028a3b39c8d0c423bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d935460964a64bd6909775496858e236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a83fbd0c508c481ba2ceea8d6cb2493d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e3c9e4b63048ef8c894fce5c24d10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05825a7c09434e1e9efb99e3adcbd2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e80cbd611ed4017a56398eddd75ee07",
              "IPY_MODEL_8a17ea99b5a14080a7c7467c40892cc3",
              "IPY_MODEL_091bd6031bd44b05a46afcbf63dd5d4b"
            ],
            "layout": "IPY_MODEL_2dd332a2a63b47fd8fcd6a75b753b49e"
          }
        },
        "6e80cbd611ed4017a56398eddd75ee07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee89c6b5839442e9b24ce990976cea1a",
            "placeholder": "​",
            "style": "IPY_MODEL_6b4885a446d045efbe7160375d5387dc",
            "value": "Downloading: 100%"
          }
        },
        "8a17ea99b5a14080a7c7467c40892cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b825058509cf41ee935a58f8f817d1c8",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf07f1e06901472bafb3be31c3bb4e85",
            "value": 2464616
          }
        },
        "091bd6031bd44b05a46afcbf63dd5d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac1824c0f11640e98d86152f3881cf85",
            "placeholder": "​",
            "style": "IPY_MODEL_45c5a3292798419fbcaa41c7b85c15c4",
            "value": " 2.35M/2.35M [00:00&lt;00:00, 27.0MB/s]"
          }
        },
        "2dd332a2a63b47fd8fcd6a75b753b49e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee89c6b5839442e9b24ce990976cea1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4885a446d045efbe7160375d5387dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b825058509cf41ee935a58f8f817d1c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf07f1e06901472bafb3be31c3bb4e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac1824c0f11640e98d86152f3881cf85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c5a3292798419fbcaa41c7b85c15c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}