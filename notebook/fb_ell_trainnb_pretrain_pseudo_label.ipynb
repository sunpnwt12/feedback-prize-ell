{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d53e75d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:42:57.214342Z",
          "iopub.status.busy": "2022-11-23T13:42:57.213825Z",
          "iopub.status.idle": "2022-11-23T13:42:58.380958Z",
          "shell.execute_reply": "2022-11-23T13:42:58.379663Z"
        },
        "papermill": {
          "duration": 1.178521,
          "end_time": "2022-11-23T13:42:58.383749",
          "exception": false,
          "start_time": "2022-11-23T13:42:57.205228",
          "status": "completed"
        },
        "tags": [],
        "id": "3d53e75d",
        "outputId": "58a7883d-037d-4832-a0cc-dc7e26283263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 26 13:30:57 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install -q torchmetrics\n",
        "!pip install -q transformers==4.20.1\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q kaggle --upgrade"
      ],
      "metadata": {
        "id": "mFSPp35FdGxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff71cb7e-53d4-44a4-8cb5-f53ae903edcc"
      },
      "id": "mFSPp35FdGxf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch==1.11.0+cu113 in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision==0.12.0+cu113 in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: torchaudio==0.11.0 in /usr/local/lib/python3.7/dist-packages (0.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0+cu113) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_data = True\n",
        "import os\n",
        "if os.path.exists('/content/data'):\n",
        "    prepare_data = False"
      ],
      "metadata": {
        "id": "5DMaQ-pxdIW7"
      },
      "id": "5DMaQ-pxdIW7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if prepare_data:    \n",
        "    from google.colab import files, drive\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "            name=fn, length=len(uploaded[fn])))\n",
        "    \n",
        "    # Then move kaggle.json into the folder where the API expects to find it.\n",
        "    !mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    !mkdir data && cd data && kaggle competitions download -c feedback-prize-english-language-learning\n",
        "    !unzip /content/data/feedback-prize-english-language-learning.zip -d /content/data/\n",
        "\n",
        "    # change \"sunpnwt12/fb3-nb-pl\" to your generated pseudo-labels datatset here\n",
        "    # or change pl_data_path\n",
        "    # !mkdir data/pl && cd data/pl && kaggle datasets download -d sunpnwt12/fb3-nb-pl\n",
        "    # !unzip /content/data/pl/fb3-nb-pl.zip -d /content/data/pl/\n",
        "\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GYmTD3CvdJgg"
      },
      "id": "GYmTD3CvdJgg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc0fdf23",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:42:58.401627Z",
          "iopub.status.busy": "2022-11-23T13:42:58.400692Z",
          "iopub.status.idle": "2022-11-23T13:43:15.900010Z",
          "shell.execute_reply": "2022-11-23T13:43:15.898677Z"
        },
        "papermill": {
          "duration": 17.510428,
          "end_time": "2022-11-23T13:43:15.902132",
          "exception": false,
          "start_time": "2022-11-23T13:42:58.391704",
          "status": "completed"
        },
        "tags": [],
        "id": "fc0fdf23",
        "outputId": "c96a5d19-c28e-4655-ebee-15ed7ab2ca47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python version: 3.7.15 (default, Oct 12 2022, 19:14:55) \n",
            "[GCC 7.5.0]\n",
            "iterstart version: 0.1.6\n",
            "torch version: 1.11.0+cu113\n",
            "transfromers version: 4.20.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "import gc; gc.enable()\n",
        "import random\n",
        "import warnings\n",
        "import yaml\n",
        "from itertools import chain\n",
        "from pathlib import Path\n",
        "from tabulate import tabulate\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(f'python version: {sys.version}') \n",
        "\n",
        "os.system('pip install -q iterative-stratification==0.1.7')\n",
        "import iterstrat\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "print(f'iterstart version: {iterstrat.__version__}')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "\n",
        "print(f'torch version: {torch.__version__}')\n",
        "\n",
        "from torchmetrics.functional import mean_squared_error\n",
        "\n",
        "# os.system('pip install --root-user-action=ignore --force-reinstall transformers==4.22.1')\n",
        "import transformers\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig, DataCollatorWithPadding\n",
        "print(f'transfromers version: {transformers.__version__}')\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88b817f",
      "metadata": {
        "papermill": {
          "duration": 0.007353,
          "end_time": "2022-11-23T13:43:15.917130",
          "exception": false,
          "start_time": "2022-11-23T13:43:15.909777",
          "status": "completed"
        },
        "tags": [],
        "id": "d88b817f"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80a79c9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:15.933341Z",
          "iopub.status.busy": "2022-11-23T13:43:15.932401Z",
          "iopub.status.idle": "2022-11-23T13:43:15.938293Z",
          "shell.execute_reply": "2022-11-23T13:43:15.937438Z"
        },
        "papermill": {
          "duration": 0.0161,
          "end_time": "2022-11-23T13:43:15.940307",
          "exception": false,
          "start_time": "2022-11-23T13:43:15.924207",
          "status": "completed"
        },
        "tags": [],
        "id": "f80a79c9"
      },
      "outputs": [],
      "source": [
        "class BASICCONF:\n",
        "    seed = 42\n",
        "    \n",
        "    data_path = '/content/data'\n",
        "    \n",
        "    target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
        "    num_labels = 6\n",
        "    num_folds = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49107efb",
      "metadata": {
        "papermill": {
          "duration": 0.006999,
          "end_time": "2022-11-23T13:43:15.954923",
          "exception": false,
          "start_time": "2022-11-23T13:43:15.947924",
          "status": "completed"
        },
        "tags": [],
        "id": "49107efb"
      },
      "source": [
        "# Seeding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6329d78d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:15.970635Z",
          "iopub.status.busy": "2022-11-23T13:43:15.970328Z",
          "iopub.status.idle": "2022-11-23T13:43:15.978259Z",
          "shell.execute_reply": "2022-11-23T13:43:15.977436Z"
        },
        "papermill": {
          "duration": 0.01813,
          "end_time": "2022-11-23T13:43:15.980175",
          "exception": false,
          "start_time": "2022-11-23T13:43:15.962045",
          "status": "completed"
        },
        "tags": [],
        "id": "6329d78d"
      },
      "outputs": [],
      "source": [
        "#https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\n",
        "def seed_everything(seed: int):    \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(BASICCONF.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56e08cc",
      "metadata": {
        "papermill": {
          "duration": 0.007729,
          "end_time": "2022-11-23T13:43:15.994876",
          "exception": false,
          "start_time": "2022-11-23T13:43:15.987147",
          "status": "completed"
        },
        "tags": [],
        "id": "a56e08cc"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0fcd6b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:16.010813Z",
          "iopub.status.busy": "2022-11-23T13:43:16.010098Z",
          "iopub.status.idle": "2022-11-23T13:43:17.013909Z",
          "shell.execute_reply": "2022-11-23T13:43:17.012930Z"
        },
        "papermill": {
          "duration": 1.014287,
          "end_time": "2022-11-23T13:43:17.016249",
          "exception": false,
          "start_time": "2022-11-23T13:43:16.001962",
          "status": "completed"
        },
        "tags": [],
        "id": "5e0fcd6b"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = f'{BASICCONF.data_path}/train.csv'\n",
        "TEST_PATH = f'{BASICCONF.data_path}/test.csv'\n",
        "SAMP_SUB = f'{BASICCONF.data_path}/sample_submission.csv'\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "samp_sup = pd.read_csv(SAMP_SUB)\n",
        "\n",
        "pl_data_path = '/content/data/pl'\n",
        "pl_df_f0 = pd.read_csv(f'{pl_data_path}/pl_s42_f0.csv')\n",
        "pl_df_f1 = pd.read_csv(f'{pl_data_path}/pl_s42_f1.csv')\n",
        "pl_df_f2 = pd.read_csv(f'{pl_data_path}/pl_s42_f2.csv')\n",
        "pl_df_f3 = pd.read_csv(f'{pl_data_path}/pl_s42_f3.csv')\n",
        "\n",
        "duplicated_idx = pd.concat([train_df, pl_df_f0])[pd.concat([train_df, pl_df_f0]).duplicated('text_id').values].index\n",
        "\n",
        "pl_df_f0 = pl_df_f0.drop(duplicated_idx).reset_index(drop=False)\n",
        "pl_df_f1 = pl_df_f1.drop(duplicated_idx).reset_index(drop=False)\n",
        "pl_df_f2 = pl_df_f2.drop(duplicated_idx).reset_index(drop=False)\n",
        "pl_df_f3 = pl_df_f3.drop(duplicated_idx).reset_index(drop=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e16829",
      "metadata": {
        "papermill": {
          "duration": 0.007299,
          "end_time": "2022-11-23T13:43:17.032139",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.024840",
          "status": "completed"
        },
        "tags": [],
        "id": "a3e16829"
      },
      "source": [
        "## split CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fc94d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.047803Z",
          "iopub.status.busy": "2022-11-23T13:43:17.047497Z",
          "iopub.status.idle": "2022-11-23T13:43:17.188327Z",
          "shell.execute_reply": "2022-11-23T13:43:17.187418Z"
        },
        "papermill": {
          "duration": 0.151148,
          "end_time": "2022-11-23T13:43:17.190455",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.039307",
          "status": "completed"
        },
        "tags": [],
        "id": "58fc94d4",
        "outputId": "6ff3b12f-6141-4d14-840c-db2c4606b03a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fold\n",
              "0    973\n",
              "1    972\n",
              "2    973\n",
              "3    972\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def split_cv(conf, df_):\n",
        "    df = df_.copy(deep=True)\n",
        "    mskf = MultilabelStratifiedKFold(n_splits=conf.num_folds, shuffle=True, random_state=conf.seed)\n",
        "    y = df[conf.target_cols]\n",
        "    # y = pd.get_dummies(data=df[conf.target_cols], columns=conf.target_cols)\n",
        "\n",
        "    for n, (train_index, valid_index) in enumerate(mskf.split(df, y)):\n",
        "        df.loc[ｖalid_index, 'fold'] = int(n)\n",
        "    \n",
        "    df['fold'] = df['fold'].astype(int)\n",
        "        \n",
        "    return df\n",
        "        \n",
        "pl_df_f0 = split_cv(BASICCONF, pl_df_f0)\n",
        "for fx in [pl_df_f1, pl_df_f2, pl_df_f3]:\n",
        "    fx['fold'] = pl_df_f0['fold']\n",
        "    \n",
        "pl_df_list = [pl_df_f0, pl_df_f1, pl_df_f2, pl_df_f3]\n",
        "pl_df_f0.groupby('fold').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c723c55",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.207735Z",
          "iopub.status.busy": "2022-11-23T13:43:17.206835Z",
          "iopub.status.idle": "2022-11-23T13:43:17.211518Z",
          "shell.execute_reply": "2022-11-23T13:43:17.210611Z"
        },
        "papermill": {
          "duration": 0.015031,
          "end_time": "2022-11-23T13:43:17.213598",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.198567",
          "status": "completed"
        },
        "tags": [],
        "id": "5c723c55"
      },
      "outputs": [],
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "# all_text = df['full_text']\n",
        "# def ft_array_dist(full_texts, tokenizer):\n",
        "#     lengths = []\n",
        "#     for text in full_texts.fillna('').values:\n",
        "#         length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "#         lengths.append(length)\n",
        "#     lengths = np.array(lengths)\n",
        "#     return lengths\n",
        "\n",
        "# all_text_l = ft_array_dist(all_text, tokenizer)\n",
        "# plt.hist(all_text_l, 40)\n",
        "# ft_fold = df[df['fold'] != 1]['full_text']\n",
        "# l_fold = ft_array_dist(ft_fold, tokenizer)\n",
        "# plt.hist(l_fold, 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "170c3d52",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.229185Z",
          "iopub.status.busy": "2022-11-23T13:43:17.228929Z",
          "iopub.status.idle": "2022-11-23T13:43:17.238473Z",
          "shell.execute_reply": "2022-11-23T13:43:17.237525Z"
        },
        "papermill": {
          "duration": 0.019417,
          "end_time": "2022-11-23T13:43:17.240249",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.220832",
          "status": "completed"
        },
        "tags": [],
        "id": "170c3d52"
      },
      "outputs": [],
      "source": [
        "class FB3Dataset(Dataset):\n",
        "    def __init__(self, conf, df, tokenizer, fold):\n",
        "        self.labels = df[conf.target_cols].reset_index(drop=True)\n",
        "        self.full_texts = df['full_text'].reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        if conf.dynamic_max_len:\n",
        "            self.max_len = self._get_max_len()\n",
        "        else:\n",
        "            self.max_len = conf.static_max_len_list[fold]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.full_texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        token = self._get_token(idx)\n",
        "        label = self._get_label(idx)\n",
        "        \n",
        "        return token, label\n",
        "    \n",
        "    def _get_label(self, idx):\n",
        "        return torch.tensor(self.labels.loc[idx].values, dtype=torch.float)\n",
        "    \n",
        "    def _get_token(self, idx):\n",
        "        tokenized = self.tokenizer(\n",
        "                        self.full_texts.loc[idx],\n",
        "                        add_special_tokens=True,\n",
        "                        max_length=self.max_len,\n",
        "                        pad_to_max_length=True,\n",
        "                        truncation=True,\n",
        "                        return_tensors=None,\n",
        "                )\n",
        "        return {k: torch.tensor(v, dtype=torch.long) for k, v in tokenized.items()} # stack tensor\n",
        "    \n",
        "    # get longest max_len\n",
        "    # https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train/notebook\n",
        "    def _get_max_len(self):\n",
        "        lengths = []\n",
        "        for text in self.full_texts.fillna('').values:\n",
        "            length = len(self.tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "            lengths.append(length)\n",
        "        return max(lengths) + 2 # cls & sep"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4ee33ee",
      "metadata": {
        "papermill": {
          "duration": 0.007042,
          "end_time": "2022-11-23T13:43:17.254682",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.247640",
          "status": "completed"
        },
        "tags": [],
        "id": "c4ee33ee"
      },
      "source": [
        "\n",
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c63c825c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.270681Z",
          "iopub.status.busy": "2022-11-23T13:43:17.270423Z",
          "iopub.status.idle": "2022-11-23T13:43:17.316213Z",
          "shell.execute_reply": "2022-11-23T13:43:17.315422Z"
        },
        "papermill": {
          "duration": 0.05595,
          "end_time": "2022-11-23T13:43:17.318115",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.262165",
          "status": "completed"
        },
        "tags": [],
        "id": "c63c825c"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/maunish/clrp-pytorch-roberta-finetune/notebook\n",
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, in_features, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.middle_features = hidden_dim\n",
        "        self.W = nn.Linear(in_features, hidden_dim)\n",
        "        self.V = nn.Linear(hidden_dim, 1)\n",
        "        self.out_features = hidden_dim\n",
        "\n",
        "    def forward(self, features):\n",
        "        att = torch.tanh(self.W(features))\n",
        "        score = self.V(att)\n",
        "        attention_weights = torch.softmax(score, dim=1)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "# https://www.kaggle.com/competitions/feedback-prize-english-language-learning/discussion/361678\n",
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(in_dim, in_dim),\n",
        "            nn.LayerNorm(in_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(in_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        w = self.attention(x).float()\n",
        "        w[mask==0]=float('-inf')\n",
        "        w = torch.softmax(w,1)\n",
        "        x = torch.sum(w * x, dim=1)\n",
        "        return x    \n",
        "    \n",
        "# https://www.kaggle.com/code/rhtsingh/utilizing-transformer-representations-efficiently\n",
        "class HiddenAttentionPooling(nn.Module):\n",
        "    def __init__(self, num_layers, hidden_size, hiddendim_fc):\n",
        "        super().__init__()\n",
        "        self.num_hidden_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hiddendim_fc = hiddendim_fc\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        q_t = torch.normal(mean=0.0, std=0.02, size=(1, self.hidden_size))\n",
        "        self.q = nn.Parameter(q_t).float()\n",
        "        w_ht = torch.normal(mean=0.0, std=0.02, size=(self.hidden_size, self.hiddendim_fc))\n",
        "        self.w_h = nn.Parameter(w_ht).float()\n",
        "\n",
        "    def forward(self, all_hidden_states):\n",
        "        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n",
        "                                     for layer_i in range(1, self.num_hidden_layers+1)], dim=-1)\n",
        "        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n",
        "        out = self.attention(hidden_states)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "    def attention(self, h):\n",
        "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
        "        v = F.softmax(v, -1)\n",
        "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
        "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
        "        return v\n",
        "\n",
        "class ConcatPooling(nn.Module):\n",
        "    def __init__(self, pooling_last=4):\n",
        "        super().__init__()\n",
        "        self.pooling_last = pooling_last\n",
        "        \n",
        "    def forward(self, all_hidden_states):\n",
        "        concat_pooling = torch.cat(tuple(all_hidden_states[-l] for l in range(1, self.pooling_last + 1)), -1)\n",
        "#         concat_pooling = concat_pooling.mean(dim=1) # average instead of select only one\n",
        "        concat_pooling = concat_pooling[:, 0] # select the first one\n",
        "        return concat_pooling\n",
        "\n",
        "# https://www.kaggle.com/competitions/google-quest-challenge/discussion/129840\n",
        "class WeightedLayerPooling(nn.Module):\n",
        "    def __init__(self, num_layers=12, init_std=0.02):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        weights_init = torch.zeros(self.num_layers).float()\n",
        "        weights_init.data[:-1] = -3\n",
        "        self.layer_weights = torch.nn.Parameter(weights_init)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, all_hidden_states):\n",
        "        all_layer_encoders = torch.stack(\n",
        "            [self.dropout(layer) for layer in all_hidden_states[-self.num_layers:]], dim=0\n",
        "        )\n",
        "        averaged_layers = (torch.softmax(self.layer_weights, dim=0).unsqueeze(1).unsqueeze(1).unsqueeze(1) * all_layer_encoders).sum(0)\n",
        "        return averaged_layers\n",
        "        \n",
        "class MeanPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def forward(self, last_hidden_state, attention_mask):\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        mean_embeddings = sum_embeddings / sum_mask\n",
        "        return mean_embeddings\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, conf, fold_num, config_path=None):\n",
        "        super().__init__()\n",
        "        if not config_path:\n",
        "            self.model_conf = AutoConfig.from_pretrained(conf.model_name, output_hidden_states=True)\n",
        "            self.model_conf = self._set_dropout(self.model_conf)\n",
        "            self.backbone = AutoModel.from_pretrained(conf.model_name, config=self.model_conf)\n",
        "        else:\n",
        "            self.model_conf = torch.load(config_path)\n",
        "            self.backbone = AutoModel.from_config(self.model_conf)\n",
        "        if conf.gradient_checkpointing:\n",
        "            self.backbone.gradient_checkpointing_enable()\n",
        "        \n",
        "        if not config_path:\n",
        "            for layer in self.backbone.encoder.layer[-conf.reinit_last_layers:]:\n",
        "                for module in layer.modules():\n",
        "                    self._init_weights(module)\n",
        "                    \n",
        "        self.pooling_strategy = conf.pooling_strategy_list[fold_num]\n",
        "        if self.pooling_strategy == 'mean_pooling':\n",
        "            self.pooler = MeanPooling()\n",
        "            \n",
        "        elif self.pooling_strategy == 'concat_pooling':\n",
        "            self.pooler = ConcatPooling(conf.concat_pooling_last)\n",
        "            \n",
        "        elif self.pooling_strategy == 'attn_pooling': \n",
        "            self.attn_pooler = AttentionPooling(self.model_conf.hidden_size) \n",
        "            for attn_module in self.attn_pooler.modules():\n",
        "                self._init_weights(attn_module)\n",
        "            \n",
        "        elif self.pooling_strategy == 'wlp_attn_pooling':\n",
        "            self.wlp_pooler = WeightedLayerPooling(self.model_conf.num_hidden_layers, self.model_conf.initializer_range)\n",
        "            self.attn_pooler = AttentionPooling(self.model_conf.hidden_size)\n",
        "            for attn_module in self.attn_pooler.modules():\n",
        "                self._init_weights(attn_module)\n",
        "                \n",
        "        elif self.pooling_strategy == 'concat_h_attn_mean_pooling':\n",
        "            self.hattn_pooler = HiddenAttentionPooling(self.model_conf.num_hidden_layers, self.model_conf.hidden_size, self.model_conf.hidden_size)\n",
        "            self.mean_pooler = MeanPooling()\n",
        "\n",
        "        elif self.pooling_strategy == 'concat_attn_mean_pooling':\n",
        "            self.attn_pooler = AttentionPooling(self.model_conf.hidden_size)\n",
        "            for attn_module in self.attn_pooler.modules():\n",
        "                self._init_weights(attn_module)\n",
        "            self.mean_pooler = MeanPooling()\n",
        "            \n",
        "        else:\n",
        "            raise Exception('Invalid pooling strategy')\n",
        "\n",
        "        if self.pooling_strategy in ['mean_pooling', 'attn_pooling', 'wlp_attn_pooling']:\n",
        "            hidden_size = self.model_conf.hidden_size\n",
        "        elif self.pooling_strategy in ['concat_pooling']:\n",
        "            hidden_size = self.model_conf.hidenn_size * conf.concat_pooling_last\n",
        "        elif self.pooling_strategy in ['concat_h_attn_mean_pooling', 'concat_attn_mean_pooling']:\n",
        "            hidden_size = self.model_conf.hidden_size * 2\n",
        "        else:\n",
        "            raise Exception('Cannot create fc layer.')\n",
        "            \n",
        "        self.multi_dropout = conf.multi_dropout\n",
        "        if self.multi_dropout:\n",
        "            self.dropout1 = nn.Dropout(conf.multi_dropout_p[0])\n",
        "            self.dropout2 = nn.Dropout(conf.multi_dropout_p[1])\n",
        "            self.dropout3 = nn.Dropout(conf.multi_dropout_p[2])\n",
        "            self.dropout4 = nn.Dropout(conf.multi_dropout_p[3])\n",
        "            self.dropout5 = nn.Dropout(conf.multi_dropout_p[4])\n",
        "        else:\n",
        "            self.dropout0 = nn.Dropout(0.1)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, conf.num_labels)\n",
        "        if conf.reinit_method is not None:\n",
        "            self._init_weights2_([self.fc], conf.reinit_method)\n",
        "        else:\n",
        "            self._init_weights(self.fc)\n",
        "\n",
        "        self.use_ln = conf.use_ln\n",
        "        if self.use_ln:\n",
        "            self.ln = nn.LayerNorm(hidden_size)\n",
        "            self._init_weights(self.ln)\n",
        "        \n",
        "    def _set_dropout(self, conf, ratio=0.):\n",
        "        conf.attention_probs_dropout_prob = ratio\n",
        "        conf.hidden_dropout = ratio \n",
        "        conf.hidden_dropout_prob = ratio\n",
        "        conf.pooler_dropout = ratio\n",
        "        return conf\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "    \n",
        "    def _init_weights2_(self, module_lst, method):\n",
        "        for module in module_lst:\n",
        "            for param in module.parameters():\n",
        "                if param.dim() > 1:\n",
        "                    if method == 'kaiming_normal':\n",
        "                        nn.init.kaiming_normal_(param)\n",
        "                    elif method == 'xavier_normal':\n",
        "                        nn.init.xavier_normal_(param)\n",
        "                    elif method == 'orthoganol':\n",
        "                        nn.init.orthogonal_(param)\n",
        "                    else:\n",
        "                        raise Exception('The method is invalid')\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        backbone_outputs = self.backbone(**inputs)\n",
        "        if self.pooling_strategy == 'mean_pooling':\n",
        "            last_hidden_states = backbone_outputs['last_hidden_state']\n",
        "            pooler_outputs = self.pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            \n",
        "        elif self.pooling_strategy == 'concat_pooling':\n",
        "            all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
        "            pooler_outputs = self.pooler(all_hidden_states)\n",
        "            \n",
        "        elif self.pooling_strategy == 'attn_pooling':\n",
        "            last_hidden_states = backbone_outputs['last_hidden_state']\n",
        "            pooler_outputs = self.attn_pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            \n",
        "        elif self.pooling_strategy == 'wlp_attn_pooling':\n",
        "            all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
        "            wlp_pooler = self.wlp_pooler(all_hidden_states)\n",
        "            pooler_outputs = self.attn_pooler(wlp_pooler, inputs['attention_mask'])\n",
        "            \n",
        "        elif self.pooling_strategy == 'concat_h_attn_mean_pooling':\n",
        "            last_hidden_states = backbone_outputs['last_hidden_state']\n",
        "            all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
        "            hattn_outputs = self.hattn_pooler(all_hidden_states)\n",
        "            mean_outputs = self.mean_pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            pooler_outputs = torch.cat((hattn_outputs, mean_outputs), -1)\n",
        "            \n",
        "        elif self.pooling_strategy == 'concat_attn_mean_pooling':\n",
        "            last_hidden_states = backbone_outputs['last_hidden_state']\n",
        "            attn_outputs = self.attn_pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            mean_outputs = self.mean_pooler(last_hidden_states, inputs['attention_mask'])\n",
        "            pooler_outputs = torch.cat((attn_outputs, mean_outputs), -1)\n",
        "            \n",
        "        if self.use_ln:\n",
        "            pooler_outputs = self.ln(pooler_outputs)\n",
        "            \n",
        "        if self.multi_dropout:\n",
        "            x1 = self.fc(self.dropout1(pooler_outputs))\n",
        "            x2 = self.fc(self.dropout2(pooler_outputs))\n",
        "            x3 = self.fc(self.dropout3(pooler_outputs))\n",
        "            x4 = self.fc(self.dropout4(pooler_outputs))\n",
        "            x5 = self.fc(self.dropout5(pooler_outputs))\n",
        "            \n",
        "            outputs = (x1 + x2 + x3 + x4 + x5) / 5\n",
        "\n",
        "        else:\n",
        "            outputs = self.fc(self.dropout0(pooler_outputs))\n",
        "            \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "071b02f8",
      "metadata": {
        "papermill": {
          "duration": 0.00698,
          "end_time": "2022-11-23T13:43:17.332412",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.325432",
          "status": "completed"
        },
        "tags": [],
        "id": "071b02f8"
      },
      "source": [
        "## Adversial Learning Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d42414",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.349361Z",
          "iopub.status.busy": "2022-11-23T13:43:17.347713Z",
          "iopub.status.idle": "2022-11-23T13:43:17.361701Z",
          "shell.execute_reply": "2022-11-23T13:43:17.360906Z"
        },
        "papermill": {
          "duration": 0.024059,
          "end_time": "2022-11-23T13:43:17.363603",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.339544",
          "status": "completed"
        },
        "tags": [],
        "id": "a4d42414"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/wht1996/feedback-nn-train/notebook\n",
        "class AWP:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        adv_param=\"weight\",\n",
        "        adv_lr=1,\n",
        "        adv_eps=0.2,\n",
        "        adv_step=1,\n",
        "        scaler=None,\n",
        "        apex=False,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.adv_param = adv_param\n",
        "        self.adv_lr = adv_lr\n",
        "        self.adv_eps = adv_eps\n",
        "        self.adv_step = adv_step\n",
        "        self.backup = {}\n",
        "        self.backup_eps = {}\n",
        "        self.scaler = scaler\n",
        "        self.apex = apex\n",
        "\n",
        "    def attack_backward(self, inputs, labels):\n",
        "        self._save() \n",
        "        for i in range(self.adv_step):\n",
        "            self._attack_step() \n",
        "            with torch.cuda.amp.autocast(enabled=self.apex):\n",
        "                adv_outputs = self.model(inputs)\n",
        "                adv_loss = self.criterion(adv_outputs, labels)\n",
        "                adv_loss = adv_loss.mean()\n",
        "            self.optimizer.zero_grad()\n",
        "            self.scaler.scale(adv_loss).backward()\n",
        "            \n",
        "        self._restore()\n",
        "\n",
        "    def _attack_step(self):\n",
        "        e = 1e-6\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
        "                norm1 = torch.norm(param.grad)\n",
        "                norm2 = torch.norm(param.data.detach())\n",
        "                if norm1 != 0 and not torch.isnan(norm1):\n",
        "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
        "                    param.data.add_(r_at)\n",
        "                    param.data = torch.min(\n",
        "                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n",
        "                    )\n",
        "                # param.data.clamp_(*self.backup_eps[name])\n",
        "\n",
        "    def _save(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
        "                if name not in self.backup:\n",
        "                    self.backup[name] = param.data.clone()\n",
        "                    grad_eps = self.adv_eps * param.abs().detach()\n",
        "                    self.backup_eps[name] = (\n",
        "                        self.backup[name] - grad_eps,\n",
        "                        self.backup[name] + grad_eps,\n",
        "                    )\n",
        "\n",
        "    def _restore(self,):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if name in self.backup:\n",
        "                param.data = self.backup[name]\n",
        "        self.backup = {}\n",
        "        self.backup_eps = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed0b507b",
      "metadata": {
        "papermill": {
          "duration": 0.006958,
          "end_time": "2022-11-23T13:43:17.377778",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.370820",
          "status": "completed"
        },
        "tags": [],
        "id": "ed0b507b"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b5387b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.393151Z",
          "iopub.status.busy": "2022-11-23T13:43:17.392898Z",
          "iopub.status.idle": "2022-11-23T13:43:17.397991Z",
          "shell.execute_reply": "2022-11-23T13:43:17.397017Z"
        },
        "papermill": {
          "duration": 0.015018,
          "end_time": "2022-11-23T13:43:17.399966",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.384948",
          "status": "completed"
        },
        "tags": [],
        "id": "16b5387b"
      },
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.__name__ = self.__class__.__name__\n",
        "    \n",
        "    def forward(self, y_pred, y_true):\n",
        "        return torch.sqrt(self.mse(y_pred, y_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfbf6d50",
      "metadata": {
        "papermill": {
          "duration": 0.007027,
          "end_time": "2022-11-23T13:43:17.414101",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.407074",
          "status": "completed"
        },
        "tags": [],
        "id": "bfbf6d50"
      },
      "source": [
        "# Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f6f617",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.429412Z",
          "iopub.status.busy": "2022-11-23T13:43:17.429135Z",
          "iopub.status.idle": "2022-11-23T13:43:17.435964Z",
          "shell.execute_reply": "2022-11-23T13:43:17.435093Z"
        },
        "papermill": {
          "duration": 0.016759,
          "end_time": "2022-11-23T13:43:17.437968",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.421209",
          "status": "completed"
        },
        "tags": [],
        "id": "90f6f617"
      },
      "outputs": [],
      "source": [
        "# https://realpython.com/python-timer/\n",
        "class TimerError(Exception):\n",
        "    \"\"\"A custom exception used to report errors in use of Timer class\"\"\"\n",
        "\n",
        "class Timer:\n",
        "    def __init__(self):\n",
        "        self._start_time = None\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start a new timer\"\"\"\n",
        "        if self._start_time is not None:\n",
        "            raise TimerError(f\"Timer is running. Use .stop() to stop it\")\n",
        "\n",
        "        self._start_time = time.perf_counter()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer, and report the elapsed time\"\"\"\n",
        "        if self._start_time is None:\n",
        "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
        "            \n",
        "        self._start_time = None\n",
        "    \n",
        "    def get_time(self):\n",
        "        if self._start_time is None:\n",
        "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
        "            \n",
        "        return time.perf_counter() - self._start_time\n",
        "    \n",
        "    @staticmethod\n",
        "    def formatting(second):\n",
        "        return str(datetime.timedelta(seconds=round(second)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96731d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.453484Z",
          "iopub.status.busy": "2022-11-23T13:43:17.453201Z",
          "iopub.status.idle": "2022-11-23T13:43:17.459281Z",
          "shell.execute_reply": "2022-11-23T13:43:17.458285Z"
        },
        "papermill": {
          "duration": 0.016413,
          "end_time": "2022-11-23T13:43:17.461522",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.445109",
          "status": "completed"
        },
        "tags": [],
        "id": "d96731d6"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train/notebook\n",
        "class Averager:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "        \n",
        "    def get_average(self):\n",
        "        return self.avg\n",
        "    \n",
        "    def get_value(self):\n",
        "        return self.val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e9a5e75",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.476943Z",
          "iopub.status.busy": "2022-11-23T13:43:17.476689Z",
          "iopub.status.idle": "2022-11-23T13:43:17.483081Z",
          "shell.execute_reply": "2022-11-23T13:43:17.482217Z"
        },
        "papermill": {
          "duration": 0.016408,
          "end_time": "2022-11-23T13:43:17.485058",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.468650",
          "status": "completed"
        },
        "tags": [],
        "id": "1e9a5e75"
      },
      "outputs": [],
      "source": [
        "class ModelWeightAverager:\n",
        "    def __init__(self, conf, fold):\n",
        "        self.conf = conf\n",
        "        self.fold = fold\n",
        "        self.state_dict_list = []\n",
        "    \n",
        "    def add_state_dict(self, state_dict):\n",
        "        self.state_dict_list.append(state_dict)\n",
        "        \n",
        "    def average_state_dict(self):\n",
        "        master_sd = CustomModel(self.conf, self.fold).state_dict()\n",
        "        for key in master_sd:\n",
        "            master_sd[key] = 0\n",
        "            for state_dict in self.state_dict_list:\n",
        "                master_sd[key] += state_dict[key]\n",
        "            master_sd[key] = master_sd[key] / len(self.state_dict_list)\n",
        "        \n",
        "        torch.save({\n",
        "            'model_state_dict': master_sd,\n",
        "        },\n",
        "            Path(self.conf.save_path, f'best-epoch-fold{self.fold}-swa.pt'))\n",
        "        \n",
        "        print(f'SAVED FOLD{self.fold}_M_SWA)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364b9865",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.500764Z",
          "iopub.status.busy": "2022-11-23T13:43:17.500505Z",
          "iopub.status.idle": "2022-11-23T13:43:17.524155Z",
          "shell.execute_reply": "2022-11-23T13:43:17.523229Z"
        },
        "papermill": {
          "duration": 0.034015,
          "end_time": "2022-11-23T13:43:17.526136",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.492121",
          "status": "completed"
        },
        "tags": [],
        "id": "364b9865"
      },
      "outputs": [],
      "source": [
        "# optimize padding size\n",
        "# https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train/notebook\n",
        "def collator(inputs):\n",
        "    mask_len = int(inputs['attention_mask'].sum(axis=1).max())\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = inputs[k][:, :mask_len]\n",
        "    return inputs\n",
        "\n",
        "def get_dataloader(conf, df, tokenizer, fold_num):\n",
        "    \n",
        "    train_dataset = FB3Dataset(conf, df[df['fold'] != fold_num], tokenizer, fold_num)\n",
        "    valid_dataset = FB3Dataset(conf, df[df['fold'] == fold_num], tokenizer, fold_num)\n",
        "    \n",
        "    total_train_samples = len(train_dataset)\n",
        "    \n",
        "#     data_collator = DataCollatorWithPadding(tokenizer, padding='longest', return_tensors=None)\n",
        "    \n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=conf.num_batch,\n",
        "#         collate_fn=data_collator,\n",
        "        num_workers=4,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    \n",
        "    valid_dataloader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=conf.num_batch,\n",
        "#         collate_fn=data_collator,\n",
        "        num_workers=4,\n",
        "        shuffle=False,\n",
        "        pin_memory=True,\n",
        "        drop_last=False\n",
        "    )\n",
        "    \n",
        "    return train_dataloader, valid_dataloader, total_train_samples\n",
        "\n",
        "def get_model(conf, fold_num):\n",
        "    model = CustomModel(conf, fold_num)\n",
        "    model_config_file = Path(conf.save_path, Path(conf.model_name).name + '_config.pt')\n",
        "    \n",
        "    # save model config file\n",
        "    if not model_config_file.is_file():\n",
        "        torch.save(model.model_conf, model_config_file)\n",
        "        \n",
        "    return model\n",
        "\n",
        "def get_tokenizer(conf):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(conf.model_name)\n",
        "    tokenizer_file = Path(conf.save_path, 'tokenizers/')\n",
        "    \n",
        "    if not tokenizer_file.is_file():\n",
        "        tokenizer.save_pretrained(tokenizer_file) # save tokenizer vocab\n",
        "        \n",
        "    return tokenizer\n",
        "\n",
        "def get_optimizer(conf):\n",
        "    optimizer_dict = {\n",
        "        'adamw': optim.AdamW,\n",
        "    }\n",
        "    return optimizer_dict[conf.optimizer]\n",
        "\n",
        "def get_optimizer_grouped_params(model, bb_lr, ll_lr, weight_decay=0.01, layerwise_learning_rate_decay=0.9):\n",
        "    # turn off weight decay in some layer\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if 'backbone' not in n],\n",
        "            \"weight_decay\": 0.0,\n",
        "            \"lr\": ll_lr,\n",
        "        },\n",
        "    ]\n",
        "    # layer-wise learning rate decay\n",
        "    layers = [model.backbone.embeddings] + list(model.backbone.encoder.layer)\n",
        "    layers.reverse()\n",
        "    decay_lr = bb_lr\n",
        "    for layer in layers:\n",
        "        decay_lr *= layerwise_learning_rate_decay\n",
        "        optimizer_grouped_parameters += [\n",
        "            {\n",
        "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": weight_decay,\n",
        "                \"lr\": decay_lr,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "                \"lr\": decay_lr,\n",
        "            },\n",
        "        ]\n",
        "    return optimizer_grouped_parameters\n",
        "\n",
        "def get_scheduler(conf, total_samples):\n",
        "    scheduler_dict = {\n",
        "        'cosine_warmup': {\n",
        "            'scheduler': transformers.get_cosine_schedule_with_warmup,\n",
        "            'params': {\n",
        "                'num_warmup_steps': int((total_samples // conf.num_batch) * conf.warmup_epoch),\n",
        "                'num_training_steps': (total_samples // conf.num_batch) * conf.num_epochs,\n",
        "            }\n",
        "        },\n",
        "        'linear_warmup': {\n",
        "            'scheduler': transformers.get_linear_schedule_with_warmup,\n",
        "            'params': {\n",
        "                'num_warmup_steps': int((total_samples // conf.num_batch) * conf.warmup_epoch),\n",
        "                'num_training_steps': (total_samples // conf.num_batch) * conf.num_epochs,\n",
        "            }\n",
        "        },\n",
        "        'cosine_restart_warmup': {\n",
        "            'scheduler': transformers.get_cosine_with_hard_restarts_schedule_with_warmup,\n",
        "            'params': {\n",
        "                'num_warmup_steps':  int((total_samples // conf.num_batch) * conf.warmup_epoch),\n",
        "                'num_training_steps': (total_samples // conf.num_batch) * conf.num_epochs,\n",
        "                'num_cycles': 2,\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "    \n",
        "    return scheduler_dict[conf.scheduler]['scheduler'], scheduler_dict[conf.scheduler]['params']\n",
        "\n",
        "def scores_with_MCRMSE(y_predicteds, y_targets):\n",
        "    cols_score = []\n",
        "    col_wise = y_targets.shape[1]\n",
        "    for col in range(col_wise):\n",
        "        y_predicted = torch.as_tensor(y_predicteds[:, col])\n",
        "        y_target = torch.as_tensor(y_targets[:, col])\n",
        "        rmse = mean_squared_error(y_predicted, y_target, squared=False) # returns RMSE value if set to False\n",
        "        cols_score.append(rmse)\n",
        "    score_mean = torch.mean(torch.as_tensor(cols_score))\n",
        "    return score_mean, cols_score\n",
        "\n",
        "def calculate_fold_mean(conf, df):\n",
        "    bsr_list = []\n",
        "    for i in range(conf.num_folds):\n",
        "        fold = df[df['fold'] == i]\n",
        "        best_score_row = fold.loc[fold['mcrmse'] == fold['mcrmse'].min()]\n",
        "        bsr_list.append(best_score_row)\n",
        "        \n",
        "    cv_df = pd.concat(bsr_list)\n",
        "    cv_mean = cv_df.mean(axis=0)\n",
        "    cv_mean['fold'] = cv_mean['epoch'] = int(99)\n",
        "    cv_mean = cv_mean.to_frame().T\n",
        "    cv_df = pd.concat([cv_df, cv_mean], axis=0)\n",
        "    return cv_df.reset_index(drop=True)\n",
        "\n",
        "def get_oof_df(target_cols, predictions, targets):\n",
        "    oof_df = pd.DataFrame()\n",
        "    oof_df[target_cols] = targets.cpu().numpy()\n",
        "    oof_df[[f'pred_{col}' for col in target_cols]] = predictions.cpu().numpy()\n",
        "    return oof_df\n",
        "\n",
        "def calculate_oof_cv(target_cols, oof_df):\n",
        "    predictions = oof_df[[f'pred_{col}' for col in target_cols]].values\n",
        "    targets = oof_df[target_cols].values\n",
        "    score_mean, cols_score = scores_with_MCRMSE(predictions, targets)\n",
        "    return score_mean, cols_score\n",
        "\n",
        "def export_config(basic, train):\n",
        "    config_dict = {**basic.__dict__, **train.__dict__}\n",
        "    remove_keys_list = ['__module__', '__dict__', '__weakref__', '__doc__']\n",
        "    \n",
        "    for key in remove_keys_list:\n",
        "        config_dict.pop(key)\n",
        "    \n",
        "    with open(Path(train.save_path, 'config.yml'), 'w') as file:\n",
        "        yaml.dump(config_dict, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb6597a",
      "metadata": {
        "papermill": {
          "duration": 0.007073,
          "end_time": "2022-11-23T13:43:17.540402",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.533329",
          "status": "completed"
        },
        "tags": [],
        "id": "9bb6597a"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b48da5a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.556706Z",
          "iopub.status.busy": "2022-11-23T13:43:17.556138Z",
          "iopub.status.idle": "2022-11-23T13:43:17.604096Z",
          "shell.execute_reply": "2022-11-23T13:43:17.603230Z"
        },
        "papermill": {
          "duration": 0.05866,
          "end_time": "2022-11-23T13:43:17.606176",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.547516",
          "status": "completed"
        },
        "tags": [],
        "id": "8b48da5a"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, conf, device, fold, model, optimizer, optimizer_grouped_params, scheduler, scheduler_params):\n",
        "        self.device = device\n",
        "        self.current_fold = fold\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer(optimizer_grouped_params, lr=conf.ll_lr, eps=conf.optim_eps)\n",
        "        self.scheduler = scheduler(self.optimizer, **scheduler_params)\n",
        "        \n",
        "        self.dry_run = conf.dry_run\n",
        "        self.exp = conf.exp\n",
        "\n",
        "        self.model_name = conf.model_name\n",
        "        self.target_cols = conf.target_cols\n",
        "        self.use_apex = conf.use_apex\n",
        "        self.use_awp = conf.use_awp\n",
        "        self.use_swa = conf.use_swa\n",
        "        self.multi_dropout = conf.multi_dropout\n",
        "        self.grad_clip = conf.grad_clip\n",
        "        self.grad_max_norm = conf.grad_max_norm\n",
        "        \n",
        "        self.num_batch = conf.num_batch\n",
        "        self.num_epochs = conf.num_epochs\n",
        "        self.current_epoch = None\n",
        "        self.batch_scheduler = conf.batch_scheduler\n",
        "        self.verbose_step = conf.verbose_step\n",
        "        self.accumulate_step = conf.accumulate_step\n",
        "\n",
        "        self.save_path = conf.save_path\n",
        "        \n",
        "        self.scaler = GradScaler(enabled=self.use_apex)\n",
        "        self.criterion = nn.SmoothL1Loss(beta=conf.loss_beta) # [RMSELoss, SmoothL1Loss]\n",
        "        \n",
        "        self.awp_start_epoch = conf.awp_start_epoch\n",
        "        if self.use_awp:\n",
        "            self.awp = AWP(\n",
        "                model=self.model,\n",
        "                criterion=self.criterion,\n",
        "                optimizer=self.optimizer,\n",
        "                adv_lr=conf.adv_lr,\n",
        "                adv_eps=conf.adv_eps,\n",
        "                scaler=self.scaler,\n",
        "                apex=self.use_apex,\n",
        "            )\n",
        "            \n",
        "        self.swa_start_step_ratio = conf.swa_start_step_ratio\n",
        "        if self.use_swa:\n",
        "            self.swa_model = AveragedModel(self.model)\n",
        "            self.swa_scheduler = SWALR(\n",
        "                self.optimizer,\n",
        "                swa_lr=conf.swa_lr,\n",
        "                anneal_strategy=conf.swa_anneal_strat,\n",
        "            )\n",
        "\n",
        "        self.best_train_loss = torch.tensor(10000) # placeholder\n",
        "        self.best_valid_loss = torch.tensor(10000) # placeholder\n",
        "        self.best_score = torch.tensor(10000) # placeholder\n",
        "        self.best_score_col = [torch.tensor(10000) for i in range(6)] # placeholder\n",
        "        \n",
        "        self.record_cols = [\n",
        "            'fold',\n",
        "            'epoch',\n",
        "            'train_loss',\n",
        "            'valid_loss',\n",
        "            'mcrmse',\n",
        "            'cohesion',\n",
        "            'syntax',\n",
        "            'vocabulary',\n",
        "            'phraseology',\n",
        "            'grammar',\n",
        "            'conventions',\n",
        "        ]\n",
        "        self.record_df = pd.DataFrame(columns=self.record_cols)\n",
        "        \n",
        "        if self.dry_run: \n",
        "            self.log('=============')\n",
        "            self.log('== DRY_RUN ==')\n",
        "            self.log('=============')\n",
        "            \n",
        "\n",
        "        mode = 'EXPERIMENTING_MODE' if self.exp else 'CV_MODE'\n",
        "        current_max_len = 'dynamic_padding' if conf.dynamic_max_len else conf.static_max_len_list[self.current_fold]\n",
        "        current_pooling_strategy = conf.pooling_strategy_list[self.current_fold]\n",
        "        \n",
        "        self.log(f'Date: {datetime.datetime.now(pytz.timezone(\"Asia/Ho_Chi_Minh\") )} (GMT+7)')\n",
        "        self.log(f'Mode: {mode}')\n",
        "        self.log(f'Train_on: {self.device}, (AMP: {self.use_apex}, GradScaler: {self.scaler.is_enabled()})')\n",
        "        self.log(f'Model: {self.model_name}')\n",
        "        self.log(f'Model_config: {self.model.model_conf}')\n",
        "        self.log(f'Pooling_strategy: {current_pooling_strategy}')\n",
        "        self.log(f'Initailzation: {conf.reinit_method}')\n",
        "        self.log(f'AWP: {self.use_awp} (adv_lr: {conf.adv_lr}, adv_eps: {conf.adv_eps}) at epoch {self.awp_start_epoch}')\n",
        "        self.log(f'SWA: {self.use_swa} (swa_lr: {conf.swa_lr}, anneal_strat: {conf.swa_anneal_strat}) at last {conf.swa_start_step_ratio}')\n",
        "        self.log(f'Multi_sample_dropout: {self.multi_dropout} (p: {conf.multi_dropout_p})')\n",
        "        self.log(f'Loss_fn: {str(self.criterion)}')\n",
        "        self.log(f'Optimizer: {optimizer.__name__}')\n",
        "        self.log(f'LR: (Backbone: {conf.bb_lr}, LowerLayer: {conf.ll_lr})')\n",
        "        self.log(f'LR_Scheduler: {scheduler.__name__} {scheduler_params}')\n",
        "        self.log(f'Grad_clip_norm: {self.grad_clip} (max_norm: {self.grad_max_norm})')\n",
        "        self.log(f'Number_of_batches: {self.num_batch} (Gradient_accumulate: {self.accumulate_step})')\n",
        "        self.log(f'max_len: {current_max_len}')\n",
        "        self.log('')\n",
        "        \n",
        "    def fit(self, train_loader, valid_loader):\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.current_epoch = epoch + 1\n",
        "            \n",
        "            timer = Timer()\n",
        "            timer.start()\n",
        "            \n",
        "            self.log('TRAIN_LOOP')\n",
        "            train_loss = self._train_fn(train_loader)\n",
        "            self.log('')\n",
        "            \n",
        "            self.log('VALID_LOOP')\n",
        "            valid_loss, score_mean, cols_score, valid_predictions, valid_targets = self._valid_fn(valid_loader)\n",
        "            self.log('')\n",
        "            \n",
        "            epoch_summary_dict = {\n",
        "                'EPOCH': [f'{self.current_epoch}/{self.num_epochs}'],\n",
        "                'TRAIN_LOSS': [f'{train_loss:.5f}'],\n",
        "                'VALID_LOSS': [f'{valid_loss:.5f}'],\n",
        "                'MCRMSE': [f'{score_mean:.5f}'],\n",
        "                'COLS': [' | '.join([f'{col:.3f}' for col in cols_score])],\n",
        "                'TIME': [Timer.formatting(timer.get_time())],\n",
        "            }\n",
        "            epoch_summary_table = tabulate(epoch_summary_dict, headers='keys', tablefmt=\"github\")\n",
        "            \n",
        "            \n",
        "            self.log('--------------------')\n",
        "            self.log(f'EPOCH: {self.current_epoch}/{self.num_epochs} SUMMARY')\n",
        "            self.log('--------------------')\n",
        "            self.log(epoch_summary_table)\n",
        "            self.log('')\n",
        "            \n",
        "            timer.stop()\n",
        "            \n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            self._compare_and_save(score_mean, cols_score, train_loss, valid_loss, valid_predictions, valid_targets)\n",
        "                \n",
        "            self.record([\n",
        "                self.current_fold,\n",
        "                self.current_epoch,\n",
        "                train_loss.detach().cpu().numpy(),\n",
        "                valid_loss.detach().cpu().numpy(),\n",
        "                score_mean.cpu().numpy(),\n",
        "                *[col.cpu().numpy() for col in cols_score],\n",
        "            ])\n",
        "            \n",
        "            if self.dry_run: break\n",
        "            # end of the loop\n",
        "        \n",
        "        if self.use_swa:\n",
        "            torch.optim.swa_utils.update_bn(train_loader, self.swa_model)\n",
        "\n",
        "        fold_summary_dict = {\n",
        "            'MCRMSE': [f'{self.best_score:.5f}'],\n",
        "            'cohesion': [f'{self.best_score_col[0]:.5f}'],\n",
        "            'syntax': [f'{self.best_score_col[1]:.5f}'],\n",
        "            'vocabulary': [f'{self.best_score_col[2]:.5f}'],\n",
        "            'phraseology': [f'{self.best_score_col[3]:.5f}'],\n",
        "            'grammar': [f'{self.best_score_col[4]:.5f}'],\n",
        "            'conventions': [f'{self.best_score_col[5]:.5f}'],\n",
        "        }\n",
        "        \n",
        "        fold_summary_table = tabulate(fold_summary_dict, headers='keys', tablefmt='simple_grid')\n",
        "        \n",
        "        self.log('')\n",
        "        self.log(('-' * 35) + f' FOLD {self.current_fold} RESULT ' + ('-' * 35))\n",
        "        self.log(fold_summary_table)\n",
        "        self.log('')\n",
        "        self.log(('#' * 35) + f' END OF FOlD {self.current_fold} ' + ('#' * 35))\n",
        "        self.log('')\n",
        "        self.log('')\n",
        "        \n",
        "        return self.record_df, self.oof_df\n",
        "        \n",
        "    def _train_fn(self, train_loader):\n",
        "        self.model.train()\n",
        "        total_loss = Averager()\n",
        "        current_lr = self.scheduler.get_lr()[0] # placeholder\n",
        "        timer = Timer()\n",
        "        timer.start()\n",
        "        if self.use_awp and self.awp_start_epoch <= self.current_epoch: self.log('AWP_ACTIVATED')\n",
        "        \n",
        "        for step, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            inputs = collator(inputs)\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "            labels = labels.to(self.device)\n",
        "            batchsize = len(labels)\n",
        "            \n",
        "            with autocast(enabled=self.use_apex):\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "            if self.accumulate_step > 1:\n",
        "                loss = loss / self.accumulate_step\n",
        "            total_loss.update(loss, batchsize)\n",
        "            \n",
        "            self.scaler.scale(loss).backward()\n",
        "            \n",
        "            if (step + 1) % self.accumulate_step == 0:\n",
        "                if self.use_awp and self.awp_start_epoch <= self.current_epoch:\n",
        "                    self.awp.attack_backward(inputs, labels)\n",
        "                \n",
        "                if self.use_swa:\n",
        "                    swa_start_step = int((self.num_epochs * len(train_loader)) * (1 - self.swa_start_step_ratio))\n",
        "                    current_training_step = int(((self.current_epoch - 1) * len(train_loader)) + step)\n",
        "                    if current_training_step == swa_start_step:\n",
        "                        self.log('SWA_ACTIVATED')\n",
        "                    if current_training_step >= swa_start_step:\n",
        "                        self.swa_model.update_parameters(self.model)\n",
        "                        self.swa_scheduler.step()\n",
        "                        current_lr = self.swa_scheduler.get_last_lr()[0]\n",
        "                    else:\n",
        "                        if self.batch_scheduler:\n",
        "                            self.scheduler.step()\n",
        "                            current_lr = self.scheduler.get_lr()[0]\n",
        "                            \n",
        "                if self.grad_clip:\n",
        "                    self.scaler.unscale_(self.optimizer)\n",
        "                    grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                        parameters=self.model.parameters(),\n",
        "                        max_norm=self.grad_max_norm,\n",
        "                    )\n",
        "\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                self.optimizer.zero_grad()\n",
        "            \n",
        "            if not self.use_swa:\n",
        "                if self.batch_scheduler:\n",
        "                    self.scheduler.step()\n",
        "                    current_lr = self.scheduler.get_lr()[0]\n",
        "            \n",
        "            if step % self.verbose_step == 0 or step == (len(train_loader) - 1):\n",
        "                self.log(\n",
        "                    f'[TRAIN F{self.current_fold}] ' + \\\n",
        "                    f'EPOCH: {self.current_epoch}/{self.num_epochs} | ' + \\\n",
        "                    f'STEP: {str(step).zfill(len(str(len(train_loader))))}/{len(train_loader)} | ' + \\\n",
        "                    f'LOSS: {total_loss.get_value():.5f} ({total_loss.get_average():.5f}) | ' + \\\n",
        "                    f'LR: {current_lr:.8f} | ' + \\\n",
        "                    f'TIME: {Timer.formatting(timer.get_time())} |'\n",
        "                )\n",
        "\n",
        "            if self.dry_run: break\n",
        "            # end of the loop\n",
        "            \n",
        "        timer.stop()\n",
        "\n",
        "        return total_loss.get_average()\n",
        "            \n",
        "    \n",
        "    def _valid_fn(self, valid_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = Averager()\n",
        "        timer = Timer()\n",
        "        timer.start()\n",
        "        outputs_list = [] # for stacking outputs\n",
        "        targets_list = [] # for stacking labels\n",
        "        \n",
        "        for step, (inputs, labels) in enumerate(valid_loader):\n",
        "            \n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "            labels = labels.to(self.device)\n",
        "            batchsize = len(labels)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                \n",
        "            total_loss.update(loss, batchsize)\n",
        "            outputs_list.append(outputs)\n",
        "            targets_list.append(labels)\n",
        "            \n",
        "            if step % self.verbose_step == 0 or step == (len(valid_loader) - 1):\n",
        "                self.log(\n",
        "                    f'[VALID F{self.current_fold}] ' + \\\n",
        "                    f'EPOCH: {self.current_epoch}/{self.num_epochs} | ' + \\\n",
        "                    f'STEP: {str(step).zfill(len(str(len(valid_loader))))}/{len(valid_loader)} | ' + \\\n",
        "                    f'LOSS: {total_loss.get_value():.5f} ({total_loss.get_average():.5f}) | ' + \\\n",
        "                    f'TIME: {Timer.formatting(timer.get_time())} |'\n",
        "                )\n",
        "\n",
        "            if self.dry_run: break\n",
        "            # end of the loop\n",
        "\n",
        "        predictions = torch.cat(outputs_list)\n",
        "        targets = torch.cat(targets_list)\n",
        "\n",
        "        score_mean, cols_score = scores_with_MCRMSE(predictions, targets)\n",
        "        \n",
        "        timer.stop()\n",
        "        \n",
        "        return total_loss.get_average(), score_mean, cols_score, predictions, targets\n",
        "    \n",
        "    def _compare_and_save(self, score, col_score, train_loss, valid_loss, valid_predictions, valid_targets):\n",
        "        if score < self.best_score:\n",
        "            self.best_score = score\n",
        "            self.best_score_col = col_score\n",
        "            self.best_train_loss = train_loss\n",
        "            self.best_valid_loss = valid_loss\n",
        "            \n",
        "            file_name = f'best-epoch-fold{self.current_fold}.pt'\n",
        "            self._save(self.save_path, file_name, last_checkpoint=False)\n",
        "            \n",
        "            self.oof_df = get_oof_df(self.target_cols, valid_predictions, valid_targets)\n",
        "        \n",
        "            self.log('')\n",
        "            self.log(f'[SAVED] EPOCH: {self.current_epoch} | MCRMSE: {self.best_score}')\n",
        "            self.log('')\n",
        "    \n",
        "    def _save(self, save_path, file_name, last_checkpoint=False):\n",
        "        self.model.eval()\n",
        "        if last_checkpoint:\n",
        "            torch.save({\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                'scaler': self.scaler.state_dict(),\n",
        "                'best_train_loss': self.best_train_loss,\n",
        "                'best_valid_loss': self.best_valid_loss,\n",
        "                'best_score': self.best_score,\n",
        "                'epoch': self.current_epoch,\n",
        "            }, Path(save_path, file_name))\n",
        "        else:\n",
        "            torch.save({\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'best_train_loss': self.best_train_loss,\n",
        "                'best_valid_loss': self.best_valid_loss,\n",
        "                'best_score': self.best_score,\n",
        "                'epoch': self.current_epoch,\n",
        "            }, Path(save_path, file_name))\n",
        "            \n",
        "    def log(self, message):\n",
        "        print(message)\n",
        "        if not self.dry_run:\n",
        "            with open(Path(self.save_path, 'log.txt'), mode='a+', encoding='utf-8') as log:\n",
        "                log.write(f'{message}\\n')\n",
        "\n",
        "    def record(self, record_row):\n",
        "        new_record_dict = {k: [v] for k, v in zip(self.record_cols, record_row)}\n",
        "        new_record = pd.DataFrame.from_dict(new_record_dict)\n",
        "        self.record_df = pd.concat([self.record_df, new_record], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a11ed832",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.622682Z",
          "iopub.status.busy": "2022-11-23T13:43:17.622406Z",
          "iopub.status.idle": "2022-11-23T13:43:17.632955Z",
          "shell.execute_reply": "2022-11-23T13:43:17.631972Z"
        },
        "papermill": {
          "duration": 0.021736,
          "end_time": "2022-11-23T13:43:17.635247",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.613511",
          "status": "completed"
        },
        "tags": [],
        "id": "a11ed832"
      },
      "outputs": [],
      "source": [
        "def run_training(pl_train_df_list, conf, dry_run=True, exp=True):\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    \n",
        "    conf.dry_run = dry_run # for debugging\n",
        "    conf.exp = exp # for experimenting train only the first fold\n",
        "    \n",
        "    tokenizer = get_tokenizer(conf)\n",
        "    train_result_df = pd.DataFrame()\n",
        "    oof_df = pd.DataFrame()\n",
        "    \n",
        "    for fold in conf.train_fold_list:\n",
        "        \n",
        "        seed_everything(conf.seed)\n",
        "        pl_fold_df = pl_train_df_list[fold]\n",
        "        model = get_model(conf, fold)\n",
        "        model = model.to(device)\n",
        "        optimizer = get_optimizer(conf)\n",
        "        optimizer_grouped_params = get_optimizer_grouped_params(model, conf.bb_lr, conf.ll_lr, conf.weight_decay, conf.llrd)\n",
        "        train_loader, valid_loader, total_train_samples = get_dataloader(conf, pl_fold_df, tokenizer, fold)\n",
        "        scheduler, scheduler_params = get_scheduler(conf, total_train_samples)\n",
        "\n",
        "        trainer = Trainer(conf, device, fold, model, optimizer, optimizer_grouped_params, scheduler, scheduler_params)\n",
        "        fold_result, fold_oof_df = trainer.fit(train_loader, valid_loader)\n",
        "        train_result_df = pd.concat([train_result_df, fold_result], axis=0)\n",
        "        oof_df = pd.concat((oof_df, fold_oof_df), axis=0)\n",
        "        \n",
        "        if conf.dry_run or conf.exp : break\n",
        "    \n",
        "    cv_result_df = calculate_fold_mean(conf, train_result_df)\n",
        "    oof_score_mean, oof_cols_score = calculate_oof_cv(conf.target_cols, oof_df)\n",
        "    cv_df = pd.DataFrame([[oof_score_mean.numpy(), *[col.numpy() for col in oof_cols_score]]], columns=['mcrmse', *conf.target_cols])\n",
        "    \n",
        "    print('Overall Training Result')\n",
        "    display(train_result_df)\n",
        "    print('Best Result')\n",
        "    display(cv_result_df)\n",
        "    print('CV Result')\n",
        "    display(cv_df)\n",
        "    \n",
        "    train_result_df.reset_index(drop=True).to_csv(Path(conf.save_path, 'train_result.csv'), index=False)\n",
        "    cv_result_df.reset_index(drop=True).to_csv(Path(conf.save_path, 'best_result.csv'), index=False)\n",
        "    cv_df.reset_index(drop=True).to_csv(Path(conf.save_path, 'cv_result.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45353600",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.650729Z",
          "iopub.status.busy": "2022-11-23T13:43:17.650476Z",
          "iopub.status.idle": "2022-11-23T13:43:17.734129Z",
          "shell.execute_reply": "2022-11-23T13:43:17.733233Z"
        },
        "papermill": {
          "duration": 0.093781,
          "end_time": "2022-11-23T13:43:17.736312",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.642531",
          "status": "completed"
        },
        "tags": [],
        "id": "45353600"
      },
      "outputs": [],
      "source": [
        "class TRAINCONF(BASICCONF):\n",
        "    \n",
        "    # general config\n",
        "    exp_num = '64s42pretrained'\n",
        "    save_path = f'/content/drive/MyDrive/Colab Notebooks/kaggle/fb3/results/exp{exp_num}'\n",
        "\n",
        "    # run config\n",
        "    dry_run = True # for debugging\n",
        "    exp = True # for experimenting\n",
        "    train_fold_list = [0, 1, 2, 3]\n",
        "    \n",
        "    # dataset config\n",
        "    dynamic_max_len = False\n",
        "    static_max_len_list = [768, 768, 768, 768] # if dynaimic_padding is False: then use static_max_len_list instead\n",
        "    # [1428, 1428, 1428, 1428] default max_len for 4 fold\n",
        "    \n",
        "    # model config\n",
        "    model_name = 'microsoft/deberta-v3-base' # [xsmall, small, base, large, xlarge]\n",
        "    reinit_last_layers = 1 # from the bottom (no need to set negative value).\n",
        "    reinit_method = None # [kaiming_normal, xavier_normal, orthoganol, None] # if None: initialize by  normal dist\n",
        "    gradient_checkpointing = True\n",
        "    \n",
        "    use_awp = True\n",
        "    awp_start_epoch = 1\n",
        "    adv_lr = 2e-5\n",
        "    adv_eps = 1e-3\n",
        "    \n",
        "    use_swa = False\n",
        "    swa_start_step_ratio = 0.112 #tart from last n% of the training step # 0.112(1300)\n",
        "    swa_lr = 1e-6\n",
        "    swa_anneal_strat = 'cos' # ['cos', 'linear']\n",
        "    \n",
        "    pooling_strategy_list = [\n",
        "        'concat_attn_mean_pooling',\n",
        "        'concat_attn_mean_pooling',\n",
        "        'concat_attn_mean_pooling',\n",
        "        'concat_attn_mean_pooling',\n",
        "    ]\n",
        "    \n",
        "    # [\n",
        "    #     mean_pooling,\n",
        "    #     concat_pooling,\n",
        "    #     attn_pooling,\n",
        "    #     wlp_attn_pooling,\n",
        "    #     concat_h_attn_mean_pooling,\n",
        "    #     concat_attn_mean_pooling,\n",
        "    # ]\n",
        "    \n",
        "    wlp_pooling_start = 0 # for weighted layer pooling (n from the top)\n",
        "    concat_pooling_last = 4 # for concatenate pooling (n from the bottom)\n",
        "    \n",
        "    use_ln = False\n",
        "\n",
        "    multi_dropout = True\n",
        "    multi_dropout_p = [0.3, 0.3, 0.3, 0.3, 0.3]\n",
        "    \n",
        "    # trainer config\n",
        "    use_apex = torch.cuda.is_available()\n",
        "    verbose_step = 40\n",
        "    num_epochs = 1\n",
        "    num_batch = 8\n",
        "    accumulate_step = 1\n",
        "    \n",
        "    # optimizer config\n",
        "    optimizer = 'adamw'\n",
        "    bb_lr = 2e-5 # backbone lr\n",
        "    ll_lr = 3e-5 # lowerlayer lr\n",
        "    \n",
        "    weight_decay = 0.01\n",
        "    llrd = 0.9\n",
        "    optim_eps = 1e-6\n",
        "    \n",
        "    batch_scheduler = True\n",
        "    scheduler = 'cosine_warmup' # [cosine_warmup, linear_warmup, consine_restart_warmup]\n",
        "    warmup_epoch = 0.25 # first n of the first epoch\n",
        "    \n",
        "    grad_clip = False\n",
        "    grad_max_norm = 10\n",
        "    \n",
        "    # loss_fn config\n",
        "    loss_beta = 1.0\n",
        "    \n",
        "    is_pl = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_or_create(path):\n",
        "    path = Path(path)\n",
        "    if not path.is_dir():\n",
        "        path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "bP_CyukWIf1k"
      },
      "id": "bP_CyukWIf1k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fe0619e5",
      "metadata": {
        "papermill": {
          "duration": 0.007085,
          "end_time": "2022-11-23T13:43:17.750872",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.743787",
          "status": "completed"
        },
        "tags": [],
        "id": "fe0619e5"
      },
      "source": [
        "# RUN TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a8e494e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T13:43:17.766798Z",
          "iopub.status.busy": "2022-11-23T13:43:17.766522Z",
          "iopub.status.idle": "2022-11-23T14:57:34.556004Z",
          "shell.execute_reply": "2022-11-23T14:57:34.554754Z"
        },
        "papermill": {
          "duration": 4456.80074,
          "end_time": "2022-11-23T14:57:34.558746",
          "exception": false,
          "start_time": "2022-11-23T13:43:17.758006",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "de28e755acd742ce944be5e2bc4f66f9",
            "c9675e3907bb49f58217d99bbe143ff5",
            "b3f20624c7b34d4bbc30e983b01022cd",
            "1adda1f6dd834017a61e23ae47903bfe",
            "a9b4fbb807514e54b9fbd06be366486a",
            "0ec52a74cfe9420fbd7c6bb2327279c3",
            "881c83965e1c444eb8eeb354dddae146",
            "8356bf7aecdf44beb51bb76c6460aa8e",
            "4b73dc94bab74770928b031febe0cf91",
            "15387110215b46e18cecd7590c7e80d2",
            "0fcf7a3686904880ab6334d728e9e534",
            "1308a6360c3c455a855165a6ff3b179b",
            "b04814bb00584b55ae03dd31b2e3a8a9",
            "6cdc64cf80b2430da2b903bd3f646eca",
            "464fb5b3762e41738d422247997264a6",
            "2742fb365b47443c9567e1f6f60d8e10",
            "37e17bb8d8e34a37b15e242e2633ab13",
            "7d3d4bbddc614e029e575deba4b5dac2",
            "687790dfe19e45d5a8131b7e37a8056a",
            "f02d8ffe2e1547b7b6eba09fa69e14e1",
            "e382e9dc27b34209926a2715dd1f43ec",
            "5f9fb1f6f4fd4725b0275cd83d1662f3",
            "4f5150f7fdc74ce7a0b2e94546912291",
            "08decec3f0b2455eb3a65b41c1021bf8",
            "0c8e3932bcca4de8b5c91dcef0f876ee",
            "2a5b2946f0fa414f9f58178837009dd2",
            "118b89976b1048c1a6d4be13d7d76920",
            "eaaf7b4a089d45ca9f33adb54501034d",
            "4c02a2d0a6ec4f6294147b5968a6877e",
            "06c2358574524e83b7f89458495451de",
            "db14b3a8361547f482821725387ee508",
            "5c9cfb8a52ee46d1b5473ba2f2a48a1b",
            "83962c357e8b4c0ab7c241b224bf5301",
            "b941085531bf40e39c4e676132d9ec4c",
            "999f632b466a41a2bd1926ab95c51445",
            "eb0d48c09001474bb9f52a91a8e676c6",
            "e7626076a0fc4ba090593872ab62047f",
            "3ca01bac164948009fdab1def54f19eb",
            "9ca1738e9e93450983a0928e70dfe238",
            "8da4cdc224b14e0e80b9fab01c19b0b6",
            "b7608a328e42482986d360ec37e7f2bd",
            "5d74aad908314d19b93b7bbf99223c51",
            "ee0fa5103e084c5cb784b050e8c49264",
            "ec7e86de1a6c4facb0d0c893efb11bfd"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9a8e494e",
        "outputId": "3e55ff7c-f3f5-4f4f-c435-caaa28b25b1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de28e755acd742ce944be5e2bc4f66f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1308a6360c3c455a855165a6ff3b179b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f5150f7fdc74ce7a0b2e94546912291"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b941085531bf40e39c4e676132d9ec4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date: 2022-11-26 20:32:00.439964+07:00 (GMT+7)\n",
            "Mode: CV_MODE\n",
            "Train_on: cuda, (AMP: True, GradScaler: True)\n",
            "Model: microsoft/deberta-v3-base\n",
            "Model_config: DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0.0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Pooling_strategy: concat_attn_mean_pooling\n",
            "Initailzation: None\n",
            "AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1\n",
            "SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112\n",
            "Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])\n",
            "Loss_fn: SmoothL1Loss()\n",
            "Optimizer: AdamW\n",
            "LR: (Backbone: 2e-05, LowerLayer: 3e-05)\n",
            "LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 91, 'num_training_steps': 364}\n",
            "Grad_clip_norm: False (max_norm: 10)\n",
            "Number_of_batches: 8 (Gradient_accumulate: 1)\n",
            "max_len: 768\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 000/364 | LOSS: 2.87902 (2.87902) | LR: 0.00000033 | TIME: 0:00:03 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 040/364 | LOSS: 0.29788 (2.26986) | LR: 0.00001352 | TIME: 0:01:55 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 080/364 | LOSS: 0.09716 (1.23018) | LR: 0.00002670 | TIME: 0:03:49 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 120/364 | LOSS: 0.04660 (0.84644) | LR: 0.00002911 | TIME: 0:05:38 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 160/364 | LOSS: 0.01204 (0.64328) | LR: 0.00002539 | TIME: 0:07:29 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 200/364 | LOSS: 0.02485 (0.52068) | LR: 0.00001950 | TIME: 0:09:28 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 240/364 | LOSS: 0.02639 (0.43772) | LR: 0.00001268 | TIME: 0:11:18 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 280/364 | LOSS: 0.01524 (0.37782) | LR: 0.00000634 | TIME: 0:13:13 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 320/364 | LOSS: 0.01978 (0.33272) | LR: 0.00000180 | TIME: 0:15:08 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 360/364 | LOSS: 0.01701 (0.29764) | LR: 0.00000001 | TIME: 0:17:04 |\n",
            "[TRAIN F0] EPOCH: 1/1 | STEP: 363/364 | LOSS: 0.01198 (0.29531) | LR: 0.00000000 | TIME: 0:17:12 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F0] EPOCH: 1/1 | STEP: 000/122 | LOSS: 0.00765 (0.00765) | TIME: 0:00:01 |\n",
            "[VALID F0] EPOCH: 1/1 | STEP: 040/122 | LOSS: 0.00997 (0.00677) | TIME: 0:00:33 |\n",
            "[VALID F0] EPOCH: 1/1 | STEP: 080/122 | LOSS: 0.00470 (0.00653) | TIME: 0:01:04 |\n",
            "[VALID F0] EPOCH: 1/1 | STEP: 120/122 | LOSS: 0.00624 (0.00643) | TIME: 0:01:35 |\n",
            "[VALID F0] EPOCH: 1/1 | STEP: 121/122 | LOSS: 0.00980 (0.00645) | TIME: 0:01:36 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 1/1 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 1/1     |      0.29531 |      0.00645 |  0.11335 | 0.117 | 0.106 | 0.112 | 0.105 | 0.126 | 0.114 | 0:18:48 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 1 | MCRMSE: 0.11335483938455582\n",
            "\n",
            "\n",
            "----------------------------------- FOLD 0 RESULT -----------------------------------\n",
            "  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions\n",
            "--------  ----------  --------  ------------  -------------  ---------  -------------\n",
            " 0.11335     0.11728   0.10614       0.11166        0.10521    0.12605        0.11379\n",
            "\n",
            "################################### END OF FOlD 0 ###################################\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date: 2022-11-26 20:50:56.503354+07:00 (GMT+7)\n",
            "Mode: CV_MODE\n",
            "Train_on: cuda, (AMP: True, GradScaler: True)\n",
            "Model: microsoft/deberta-v3-base\n",
            "Model_config: DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0.0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Pooling_strategy: concat_attn_mean_pooling\n",
            "Initailzation: None\n",
            "AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1\n",
            "SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112\n",
            "Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])\n",
            "Loss_fn: SmoothL1Loss()\n",
            "Optimizer: AdamW\n",
            "LR: (Backbone: 2e-05, LowerLayer: 3e-05)\n",
            "LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 91, 'num_training_steps': 364}\n",
            "Grad_clip_norm: False (max_norm: 10)\n",
            "Number_of_batches: 8 (Gradient_accumulate: 1)\n",
            "max_len: 768\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 000/364 | LOSS: 3.33501 (3.33501) | LR: 0.00000033 | TIME: 0:00:03 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 040/364 | LOSS: 0.29412 (2.28276) | LR: 0.00001352 | TIME: 0:01:56 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 080/364 | LOSS: 0.07251 (1.23315) | LR: 0.00002670 | TIME: 0:03:53 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 120/364 | LOSS: 0.02691 (0.84364) | LR: 0.00002911 | TIME: 0:05:47 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 160/364 | LOSS: 0.02633 (0.64039) | LR: 0.00002539 | TIME: 0:07:37 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 200/364 | LOSS: 0.03068 (0.51764) | LR: 0.00001950 | TIME: 0:09:31 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 240/364 | LOSS: 0.02334 (0.43510) | LR: 0.00001268 | TIME: 0:11:25 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 280/364 | LOSS: 0.02669 (0.37564) | LR: 0.00000634 | TIME: 0:13:17 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 320/364 | LOSS: 0.01905 (0.33090) | LR: 0.00000180 | TIME: 0:15:09 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 360/364 | LOSS: 0.01895 (0.29611) | LR: 0.00000001 | TIME: 0:17:05 |\n",
            "[TRAIN F1] EPOCH: 1/1 | STEP: 363/364 | LOSS: 0.01078 (0.29379) | LR: 0.00000000 | TIME: 0:17:13 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F1] EPOCH: 1/1 | STEP: 000/122 | LOSS: 0.00518 (0.00518) | TIME: 0:00:01 |\n",
            "[VALID F1] EPOCH: 1/1 | STEP: 040/122 | LOSS: 0.00439 (0.00546) | TIME: 0:00:32 |\n",
            "[VALID F1] EPOCH: 1/1 | STEP: 080/122 | LOSS: 0.00506 (0.00594) | TIME: 0:01:02 |\n",
            "[VALID F1] EPOCH: 1/1 | STEP: 120/122 | LOSS: 0.00865 (0.00579) | TIME: 0:01:33 |\n",
            "[VALID F1] EPOCH: 1/1 | STEP: 121/122 | LOSS: 0.00547 (0.00579) | TIME: 0:01:33 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 1/1 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 1/1     |      0.29379 |      0.00579 |  0.10744 | 0.109 | 0.105 | 0.114 | 0.098 | 0.113 | 0.106 | 0:18:47 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 1 | MCRMSE: 0.10743946582078934\n",
            "\n",
            "\n",
            "----------------------------------- FOLD 1 RESULT -----------------------------------\n",
            "  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions\n",
            "--------  ----------  --------  ------------  -------------  ---------  -------------\n",
            " 0.10744       0.109   0.10488       0.11388        0.09764     0.1133        0.10593\n",
            "\n",
            "################################### END OF FOlD 1 ###################################\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date: 2022-11-26 21:09:50.683978+07:00 (GMT+7)\n",
            "Mode: CV_MODE\n",
            "Train_on: cuda, (AMP: True, GradScaler: True)\n",
            "Model: microsoft/deberta-v3-base\n",
            "Model_config: DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0.0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Pooling_strategy: concat_attn_mean_pooling\n",
            "Initailzation: None\n",
            "AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1\n",
            "SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112\n",
            "Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])\n",
            "Loss_fn: SmoothL1Loss()\n",
            "Optimizer: AdamW\n",
            "LR: (Backbone: 2e-05, LowerLayer: 3e-05)\n",
            "LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 91, 'num_training_steps': 364}\n",
            "Grad_clip_norm: False (max_norm: 10)\n",
            "Number_of_batches: 8 (Gradient_accumulate: 1)\n",
            "max_len: 768\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 000/364 | LOSS: 2.55465 (2.55465) | LR: 0.00000033 | TIME: 0:00:04 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 040/364 | LOSS: 0.56751 (2.26057) | LR: 0.00001352 | TIME: 0:01:57 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 080/364 | LOSS: 0.09555 (1.21795) | LR: 0.00002670 | TIME: 0:03:46 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 120/364 | LOSS: 0.02391 (0.83162) | LR: 0.00002911 | TIME: 0:05:47 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 160/364 | LOSS: 0.01376 (0.63200) | LR: 0.00002539 | TIME: 0:07:38 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 200/364 | LOSS: 0.02164 (0.51137) | LR: 0.00001950 | TIME: 0:09:35 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 240/364 | LOSS: 0.02165 (0.42974) | LR: 0.00001268 | TIME: 0:11:30 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 280/364 | LOSS: 0.01373 (0.37091) | LR: 0.00000634 | TIME: 0:13:29 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 320/364 | LOSS: 0.03122 (0.32668) | LR: 0.00000180 | TIME: 0:15:25 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 360/364 | LOSS: 0.01205 (0.29236) | LR: 0.00000001 | TIME: 0:17:26 |\n",
            "[TRAIN F2] EPOCH: 1/1 | STEP: 363/364 | LOSS: 0.01514 (0.29007) | LR: 0.00000000 | TIME: 0:17:35 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F2] EPOCH: 1/1 | STEP: 000/122 | LOSS: 0.00429 (0.00429) | TIME: 0:00:01 |\n",
            "[VALID F2] EPOCH: 1/1 | STEP: 040/122 | LOSS: 0.00520 (0.00607) | TIME: 0:00:32 |\n",
            "[VALID F2] EPOCH: 1/1 | STEP: 080/122 | LOSS: 0.00413 (0.00587) | TIME: 0:01:03 |\n",
            "[VALID F2] EPOCH: 1/1 | STEP: 120/122 | LOSS: 0.00657 (0.00587) | TIME: 0:01:33 |\n",
            "[VALID F2] EPOCH: 1/1 | STEP: 121/122 | LOSS: 0.00288 (0.00585) | TIME: 0:01:34 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 1/1 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 1/1     |      0.29007 |      0.00585 |  0.10792 | 0.108 | 0.104 | 0.110 | 0.098 | 0.123 | 0.105 | 0:19:09 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 1 | MCRMSE: 0.10792417079210281\n",
            "\n",
            "\n",
            "----------------------------------- FOLD 2 RESULT -----------------------------------\n",
            "  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions\n",
            "--------  ----------  --------  ------------  -------------  ---------  -------------\n",
            " 0.10792     0.10811    0.1042       0.10995        0.09772    0.12268        0.10489\n",
            "\n",
            "################################### END OF FOlD 2 ###################################\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date: 2022-11-26 21:29:06.801990+07:00 (GMT+7)\n",
            "Mode: CV_MODE\n",
            "Train_on: cuda, (AMP: True, GradScaler: True)\n",
            "Model: microsoft/deberta-v3-base\n",
            "Model_config: DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0.0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Pooling_strategy: concat_attn_mean_pooling\n",
            "Initailzation: None\n",
            "AWP: True (adv_lr: 2e-05, adv_eps: 0.001) at epoch 1\n",
            "SWA: False (swa_lr: 1e-06, anneal_strat: cos) at last 0.112\n",
            "Multi_sample_dropout: True (p: [0.3, 0.3, 0.3, 0.3, 0.3])\n",
            "Loss_fn: SmoothL1Loss()\n",
            "Optimizer: AdamW\n",
            "LR: (Backbone: 2e-05, LowerLayer: 3e-05)\n",
            "LR_Scheduler: get_cosine_schedule_with_warmup {'num_warmup_steps': 91, 'num_training_steps': 364}\n",
            "Grad_clip_norm: False (max_norm: 10)\n",
            "Number_of_batches: 8 (Gradient_accumulate: 1)\n",
            "max_len: 768\n",
            "\n",
            "TRAIN_LOOP\n",
            "AWP_ACTIVATED\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 000/364 | LOSS: 3.29682 (3.29682) | LR: 0.00000033 | TIME: 0:00:04 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 040/364 | LOSS: 0.45556 (2.29307) | LR: 0.00001352 | TIME: 0:02:01 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 080/364 | LOSS: 0.07842 (1.24374) | LR: 0.00002670 | TIME: 0:04:00 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 120/364 | LOSS: 0.03140 (0.85183) | LR: 0.00002911 | TIME: 0:05:53 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 160/364 | LOSS: 0.02728 (0.64826) | LR: 0.00002539 | TIME: 0:07:47 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 200/364 | LOSS: 0.03327 (0.52415) | LR: 0.00001950 | TIME: 0:09:46 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 240/364 | LOSS: 0.02340 (0.44053) | LR: 0.00001268 | TIME: 0:11:34 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 280/364 | LOSS: 0.01942 (0.38062) | LR: 0.00000634 | TIME: 0:13:30 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 320/364 | LOSS: 0.01645 (0.33537) | LR: 0.00000180 | TIME: 0:15:22 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 360/364 | LOSS: 0.02098 (0.30008) | LR: 0.00000001 | TIME: 0:17:21 |\n",
            "[TRAIN F3] EPOCH: 1/1 | STEP: 363/364 | LOSS: 0.02101 (0.29775) | LR: 0.00000000 | TIME: 0:17:30 |\n",
            "\n",
            "VALID_LOOP\n",
            "[VALID F3] EPOCH: 1/1 | STEP: 000/122 | LOSS: 0.00743 (0.00743) | TIME: 0:00:01 |\n",
            "[VALID F3] EPOCH: 1/1 | STEP: 040/122 | LOSS: 0.01064 (0.00703) | TIME: 0:00:32 |\n",
            "[VALID F3] EPOCH: 1/1 | STEP: 080/122 | LOSS: 0.00628 (0.00702) | TIME: 0:01:02 |\n",
            "[VALID F3] EPOCH: 1/1 | STEP: 120/122 | LOSS: 0.00996 (0.00675) | TIME: 0:01:33 |\n",
            "[VALID F3] EPOCH: 1/1 | STEP: 121/122 | LOSS: 0.00574 (0.00675) | TIME: 0:01:34 |\n",
            "\n",
            "--------------------\n",
            "EPOCH: 1/1 SUMMARY\n",
            "--------------------\n",
            "| EPOCH   |   TRAIN_LOSS |   VALID_LOSS |   MCRMSE | COLS                                          | TIME    |\n",
            "|---------|--------------|--------------|----------|-----------------------------------------------|---------|\n",
            "| 1/1     |      0.29775 |      0.00675 |  0.11615 | 0.120 | 0.118 | 0.112 | 0.114 | 0.118 | 0.116 | 0:19:04 |\n",
            "\n",
            "\n",
            "[SAVED] EPOCH: 1 | MCRMSE: 0.11615010350942612\n",
            "\n",
            "\n",
            "----------------------------------- FOLD 3 RESULT -----------------------------------\n",
            "  MCRMSE    cohesion    syntax    vocabulary    phraseology    grammar    conventions\n",
            "--------  ----------  --------  ------------  -------------  ---------  -------------\n",
            " 0.11615     0.11995   0.11765       0.11175        0.11378    0.11819        0.11558\n",
            "\n",
            "################################### END OF FOlD 3 ###################################\n",
            "\n",
            "\n",
            "Overall Training Result\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  fold epoch  train_loss    valid_loss       mcrmse     cohesion       syntax  \\\n",
              "0    0     1   0.2953077   0.006449495   0.11335484   0.11727818   0.10614471   \n",
              "0    1     1  0.29378775   0.005786872  0.107439466   0.10900378   0.10487801   \n",
              "0    2     1  0.29006767  0.0058528897   0.10792417  0.108111106  0.104199946   \n",
              "0    3     1  0.29774624   0.006749268    0.1161501   0.11995396   0.11764548   \n",
              "\n",
              "    vocabulary  phraseology      grammar  conventions  \n",
              "0    0.1116554   0.10521104   0.12605418   0.11378556  \n",
              "0   0.11388284  0.097644076  0.113296114  0.105931975  \n",
              "0   0.10994947    0.0977227  0.122675516   0.10488633  \n",
              "0  0.111754596   0.11377934   0.11819194   0.11557526  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7cde66f-7f84-4279-87af-ac3f2b716272\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>mcrmse</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2953077</td>\n",
              "      <td>0.006449495</td>\n",
              "      <td>0.11335484</td>\n",
              "      <td>0.11727818</td>\n",
              "      <td>0.10614471</td>\n",
              "      <td>0.1116554</td>\n",
              "      <td>0.10521104</td>\n",
              "      <td>0.12605418</td>\n",
              "      <td>0.11378556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29378775</td>\n",
              "      <td>0.005786872</td>\n",
              "      <td>0.107439466</td>\n",
              "      <td>0.10900378</td>\n",
              "      <td>0.10487801</td>\n",
              "      <td>0.11388284</td>\n",
              "      <td>0.097644076</td>\n",
              "      <td>0.113296114</td>\n",
              "      <td>0.105931975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29006767</td>\n",
              "      <td>0.0058528897</td>\n",
              "      <td>0.10792417</td>\n",
              "      <td>0.108111106</td>\n",
              "      <td>0.104199946</td>\n",
              "      <td>0.10994947</td>\n",
              "      <td>0.0977227</td>\n",
              "      <td>0.122675516</td>\n",
              "      <td>0.10488633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29774624</td>\n",
              "      <td>0.006749268</td>\n",
              "      <td>0.1161501</td>\n",
              "      <td>0.11995396</td>\n",
              "      <td>0.11764548</td>\n",
              "      <td>0.111754596</td>\n",
              "      <td>0.11377934</td>\n",
              "      <td>0.11819194</td>\n",
              "      <td>0.11557526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7cde66f-7f84-4279-87af-ac3f2b716272')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7cde66f-7f84-4279-87af-ac3f2b716272 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7cde66f-7f84-4279-87af-ac3f2b716272');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Result\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   fold epoch  train_loss    valid_loss       mcrmse     cohesion  \\\n",
              "0     0     1   0.2953077   0.006449495   0.11335484   0.11727818   \n",
              "1     1     1  0.29378775   0.005786872  0.107439466   0.10900378   \n",
              "2     2     1  0.29006767  0.0058528897   0.10792417  0.108111106   \n",
              "3     3     1  0.29774624   0.006749268    0.1161501   0.11995396   \n",
              "4  99.0  99.0    0.294227       0.00621     0.111217     0.113587   \n",
              "\n",
              "        syntax   vocabulary  phraseology      grammar  conventions  \n",
              "0   0.10614471    0.1116554   0.10521104   0.12605418   0.11378556  \n",
              "1   0.10487801   0.11388284  0.097644076  0.113296114  0.105931975  \n",
              "2  0.104199946   0.10994947    0.0977227  0.122675516   0.10488633  \n",
              "3   0.11764548  0.111754596   0.11377934   0.11819194   0.11557526  \n",
              "4     0.108217     0.111811     0.103589     0.120054     0.110045  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29d61de7-9a03-4048-a5a9-aaf34c568852\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>mcrmse</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2953077</td>\n",
              "      <td>0.006449495</td>\n",
              "      <td>0.11335484</td>\n",
              "      <td>0.11727818</td>\n",
              "      <td>0.10614471</td>\n",
              "      <td>0.1116554</td>\n",
              "      <td>0.10521104</td>\n",
              "      <td>0.12605418</td>\n",
              "      <td>0.11378556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29378775</td>\n",
              "      <td>0.005786872</td>\n",
              "      <td>0.107439466</td>\n",
              "      <td>0.10900378</td>\n",
              "      <td>0.10487801</td>\n",
              "      <td>0.11388284</td>\n",
              "      <td>0.097644076</td>\n",
              "      <td>0.113296114</td>\n",
              "      <td>0.105931975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29006767</td>\n",
              "      <td>0.0058528897</td>\n",
              "      <td>0.10792417</td>\n",
              "      <td>0.108111106</td>\n",
              "      <td>0.104199946</td>\n",
              "      <td>0.10994947</td>\n",
              "      <td>0.0977227</td>\n",
              "      <td>0.122675516</td>\n",
              "      <td>0.10488633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29774624</td>\n",
              "      <td>0.006749268</td>\n",
              "      <td>0.1161501</td>\n",
              "      <td>0.11995396</td>\n",
              "      <td>0.11764548</td>\n",
              "      <td>0.111754596</td>\n",
              "      <td>0.11377934</td>\n",
              "      <td>0.11819194</td>\n",
              "      <td>0.11557526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.294227</td>\n",
              "      <td>0.00621</td>\n",
              "      <td>0.111217</td>\n",
              "      <td>0.113587</td>\n",
              "      <td>0.108217</td>\n",
              "      <td>0.111811</td>\n",
              "      <td>0.103589</td>\n",
              "      <td>0.120054</td>\n",
              "      <td>0.110045</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29d61de7-9a03-4048-a5a9-aaf34c568852')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29d61de7-9a03-4048-a5a9-aaf34c568852 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29d61de7-9a03-4048-a5a9-aaf34c568852');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Result\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       mcrmse     cohesion       syntax  vocabulary phraseology      grammar  \\\n",
              "0  0.11132877  0.113701954  0.108354494  0.11181876  0.10380057  0.120152414   \n",
              "\n",
              "   conventions  \n",
              "0  0.110144444  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48906818-c77a-4ff2-ba76-b9d9310ee43a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mcrmse</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.11132877</td>\n",
              "      <td>0.113701954</td>\n",
              "      <td>0.108354494</td>\n",
              "      <td>0.11181876</td>\n",
              "      <td>0.10380057</td>\n",
              "      <td>0.120152414</td>\n",
              "      <td>0.110144444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48906818-c77a-4ff2-ba76-b9d9310ee43a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48906818-c77a-4ff2-ba76-b9d9310ee43a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48906818-c77a-4ff2-ba76-b9d9310ee43a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "check_or_create(TRAINCONF.save_path)\n",
        "export_config(basic=BASICCONF, train=TRAINCONF)\n",
        "run_training(pl_df_list, TRAINCONF, dry_run=False, exp=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef11cc3c",
      "metadata": {
        "papermill": {
          "duration": 0.012582,
          "end_time": "2022-11-23T14:57:34.585354",
          "exception": false,
          "start_time": "2022-11-23T14:57:34.572772",
          "status": "completed"
        },
        "tags": [],
        "id": "ef11cc3c"
      },
      "source": [
        "# Jump to Results 🔼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725c9db6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-23T14:57:34.612994Z",
          "iopub.status.busy": "2022-11-23T14:57:34.611935Z",
          "iopub.status.idle": "2022-11-23T14:57:34.616954Z",
          "shell.execute_reply": "2022-11-23T14:57:34.616065Z"
        },
        "papermill": {
          "duration": 0.020779,
          "end_time": "2022-11-23T14:57:34.618917",
          "exception": false,
          "start_time": "2022-11-23T14:57:34.598138",
          "status": "completed"
        },
        "tags": [],
        "id": "725c9db6"
      },
      "outputs": [],
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "# model = AutoModel.from_pretrained('microsoft/deberta-v3-base', output_hidden_states=True)\n",
        "# train_loader, valid_loader, total_train_samples = get_dataloader(conf, df, tokenizer, 8, 2)\n",
        "\n",
        "# loader = iter(train_loader)\n",
        "# first = next(loader)\n",
        "# outputs = model(**first[0])\n",
        "\n",
        "# import pdb; pdb.set_trace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de2555fb",
      "metadata": {
        "papermill": {
          "duration": 0.012068,
          "end_time": "2022-11-23T14:57:34.643676",
          "exception": false,
          "start_time": "2022-11-23T14:57:34.631608",
          "status": "completed"
        },
        "tags": [],
        "id": "de2555fb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4488.213458,
      "end_time": "2022-11-23T14:57:37.699461",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-11-23T13:42:49.486003",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de28e755acd742ce944be5e2bc4f66f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9675e3907bb49f58217d99bbe143ff5",
              "IPY_MODEL_b3f20624c7b34d4bbc30e983b01022cd",
              "IPY_MODEL_1adda1f6dd834017a61e23ae47903bfe"
            ],
            "layout": "IPY_MODEL_a9b4fbb807514e54b9fbd06be366486a"
          }
        },
        "c9675e3907bb49f58217d99bbe143ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ec52a74cfe9420fbd7c6bb2327279c3",
            "placeholder": "​",
            "style": "IPY_MODEL_881c83965e1c444eb8eeb354dddae146",
            "value": "Downloading: 100%"
          }
        },
        "b3f20624c7b34d4bbc30e983b01022cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8356bf7aecdf44beb51bb76c6460aa8e",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b73dc94bab74770928b031febe0cf91",
            "value": 52
          }
        },
        "1adda1f6dd834017a61e23ae47903bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15387110215b46e18cecd7590c7e80d2",
            "placeholder": "​",
            "style": "IPY_MODEL_0fcf7a3686904880ab6334d728e9e534",
            "value": " 52.0/52.0 [00:00&lt;00:00, 809B/s]"
          }
        },
        "a9b4fbb807514e54b9fbd06be366486a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ec52a74cfe9420fbd7c6bb2327279c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "881c83965e1c444eb8eeb354dddae146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8356bf7aecdf44beb51bb76c6460aa8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b73dc94bab74770928b031febe0cf91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15387110215b46e18cecd7590c7e80d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fcf7a3686904880ab6334d728e9e534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1308a6360c3c455a855165a6ff3b179b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b04814bb00584b55ae03dd31b2e3a8a9",
              "IPY_MODEL_6cdc64cf80b2430da2b903bd3f646eca",
              "IPY_MODEL_464fb5b3762e41738d422247997264a6"
            ],
            "layout": "IPY_MODEL_2742fb365b47443c9567e1f6f60d8e10"
          }
        },
        "b04814bb00584b55ae03dd31b2e3a8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37e17bb8d8e34a37b15e242e2633ab13",
            "placeholder": "​",
            "style": "IPY_MODEL_7d3d4bbddc614e029e575deba4b5dac2",
            "value": "Downloading: 100%"
          }
        },
        "6cdc64cf80b2430da2b903bd3f646eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_687790dfe19e45d5a8131b7e37a8056a",
            "max": 579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f02d8ffe2e1547b7b6eba09fa69e14e1",
            "value": 579
          }
        },
        "464fb5b3762e41738d422247997264a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e382e9dc27b34209926a2715dd1f43ec",
            "placeholder": "​",
            "style": "IPY_MODEL_5f9fb1f6f4fd4725b0275cd83d1662f3",
            "value": " 579/579 [00:00&lt;00:00, 19.1kB/s]"
          }
        },
        "2742fb365b47443c9567e1f6f60d8e10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e17bb8d8e34a37b15e242e2633ab13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3d4bbddc614e029e575deba4b5dac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "687790dfe19e45d5a8131b7e37a8056a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f02d8ffe2e1547b7b6eba09fa69e14e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e382e9dc27b34209926a2715dd1f43ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f9fb1f6f4fd4725b0275cd83d1662f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f5150f7fdc74ce7a0b2e94546912291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08decec3f0b2455eb3a65b41c1021bf8",
              "IPY_MODEL_0c8e3932bcca4de8b5c91dcef0f876ee",
              "IPY_MODEL_2a5b2946f0fa414f9f58178837009dd2"
            ],
            "layout": "IPY_MODEL_118b89976b1048c1a6d4be13d7d76920"
          }
        },
        "08decec3f0b2455eb3a65b41c1021bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaaf7b4a089d45ca9f33adb54501034d",
            "placeholder": "​",
            "style": "IPY_MODEL_4c02a2d0a6ec4f6294147b5968a6877e",
            "value": "Downloading: 100%"
          }
        },
        "0c8e3932bcca4de8b5c91dcef0f876ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06c2358574524e83b7f89458495451de",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db14b3a8361547f482821725387ee508",
            "value": 2464616
          }
        },
        "2a5b2946f0fa414f9f58178837009dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9cfb8a52ee46d1b5473ba2f2a48a1b",
            "placeholder": "​",
            "style": "IPY_MODEL_83962c357e8b4c0ab7c241b224bf5301",
            "value": " 2.35M/2.35M [00:00&lt;00:00, 17.5MB/s]"
          }
        },
        "118b89976b1048c1a6d4be13d7d76920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaaf7b4a089d45ca9f33adb54501034d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c02a2d0a6ec4f6294147b5968a6877e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06c2358574524e83b7f89458495451de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db14b3a8361547f482821725387ee508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c9cfb8a52ee46d1b5473ba2f2a48a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83962c357e8b4c0ab7c241b224bf5301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b941085531bf40e39c4e676132d9ec4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_999f632b466a41a2bd1926ab95c51445",
              "IPY_MODEL_eb0d48c09001474bb9f52a91a8e676c6",
              "IPY_MODEL_e7626076a0fc4ba090593872ab62047f"
            ],
            "layout": "IPY_MODEL_3ca01bac164948009fdab1def54f19eb"
          }
        },
        "999f632b466a41a2bd1926ab95c51445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca1738e9e93450983a0928e70dfe238",
            "placeholder": "​",
            "style": "IPY_MODEL_8da4cdc224b14e0e80b9fab01c19b0b6",
            "value": "Downloading: 100%"
          }
        },
        "eb0d48c09001474bb9f52a91a8e676c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7608a328e42482986d360ec37e7f2bd",
            "max": 371146213,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d74aad908314d19b93b7bbf99223c51",
            "value": 371146213
          }
        },
        "e7626076a0fc4ba090593872ab62047f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0fa5103e084c5cb784b050e8c49264",
            "placeholder": "​",
            "style": "IPY_MODEL_ec7e86de1a6c4facb0d0c893efb11bfd",
            "value": " 354M/354M [00:10&lt;00:00, 58.0MB/s]"
          }
        },
        "3ca01bac164948009fdab1def54f19eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca1738e9e93450983a0928e70dfe238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da4cdc224b14e0e80b9fab01c19b0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7608a328e42482986d360ec37e7f2bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d74aad908314d19b93b7bbf99223c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee0fa5103e084c5cb784b050e8c49264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec7e86de1a6c4facb0d0c893efb11bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}